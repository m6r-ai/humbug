{
  "metadata": {
    "version": "0.1"
  },
  "conversation": [
    {
      "id": "e4a8e77c-b912-48ce-be9d-6c58b562543c",
      "timestamp": "2025-06-12T06:14:38.025673",
      "type": "user_message",
      "content": "The following preamble describes some elements of a language called Metaphor.  Please pay\nextremely close attention to the details as they will affect the way you interpret\neverything that follows after \"BEGIN DESCRIPTION IN METAPHOR:\"\n\nMetaphor is a structured natural language prompt creation language.  It is designed to\nlet a user convey their requirements to a large language model AI.\n\nMetaphor has the structure of a document tree with branches and leaves being prefixed\nby new sections containing the keywords \"Role:\", \"Context:\" or \"Action:\".  Each of\nthese indicates the start of a new block of information.  Blocks are introduced using\nMarkdown-style headings (using hash symbols).  The number of hashes gives an indication\nof the nesting depth and the parent/child relationship.\n\nBlock keywords have an optional name that will immediately follow them on the same line.\nIf this is missing then the block name is not defined.\n\nAfter a block heading there may be one or more lines of text that will describe the purpose\nof that block.  A block may also include one or more optional child blocks inside them and\nthat further clarify their parent block.\n\nWithin the text of a block, you may be presented with code or document fragments inside a\nblock delimited by 3 backticks.  Please pay close attention to the indentation level of the\nopening 3 backticks.  The identation of such code or document fragments is relative to this,\nnot relative to the block in which the code or document fragment occurs.\n\nIf \"Role:\" block exists then this contains details about the role you should fulfil.  This\nmay also describe specific skills you have, knowledge you should apply, and the\napproach you take to apply these.\n\n\"Context:\" blocks provide context necessary to understand what you will be asked to do.\n\n\"Action:\" blocks describes the task, or tasks, you should do.\n\nIf you are asked to offer any opinions on the Metaphor prompt then always provide the full\nset of parent headings leading up to any block you want to talk about.  This will allow\nthe user to understand which part of the Metaphor prompt is being discussed.\n\nWhen you process the actions please carefully ensure you do all of them accurately and\ncomplete all the elements requested.  Unless otherwise instructed, do not include any\nplaceholders in your responses.\n\nBEGIN DESCRIPTION IN METAPHOR:\n\n# Role:\n\nYou are a world class python programmer, highly skilled in accurate and performant software development.  You\nare going to assist me in making modifications to my application.\n\n# Context:\n\n## Context: Python implementation rules\n\nAs an engineer working with the application, I want the application to be easy to use and understand,\nso I can maintain and enhance it over time.\n\n### Context: Implement in Python 3\n\nThe application will be written in the latest version of Python 3.  Assume a baseline of Python 3.10.\n\n### Context: Indentation of code\n\nCode must be indented by 4 spaces.\n\n### Context: Use docstrings\n\nDocstrings must be used to describe all modules, classes, and functions.  This should follow PEP 257 guidelines.\n\n### Context: Use type hints\n\nType hints must be used for function arguments and return values.\n\nAs we're using Python 3.10 as a minimum, use union types.  E.g. use `T | None` instead of `Optional[T]`.\n\n`self` parameters do not need to have type hints.\n\n### Context: Use comments\n\nComments must be used to describe any complex logic, or rationale that would not be obvious from\nsimply reading the code.  This ensures that anyone reading the code for the first time will be able\nto understand why the code is the way it is.\n\n### Context: PEP 8 imports\n\nThe import list in any module should follow PEP 8 guidelines, including the ordering of imports.\n\n### Context: Avoid unnecessary `elif` and `else` statements\n\nTo improve readability, do not use `elif` or `else` statements if the preceding `if` branch ends with\na `return`, `continue`, or `break`.\n\nFor example, do this:\n\n```python\nif condition:\n    return\n\nnext_statement()\n```\n\ninstead of this:\n\n```python\nif condition:\n    return\nelse:\n    next_statement()\n```\n\nThe first version avoids the unecessary else statement.\n\n### Context: Handle error and exception paths early\n\nIf it is possible to detect errors and exceptions early then do so.  Always prefer to do this as early\nas possible within the code so we have the fewest possible conditional checks by the time we reach the\nmain purpose of any function or method.\n\nThis is sometimes known as \"flattening the code to the left\" as there is generally less indentation required\nwhen we do this.  This makes the code easier to read.\n\nFor example do this:\n\n```python\nif error_condition:\n    return\n\nif another_error_condition:\n    return\n\nhandle_happy_path()\n```\n\ninstead of this:\n\n```python\nif not error_condition:\n    if not another_error_condition:\n        handle_happy_path()\n```\n\nWhile the latter has slightly fewer lines of code, it is far more difficult to understand when reading.\n\n### Context: Exception handling philosophy\n\n#### Context: Exception documentation\n\nDocument what exceptions each function may raise in its docstring.\n\n#### Context: Handling exceptions\n\nAttempt to handle and mitigate exceptions at the level closest to which they are first\ndetected.  If we cannot handle or mitigate the exception then it should be wrapped in a domain-appropriate\nexception class and this re-raised to the next level up the call stack.\n\nInclude contextual information when wrapping exceptions.\n\nPreserve the exception chain using `raise ... from e` syntax.\n\n#### Context: Avoid bare `except:` or `except Exception:` clauses.\n\nAvoid the use of bare `except:` or `except Exception:` clauses unless a function we are calling\ncan only have exceptions handled this way.\n\nWe should always catch specific exception types that could occur from an operation.\n\n#### Context: Exception logging\n\nAll exceptions should be logged when they occur, before re-raising or wrapping them.\n\nUse appropriate log levels:\n- ERROR for exceptions that indicate failure.\n- WARNING for exceptions that can be handled/recovered from.\n- DEBUG for detailed exception information during development.\n\nWe must include sufficient context in log messages to aid debugging.\n\nLogging must use lazy evaluation of any arguments rather.\n\n#### Context: Exception wrapping example\n\nDo this:\n\n```python\ntry:\n    await self.api_client.fetch_data()\n\nexcept ConnectionError as e:\n    logger.error(\"Failed to retrieve data from API endpoint\", exc_info=True)\n    raise DataFetchError(f\"Failed to retrieve data from API endpoint: {e}\") from e\n\nexcept TimeoutError as e:\n    logger.warning(\"API request timed out, will retry\", exc_info=True)\n```\n\nNot this:\n\n```python\ntry:\n    await self.api_client.fetch_data()\nexcept Exception as e:\n    logger.error(f\"Error: {e}\")  # Insufficient context, no stack trace\n    raise  # No wrapping or additional context\n```\n\n## Context: Dependencies\n\nLeverage standard library tools before custom solutions, unless specifically instructed, or\nunless a depdency is already in use.\n\n## Context: Existing code\n\nThe following files are used in my application:\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/markdown/markdown_converter.py\n\n```python\n\"\"\"\nUtility for converting simplified markdown text to HTML.\n\nThis module provides functionality to incrementally convert simplified markdown\nto HTML while preserving code blocks and handling streaming text updates.\n\"\"\"\n\nimport logging\nfrom typing import List, Tuple, cast\n\nfrom humbug.markdown.markdown_ast_builder import MarkdownASTBuilder\nfrom humbug.markdown.markdown_ast_node import MarkdownCodeBlockNode, MarkdownASTNode, MarkdownDocumentNode\nfrom humbug.syntax.programming_language import ProgrammingLanguage\nfrom humbug.syntax.programming_language_utils import ProgrammingLanguageUtils\n\n\nclass MarkdownConverter:\n    \"\"\"\n    Converts simplified markdown to HTML using an AST-based approach.\n\n    This class handles the incremental parsing of simplified markdown into an\n    Abstract Syntax Tree (AST) representation and extraction of content sections for rendering.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initialize the markdown converter with an AST builder and HTML renderer.\n\n        Args:\n            source_path: Optional path to the source markdown file\n        \"\"\"\n        self.ast_builder = MarkdownASTBuilder(True)\n\n        self._logger = logging.getLogger(\"ConversationMarkdownConverter\")\n\n        # Keep track of the current text for incremental updates\n        self.current_text = \"\"\n\n        # Store builder state for preservation during reset\n        self.builder_state = None\n\n        self._source_path: str | None = None\n\n    def extract_sections(self, text: str, path: str | None) -> List[Tuple[MarkdownASTNode, ProgrammingLanguage | None]]:\n        \"\"\"\n        Process markdown text and extract content sections from it.\n\n        Args:\n            text: The markdown text to process\n            path: Optional path to the source markdown file\n\n        Returns:\n            List of (node, language) tuples where language is None for markdown content\n            and a ProgrammingLanguage enum for code blocks\n\n        Raises:\n            None\n        \"\"\"\n        self._source_path = path\n\n        # Update the AST based on the changes\n        self.ast_builder.update_ast(text, self.current_text, path)\n        self.current_text = text\n\n        # Extract content sections from the AST document\n        return self._extract_sections_from_ast(self.ast_builder.document())\n\n    def _extract_sections_from_ast(self, document: MarkdownASTNode) -> List[Tuple[MarkdownASTNode, ProgrammingLanguage | None]]:\n        \"\"\"\n        Extract content sections from the AST document.\n\n        Args:\n            document: The AST document node\n\n        Returns:\n            List of (node, language) tuples where language is None for markdown content\n            and a ProgrammingLanguage enum for code blocks\n        \"\"\"\n        sections: List[tuple[MarkdownASTNode, ProgrammingLanguage | None]] = []\n        current_markdown_nodes: List[MarkdownASTNode] = []\n\n        # Helper function to add accumulated markdown content as a section\n        def add_markdown_section() -> None:\n            if current_markdown_nodes:\n                # Create a container node for these markdown nodes\n                container = MarkdownDocumentNode(self._source_path)\n                for node in current_markdown_nodes:\n                    container.add_child(node)\n\n                # Add as a markdown section\n                sections.append((container, None))\n                current_markdown_nodes.clear()\n\n        # Process all nodes in the document\n        for node in document.children:\n            if isinstance(node, MarkdownCodeBlockNode):\n                # Add any accumulated markdown before this code block\n                add_markdown_section()\n\n                # Process the code block\n                language = ProgrammingLanguageUtils.from_name(node.language) if node.language else ProgrammingLanguage.TEXT\n\n                # Add the code block node as a section with its language\n                sections.append((node, language))\n\n            else:\n                # Add to current markdown content\n                current_markdown_nodes.append(cast(MarkdownASTNode, node))\n\n        # Add any remaining markdown content\n        add_markdown_section()\n\n        return sections\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/markdown/markdown_ast_node.py\n\n```python\n\"\"\"\nUtility for converting simplified markdown text to HTML.\n\nThis module provides functionality to incrementally convert simplified markdown\nto HTML while preserving code blocks and handling streaming text updates.\n\"\"\"\n\nfrom humbug.ast.ast import ASTNode, ASTVisitor\n\n\nclass MarkdownASTNode(ASTNode):\n    \"\"\"Base class for all Markdown AST nodes.\"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize an AST node with common markdown properties.\"\"\"\n        super().__init__()\n\n        # Source range information to support incremental updating\n        self.line_start: int | None = None\n        self.line_end: int | None = None\n\n\nclass MarkdownASTVisitor(ASTVisitor):\n    \"\"\"Base visitor class for Markdown AST traversal.\"\"\"\n\n\nclass MarkdownDocumentNode(MarkdownASTNode):\n    \"\"\"Root node representing an entire HTML document.\"\"\"\n\n    def __init__(self, source_path: str | None = None) -> None:\n        \"\"\"\n        Initialize a document node.\n\n        Args:\n            source_path: Optional path to the source file for resolving relative references\n        \"\"\"\n        super().__init__()\n        self.source_path = source_path\n\n\nclass MarkdownParagraphNode(MarkdownASTNode):\n    \"\"\"Node representing an HTML paragraph (<p>).\"\"\"\n\n\nclass MarkdownHeadingNode(MarkdownASTNode):\n    \"\"\"Node representing an HTML heading (<h1> through <h6>).\"\"\"\n    def __init__(self, level: int, anchor_id: str) -> None:\n        \"\"\"\n        Initialize a heading node.\n\n        Args:\n            level: The heading level (1-6)\n        \"\"\"\n        super().__init__()\n\n        # Level should be 1-6\n        self.level = max(1, min(6, level))\n        self.anchor_id = anchor_id\n\n\nclass MarkdownOrderedListNode(MarkdownASTNode):\n    \"\"\"Node representing an HTML ordered list (<ol>).\"\"\"\n    def __init__(self, indent: int = 0, start: int = 1) -> None:\n        \"\"\"\n        Initialize an ordered list node.\n\n        Args:\n            indent: The indentation level of this list\n        \"\"\"\n        super().__init__()\n        self.indent = indent\n        self.start = start\n\n        # Content indent is typically indent + marker (e.g., \"1.\") + space\n        # For ordered lists, we use a default of 3 characters for the marker (\"1. \")\n        self.content_indent = indent + 3\n\n        # Track whether this list should render tightly (without extra spacing)\n        self.tight = True\n\n\nclass MarkdownUnorderedListNode(MarkdownASTNode):\n    \"\"\"Node representing an HTML unordered list (<ul>).\"\"\"\n    def __init__(self, indent: int = 0) -> None:\n        \"\"\"\n        Initialize an unordered list node.\n\n        Args:\n            indent: The indentation level of this list\n        \"\"\"\n        super().__init__()\n        self.indent = indent\n\n        # Content indent is typically indent + marker (e.g., \"-\") + space\n        # For unordered lists, we use 2 characters for the marker (\"- \")\n        self.content_indent = indent + 2\n\n        # Track whether this list should render tightly (without extra spacing)\n        self.tight = True\n\n\nclass MarkdownListItemNode(MarkdownASTNode):\n    \"\"\"Node representing an HTML list item (<li>).\"\"\"\n\n\nclass MarkdownTextNode(MarkdownASTNode):\n    \"\"\"Node representing plain text content.\"\"\"\n    def __init__(self, content: str) -> None:\n        \"\"\"\n        Initialize a text node.\n\n        Args:\n            content: The text content\n        \"\"\"\n        super().__init__()\n        self.content = content\n\n\nclass MarkdownBoldNode(MarkdownASTNode):\n    \"\"\"Node representing bold text (<b> or <strong>).\"\"\"\n\n\nclass MarkdownEmphasisNode(MarkdownASTNode):\n    \"\"\"Node representing emphasized text (<em> or <i>).\"\"\"\n\n\nclass MarkdownInlineCodeNode(MarkdownASTNode):\n    \"\"\"Node representing inline code (<code>).\"\"\"\n    def __init__(self, content: str = \"\") -> None:\n        \"\"\"\n        Initialize an inline code node.\n\n        Args:\n            content: The code content\n        \"\"\"\n        super().__init__()\n        self.content = content\n\n\nclass MarkdownLinkNode(MarkdownASTNode):\n    \"\"\"Node representing a link (<a>).\"\"\"\n    def __init__(self, url: str = \"\", title: str | None = None) -> None:\n        \"\"\"\n        Initialize a link node.\n\n        Args:\n            url: The link URL\n            title: Optional title attribute\n        \"\"\"\n        super().__init__()\n        self.url = url\n        self.title = title\n\n\nclass MarkdownImageNode(MarkdownASTNode):\n    \"\"\"Node representing an image (<img>).\"\"\"\n    def __init__(self, url: str = \"\", alt_text: str = \"\", title: str | None = None) -> None:\n        \"\"\"\n        Initialize an image node.\n\n        Args:\n            url: The image URL\n            alt_text: Alternative text for the image\n            title: Optional title attribute\n        \"\"\"\n        super().__init__()\n        self.url = url\n        self.alt_text = alt_text\n        self.title = title\n\n\nclass MarkdownCodeBlockNode(MarkdownASTNode):\n    \"\"\"Node representing a code block (<pre><code>).\"\"\"\n    def __init__(self, language: str = \"\", content: str = \"\") -> None:\n        \"\"\"\n        Initialize a code block node.\n\n        Args:\n            language: Optional language identifier for syntax highlighting\n            content: The code content\n        \"\"\"\n        super().__init__()\n        self.language = language\n        self.content = content\n\n\nclass MarkdownLineBreakNode(MarkdownASTNode):\n    \"\"\"Node representing a line break.\"\"\"\n\n\nclass MarkdownTableNode(MarkdownASTNode):\n    \"\"\"Node representing an HTML table (<table>).\"\"\"\n\n\nclass MarkdownTableHeaderNode(MarkdownASTNode):\n    \"\"\"Node representing the header row section of a table (<thead>).\"\"\"\n\n\nclass MarkdownTableBodyNode(MarkdownASTNode):\n    \"\"\"Node representing the body section of a table (<tbody>).\"\"\"\n\n\nclass MarkdownTableRowNode(MarkdownASTNode):\n    \"\"\"Node representing a table row (<tr>).\"\"\"\n\n\nclass MarkdownTableCellNode(MarkdownASTNode):\n    \"\"\"Node representing a table cell (<td> or <th>).\"\"\"\n    def __init__(self, is_header: bool = False, alignment: str = \"left\") -> None:\n        \"\"\"\n        Initialize a table cell node.\n\n        Args:\n            is_header: Whether this is a header cell (<th>) or a data cell (<td>)\n            alignment: Cell alignment ('left', 'center', 'right')\n        \"\"\"\n        super().__init__()\n        self.is_header = is_header\n        self.alignment = alignment\n\n\nclass MarkdownHorizontalRuleNode(MarkdownASTNode):\n    \"\"\"Node representing a horizontal rule (<hr>).\"\"\"\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/markdown/markdown_ast_builder.py\n\n```python\n\"\"\"\nParser to construct an AST from Markdown.\n\"\"\"\n\nimport logging\nimport re\nfrom typing import Dict, List, Tuple, Any, cast\n\nfrom humbug.markdown.markdown_ast_node import (\n    MarkdownASTNode, MarkdownDocumentNode, MarkdownTextNode, MarkdownLineBreakNode,\n    MarkdownEmphasisNode, MarkdownBoldNode, MarkdownHeadingNode,\n    MarkdownParagraphNode, MarkdownOrderedListNode, MarkdownUnorderedListNode,\n    MarkdownListItemNode, MarkdownInlineCodeNode, MarkdownCodeBlockNode,\n    MarkdownTableNode, MarkdownTableHeaderNode, MarkdownTableBodyNode,\n    MarkdownTableRowNode, MarkdownTableCellNode, MarkdownHorizontalRuleNode,\n    MarkdownImageNode, MarkdownLinkNode\n)\nfrom humbug.syntax.parser_registry import ParserRegistry\nfrom humbug.syntax.programming_language import ProgrammingLanguage\nfrom humbug.syntax.programming_language_utils import ProgrammingLanguageUtils\n\n\nclass TableBufferState:\n    \"\"\"Class to track and buffer table elements during parsing.\"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize the table buffer state.\"\"\"\n        # Buffer for table rows before commitment\n        self.header_row: List[str] = []\n        self.header_line: str = \"\"\n        self.separator_row: List[str] = []\n        self.separator_line: str = \"\"\n        self.body_rows: List[List[str]] = []\n\n        # Table state\n        self.is_in_potential_table: bool = False\n        self.is_confirmed_table: bool = False\n        self.alignments: List[str] = []\n\n        # Line tracking for AST nodes\n        self.start_line: int = -1\n        self.current_line: int = -1\n\n    def reset(self) -> None:\n        \"\"\"Reset the table buffer state.\"\"\"\n        self.header_row = []\n        self.header_line = \"\"\n        self.separator_row = []\n        self.separator_line = \"\"\n        self.body_rows = []\n        self.is_in_potential_table = False\n        self.is_confirmed_table = False\n        self.alignments = []\n        self.start_line = -1\n        self.current_line = -1\n\n    def is_valid_table(self) -> bool:\n        \"\"\"\n        Check if we have sufficient elements for a valid table.\n\n        Returns:\n            True if we have a header row, separator row, and at least one body row\n        \"\"\"\n        return (len(self.header_row) > 0 and\n                len(self.separator_row) > 0 and\n                len(self.body_rows) > 0)\n\n\nclass ListState:\n    \"\"\"Tracks the state of a list and its items during parsing.\"\"\"\n\n    def __init__(self, list_node: MarkdownOrderedListNode | MarkdownUnorderedListNode, indent: int) -> None:\n        \"\"\"\n        Initialize a list state tracker.\n\n        Args:\n            list_node: The list node (MarkdownOrderedListNode or MarkdownUnorderedListNode)\n            indent: The indentation level of the list marker\n        \"\"\"\n        self.list_node = list_node\n        self.indent = indent\n        self.marker_length = 0\n        self.last_item: MarkdownListItemNode | None = None\n        self.contains_blank_line = False\n\n\nclass MarkdownASTBuilder:\n    \"\"\"\n    Builder class for constructing an AST from markdown text.\n\n    This class handles the incremental parsing of markdown text into an\n    Abstract Syntax Tree (AST) representation.\n    \"\"\"\n\n    def __init__(self, no_underscores: bool):\n        \"\"\"Initialize the AST builder with regex patterns for markdown elements.\"\"\"\n        self._no_underscores = no_underscores\n        self._source_path: str | None = None\n\n        # Regular expressions for markdown elements\n        self._heading_pattern = re.compile(r'^(#{1,10})\\s+(.*?)(?:\\s+#{1,10})?$', re.MULTILINE)\n        self._unordered_list_pattern = re.compile(r'^(\\s*)([*+-])\\s+(.*?)$', re.MULTILINE)\n        self._ordered_list_pattern = re.compile(r'^(\\s*)(\\d+)\\.[ \\t]+(.*?)$', re.MULTILINE)\n        self._code_block_pattern = re.compile(r'^```(?:([\\w\\-#+./*():\\s]+))?$')\n        self._table_row_pattern = re.compile(r'^(\\|.+\\|)$', re.MULTILINE)\n        self._table_separator_pattern = re.compile(r'^(\\|[\\s:-]+\\|)$', re.MULTILINE)\n        self._horizontal_rule_pattern = re.compile(r'^(?:\\s*(?:[-*_])\\s*){3,}$')\n\n        self._logger = logging.getLogger(\"MarkdownASTBuilder\")\n\n        # Initialize an empty document\n        self._document = MarkdownDocumentNode()\n\n        # Mapping from line numbers to nodes for incremental updates\n        self._line_to_node_map: Dict[int, List[MarkdownASTNode]] = {}\n\n        # Track header IDs to allow us to create unique link anchors for headings with the same text\n        self._used_header_ids: Dict[str, int] = {}\n\n        # List state tracking\n        self._list_stack: List[ListState] = []\n\n        # Text continuation tracking\n        self._last_paragraph: MarkdownParagraphNode | None = None\n        self._last_processed_line_type: str = \"\"\n        self._blank_line_count: int = 0\n\n        # Code block state tracking\n        self._in_code_block = False\n        self._code_block_language = \"\"\n        self._code_block_content: List[str] = []\n        self._code_block_start_line = -1\n        self._code_block_nesting_level = 0\n        self._code_block_indents: List[int] = []\n        self._embedded_parser_state: Any = None\n        self._embedded_language: ProgrammingLanguage = ProgrammingLanguage.UNKNOWN\n\n        # Table state tracking using the new buffer approach\n        self._table_buffer = TableBufferState()\n\n    def document(self) -> MarkdownDocumentNode:\n        \"\"\"\n        Get the current document node.\n\n        Returns:\n            The document node\n        \"\"\"\n        return self._document\n\n    def _should_parse_code_block_as_continuation(\n        self,\n        language: ProgrammingLanguage,\n        line_content: str\n    ) -> bool:\n        \"\"\"\n        Check if a line should be parsed as a continuation by the embedded parser.\n\n        Args:\n            language: The programming language of the code block\n            line_content: The content of the line to check\n\n        Returns:\n            True if this line should be treated as a continuation\n        \"\"\"\n        if language == ProgrammingLanguage.TEXT:\n            return False\n\n        # Get or create parser for this language\n        parser = ParserRegistry.create_parser(language)\n        assert parser is not None, f\"No parser registered for language: {language.name}\"\n\n        # If language changed, reset state\n        if language != self._embedded_language:\n            self._embedded_parser_state = None\n            self._embedded_language = language\n\n        # Parse the line and check if we're in a continuation\n        new_state = parser.parse(self._embedded_parser_state, line_content)\n\n        # Update stored state\n        self._embedded_parser_state = new_state\n\n        # Return whether we're in a continuation\n        return new_state is not None and new_state.parsing_continuation\n\n    def identify_line_type(self, line: str) -> Tuple[str, Any]:\n        \"\"\"\n        Identify the type of a markdown line.\n\n        Args:\n            line: The line to identify\n\n        Returns:\n            A tuple of (line_type, content) where line_type is one of:\n            'heading', 'unordered_list_item', 'ordered_list_item', 'blank', 'text',\n            'code_block_start', 'code_block_end', 'code_block_content',\n            'table_row', 'table_separator', 'line_break', 'horizontal_rule'\n        \"\"\"\n        # Handle code block state\n        lstripped_line = line.lstrip()\n        indent = len(line) - len(lstripped_line)\n\n        if self._in_code_block:\n            # Check if our embedded parser indicates this should be a continuation\n            if self._code_block_language:\n                language = ProgrammingLanguageUtils.from_name(self._code_block_language)\n                assert language != ProgrammingLanguage.UNKNOWN, \"Unknown programming language in code block\"\n                if self._should_parse_code_block_as_continuation(language, line):\n                    return 'code_block_content', line\n\n            # Check for code fence.  If we have one then we're either closing\n            # this block or nesting another.\n            code_block_match = self._code_block_pattern.match(lstripped_line)\n            if code_block_match:\n                language_name = code_block_match.group(1)\n                if language_name is not None or indent > self._code_block_indents[-1]:\n                    self._code_block_nesting_level += 1\n                    self._code_block_indents.append(indent)\n                    return 'code_block_content', line\n\n                self._code_block_indents.pop()\n                self._code_block_nesting_level -= 1\n                if self._code_block_nesting_level == 0:\n                    return 'code_block_end', None\n\n            return 'code_block_content', line\n\n        # Check for code block start\n        code_block_match = self._code_block_pattern.match(lstripped_line)\n        if code_block_match:\n            language_name = code_block_match.group(1) or \"\"\n            self._code_block_nesting_level = 1\n            self._code_block_indents.append(indent)\n            return 'code_block_start', language_name\n\n        # Check for a line break\n        if indent >= 2 and not lstripped_line:\n            return 'line_break', None\n\n        # Check for blank line\n        stripped_line = line.strip()\n        if not stripped_line:\n            return 'blank', None\n\n        # Check for heading\n        heading_match = self._heading_pattern.match(line)\n        if heading_match:\n            level = len(heading_match.group(1))\n            content = heading_match.group(2).strip()\n            return 'heading', (level, content)\n\n        # Check for table separator row\n        if stripped_line.startswith('|') and stripped_line.endswith('|'):\n            # Check if it's a separator row with at least one colon or dash\n            if '-' in line and (':-' in line or '-:' in line or '--' in line):\n                return 'table_separator', stripped_line\n\n            # Regular table row\n            return 'table_row', stripped_line\n\n        # Check for unordered list item\n        unordered_match = self._unordered_list_pattern.match(line)\n        if unordered_match:\n            indent = len(unordered_match.group(1))\n            marker = unordered_match.group(2)\n            content = unordered_match.group(3)\n            return 'unordered_list_item', (indent, marker, content)\n\n        # Check for ordered list item\n        ordered_match = self._ordered_list_pattern.match(line)\n        if ordered_match:\n            indent = len(ordered_match.group(1))\n            number = ordered_match.group(2)\n            content = ordered_match.group(3)\n            return 'ordered_list_item', (indent, number, content)\n\n        # Check for horizontal rule\n        if self._horizontal_rule_pattern.match(line):\n            return 'horizontal_rule', None\n\n        # Default to regular text\n        return 'text', line\n\n    def _find_closing_parenthesis(self, text: str, start_pos: int) -> int:\n        \"\"\"\n        Find the closing parenthesis that matches an opening one, handling nested parentheses.\n\n        Args:\n            text: The text to search in\n            start_pos: The position after the opening parenthesis\n\n        Returns:\n            The position of the closing parenthesis, or -1 if not found\n        \"\"\"\n        paren_count = 1\n        pos = start_pos\n\n        while pos < len(text):\n            if text[pos] == '(':\n                paren_count += 1\n\n            elif text[pos] == ')':\n                paren_count -= 1\n                if paren_count == 0:\n                    return pos\n\n            pos += 1\n\n        return -1\n\n    def _parse_url_and_title(self, url_title: str) -> Tuple[str, str | None]:\n        \"\"\"\n        Parse a URL string that may contain a title in quotes.\n\n        Args:\n            url_title: The string containing URL and optional title\n\n        Returns:\n            A tuple of (url, title) where title may be None\n        \"\"\"\n        # Look for title in quotes\n        title_match = re.search(r'\\s+[\\'\"](.+?)[\\'\"]$', url_title)\n        if title_match:\n            title = title_match.group(1)\n            url = url_title[:title_match.start()].strip()\n            return url, title\n\n        return url_title.strip(), None\n\n    def _parse_inline_formatting(self, text: str) -> List[MarkdownASTNode]:\n        \"\"\"\n        Parse inline formatting (bold, italic, inline code) in text and create appropriate AST nodes.\n\n        Args:\n            text: The text to parse\n\n        Returns:\n            A list of AST nodes representing the formatted text\n        \"\"\"\n        # Check if text has trailing line break\n        has_line_break = text.endswith('  ')\n        if has_line_break:\n            text = text[:-2]\n\n        # Simple state machine for inline formatting\n        i = 0\n        nodes: List[MarkdownASTNode] = []\n        current_text = \"\"\n\n        while i < len(text):\n            # Check for image (highest precedence due to the '!' prefix)\n            if text[i] == '!' and i + 1 < len(text) and text[i+1] == '[':\n                # Look for the closing '](' pattern\n                bracket_end = text.find('](', i + 2)\n                if bracket_end != -1:\n                    # Find closing parenthesis\n                    paren_end = self._find_closing_parenthesis(text, bracket_end + 2)\n                    if paren_end != -1:\n                        # Add any accumulated text before this image\n                        if current_text:\n                            nodes.append(MarkdownTextNode(current_text))\n                            current_text = \"\"\n\n                        # Extract the alt text and URL\n                        alt_text = text[i+2:bracket_end]\n                        url_title = text[bracket_end+2:paren_end]\n                        url, title = self._parse_url_and_title(url_title)\n\n                        # Create image node\n                        image_node = MarkdownImageNode(url, alt_text, title)\n                        nodes.append(image_node)\n\n                        # Move past the closing parenthesis\n                        i = paren_end + 1\n                        continue\n\n            # Check for link\n            elif text[i] == '[':\n                # Look for the closing '](' pattern\n                bracket_end = text.find('](', i + 1)\n                if bracket_end != -1:\n                    # Find closing parenthesis\n                    paren_end = self._find_closing_parenthesis(text, bracket_end + 2)\n                    if paren_end != -1:\n                        # Add any accumulated text before this link\n                        if current_text:\n                            nodes.append(MarkdownTextNode(current_text))\n                            current_text = \"\"\n\n                        # Extract the link text and URL\n                        link_text = text[i+1:bracket_end]\n                        url_title = text[bracket_end+2:paren_end]\n                        url, title = self._parse_url_and_title(url_title)\n\n                        # Create link node\n                        link_node = MarkdownLinkNode(url, title)\n\n                        # Process the content inside the link text recursively\n                        for child_node in self._parse_inline_formatting(link_text):\n                            link_node.add_child(child_node)\n\n                        nodes.append(link_node)\n\n                        # Move past the closing parenthesis\n                        i = paren_end + 1\n                        continue\n\n            # Check for inline code (high precedence)\n            elif text[i] == '`':\n                # Look for the closing backtick\n                end_pos = text.find('`', i + 1)\n                if end_pos != -1:\n                    # Add any accumulated text before this code block\n                    if current_text:\n                        nodes.append(MarkdownTextNode(current_text))\n                        current_text = \"\"\n\n                    # Extract the code content (excluding backticks)\n                    code_content = text[i+1:end_pos]\n                    nodes.append(MarkdownInlineCodeNode(code_content))\n\n                    # Move past the closing backtick\n                    i = end_pos + 1\n                    continue\n\n            # Check for bold formatting\n            elif (i + 1 < len(text) and\n                    ((text[i:i+2] == '**') or (text[i:i+2] == '__' and not self._no_underscores))):\n                # Determine which marker we're using\n                marker = text[i:i+2]\n\n                # Look for the closing marker\n                end_pos = text.find(marker, i + 2)\n                if end_pos != -1:\n                    # Add any accumulated text before this bold block\n                    if current_text:\n                        nodes.append(MarkdownTextNode(current_text))\n                        current_text = \"\"\n\n                    # Extract the bold content (excluding markers)\n                    bold_content = text[i+2:end_pos]\n\n                    # Create bold node and process its content recursively\n                    bold_node = MarkdownBoldNode()\n\n                    # Process the content inside the bold\n                    for child_node in self._parse_inline_formatting(bold_content):\n                        bold_node.add_child(child_node)\n\n                    nodes.append(bold_node)\n\n                    # Move past the closing marker\n                    i = end_pos + 2\n                    continue\n\n            # Check for italic formatting\n            elif (text[i] == '*' or (text[i] == '_' and not self._no_underscores)) and (\n                    i == 0 or text[i-1] != text[i]):\n                # Determine which marker we're using\n                marker = text[i]\n\n                # Look for the closing marker\n                end_pos = text.find(marker, i + 1)\n                if end_pos != -1 and (end_pos + 1 >= len(text) or text[end_pos+1] != marker):  # Avoid **\n                    # Add any accumulated text before this italic block\n                    if current_text:\n                        nodes.append(MarkdownTextNode(current_text))\n                        current_text = \"\"\n\n                    # Extract the italic content (excluding markers)\n                    italic_content = text[i+1:end_pos]\n\n                    # Create emphasis node and process its content recursively\n                    emphasis_node = MarkdownEmphasisNode()\n\n                    # Process the content inside the emphasis\n                    for child_node in self._parse_inline_formatting(italic_content):\n                        emphasis_node.add_child(child_node)\n\n                    nodes.append(emphasis_node)\n\n                    # Move past the closing marker\n                    i = end_pos + 1\n                    continue\n\n            # No formatting found, accumulate normal text\n            current_text += text[i]\n            i += 1\n\n        # Add any remaining accumulated text\n        if current_text:\n            nodes.append(MarkdownTextNode(current_text))\n\n        # Append a line break node if needed\n        if has_line_break:\n            nodes.append(MarkdownLineBreakNode())\n\n        return nodes\n\n    def _create_id_from_text(self, text: str) -> str:\n        \"\"\"\n        Create a simplified ID from text suitable for HTML anchor links.\n\n        Args:\n            text: The text to convert to an ID\n\n        Returns:\n            A simplified string suitable for use as an element ID\n        \"\"\"\n        # Convert to lowercase\n        text = text.lower()\n\n        # Replace spaces with hyphens\n        text = text.replace(' ', '-')\n\n        # Remove special characters\n        text = re.sub(r'[^a-z0-9-]', '', text)\n\n        # Ensure it doesn't start with a number\n        if text and text[0].isdigit():\n            text = 'h-' + text\n\n        return text\n\n    def _parse_heading(self, level: int, content: str, line_num: int) -> None:\n        \"\"\"\n        Parse a heading line and create a heading node.\n\n        Args:\n            level: The heading level (1-6)\n            content: The heading content\n            line_num: The line number\n        \"\"\"\n        anchor_id = self._create_id_from_text(content)\n\n        # Check if this ID already exists.  If it doesn't, then record we've seen it.   If it does,\n        # then add a suffix to it to make it unique.\n        if anchor_id not in self._used_header_ids:\n            self._used_header_ids[anchor_id] = 0\n\n        else:\n            # This ID already exists, increment the counter and append it\n            self._used_header_ids[anchor_id] += 1\n            anchor_id = f\"{anchor_id}-{self._used_header_ids[anchor_id]}\"\n\n        heading = MarkdownHeadingNode(level, anchor_id)\n        for node in self._parse_inline_formatting(content):\n            heading.add_child(node)\n\n        heading.line_start = line_num\n        heading.line_end = line_num\n        self._register_node_line(heading, line_num)\n\n        self._document.add_child(heading)\n\n    def _parse_text(self, text: str, line_num: int) -> MarkdownParagraphNode:\n        \"\"\"\n        Parse a text line and create a paragraph node.\n\n        Args:\n            text: The text content\n            line_num: The line number\n        \"\"\"\n        paragraph = MarkdownParagraphNode()\n        for node in self._parse_inline_formatting(text):\n            paragraph.add_child(node)\n\n        paragraph.line_start = line_num\n        paragraph.line_end = line_num\n        self._register_node_line(paragraph, line_num)\n\n        self._document.add_child(paragraph)\n        return paragraph\n\n    def _current_list_state(self) -> ListState | None:\n        \"\"\"\n        Return the current list state or None if not in a list.\n\n        Returns:\n            The current list state or None\n        \"\"\"\n        return self._list_stack[-1] if self._list_stack else None\n\n    def _close_lists_at_indent(self, indent: int, consider_marker: bool) -> bool:\n        \"\"\"\n        Close all lists deeper than the given indent level.\n\n        Args:\n            indent: The indentation level\n            consider_marker: Whether to consider the marker length for closing lists\n\n        Returns:\n            True if lists were closed, False otherwise\n        \"\"\"\n        if not self._list_stack:\n            return False\n\n        closed_lists = False\n\n        while self._list_stack:\n            marker_adjust = self._list_stack[-1].marker_length if consider_marker else 0\n            if (self._list_stack[-1].indent + marker_adjust) <= indent:\n                break\n\n            self._list_stack.pop()\n            closed_lists = True\n\n        return closed_lists\n\n    def _find_parent_for_list(self) -> MarkdownASTNode:\n        \"\"\"\n        Find the appropriate parent for a new list.\n\n        Returns:\n            The parent node\n        \"\"\"\n        if not self._list_stack:\n            return self._document\n\n        # Find the last list item of the deepest list to be the parent\n        current_list = self._list_stack[-1]\n        assert current_list.last_item is not None, \"Current list state should have a last item\"\n        return current_list.last_item\n\n    def _find_or_create_ordered_list(self, indent: int, start_number: int) -> MarkdownOrderedListNode:\n        \"\"\"\n        Find or create an ordered list at the given indent level with specified start number.\n\n        Args:\n            indent: The indentation level\n            start_number: The starting number\n\n        Returns:\n            The created ordered list node\n        \"\"\"\n        # Check if we already have an ordered list at this level\n        if self._list_stack and self._list_stack[-1].indent == indent:\n            list_state = self._list_stack[-1]\n            if isinstance(list_state.list_node, MarkdownOrderedListNode):\n                return list_state.list_node\n\n            # Different list type, close it\n            self._list_stack.pop()\n\n        # Find parent\n        parent = self._find_parent_for_list()\n\n        # Create new ordered list\n        new_list = MarkdownOrderedListNode(indent, start_number)\n        parent.add_child(new_list)\n\n        # Create and add list state\n        list_state = ListState(new_list, indent)\n        self._list_stack.append(list_state)\n\n        return new_list\n\n    def _parse_ordered_list_item(self, indent: int, number: str, content: str, line_num: int) -> None:\n        \"\"\"\n        Parse an ordered list item and create a list item node.\n\n        Args:\n            indent: The indentation level\n            number: The list item number (as a string)\n            content: The item content\n            line_num: The line number\n        \"\"\"\n        # Extract the starting number\n        start_number = int(number)\n\n        # Close deeper lists\n        self._close_lists_at_indent(indent, False)\n\n        # If we're in a list, and we've seen a blank line, then mark the list as loose\n        if self._list_stack and self._blank_line_count > 0:\n            self._list_stack[-1].contains_blank_line = True\n            self._list_stack[-1].list_node.tight = False\n\n        list_node = self._find_or_create_ordered_list(indent, start_number)\n        current_list = cast(ListState, self._current_list_state())\n\n        # Create the list item\n        item = MarkdownListItemNode()\n        list_node.add_child(item)\n\n        # Calculate the actual content indentation for this specific marker\n        current_list.marker_length = len(number) + 2  # +2 for the \".\" and space after number\n\n        # Create a paragraph for the content\n        paragraph = MarkdownParagraphNode()\n        for node in self._parse_inline_formatting(content):\n            paragraph.add_child(node)\n\n        paragraph.line_start = line_num\n        paragraph.line_end = line_num\n        item.add_child(paragraph)\n        self._register_node_line(paragraph, line_num)\n\n        item.line_start = line_num\n        item.line_end = line_num\n        self._register_node_line(item, line_num)\n\n        # Update tracking variables\n        current_list.last_item = item\n        self._last_processed_line_type = 'ordered_list_item'\n\n    def _find_or_create_unordered_list(self, indent: int) -> MarkdownUnorderedListNode:\n        \"\"\"\n        Find or create an unordered list at the given indent level.\n\n        Args:\n            indent: The indentation level\n\n        Returns:\n            The created unordered list node\n        \"\"\"\n        # Check if we already have an unordered list at this level\n        if self._list_stack and self._list_stack[-1].indent == indent:\n            list_state = self._list_stack[-1]\n            if isinstance(list_state.list_node, MarkdownUnorderedListNode):\n                return list_state.list_node\n\n            # Different list type, close it\n            self._list_stack.pop()\n\n        # Find parent\n        parent = self._find_parent_for_list()\n\n        # Create new unordered list\n        new_list = MarkdownUnorderedListNode(indent)\n        parent.add_child(new_list)\n\n        # Create and add list state\n        list_state = ListState(new_list, indent)\n        self._list_stack.append(list_state)\n\n        return new_list\n\n    def _parse_unordered_list_item(self, indent: int, marker: str, content: str, line_num: int) -> None:\n        \"\"\"\n        Parse an unordered list item and create a list item node.\n\n        Args:\n            indent: The indentation level\n            marker: The bullet marker (-, *, +)\n            content: The item content\n            line_num: The line number\n        \"\"\"\n        # Close deeper lists\n        self._close_lists_at_indent(indent, False)\n\n        # If we're in a list, and we've seen a blank line, then mark the list as loose\n        if self._list_stack and self._blank_line_count > 0:\n            self._list_stack[-1].contains_blank_line = True\n            self._list_stack[-1].list_node.tight = False\n\n        list_node = self._find_or_create_unordered_list(indent)\n        current_list = cast(ListState, self._current_list_state())\n\n        # Create the list item\n        item = MarkdownListItemNode()\n        list_node.add_child(item)\n\n        # Calculate the actual content indentation for this specific marker\n        current_list.marker_length = len(marker) + 1  # +1 for the space after marker\n\n        # Create a paragraph for the content\n        paragraph = MarkdownParagraphNode()\n        for node in self._parse_inline_formatting(content):\n            paragraph.add_child(node)\n\n        paragraph.line_start = line_num\n        paragraph.line_end = line_num\n        item.add_child(paragraph)\n        self._register_node_line(paragraph, line_num)\n\n        item.line_start = line_num\n        item.line_end = line_num\n        self._register_node_line(item, line_num)\n\n        # Update tracking variables\n        current_list.last_item = item\n        self._last_processed_line_type = 'unordered_list_item'\n\n    def _parse_horizontal_rule(self, line_num: int) -> MarkdownHorizontalRuleNode:\n        \"\"\"\n        Parse a horizontal rule line and create a horizontal rule node.\n\n        Args:\n            line_num: The line number\n\n        Returns:\n            A horizontal rule node\n        \"\"\"\n        horizontal_rule = MarkdownHorizontalRuleNode()\n        horizontal_rule.line_start = line_num\n        horizontal_rule.line_end = line_num\n        self._register_node_line(horizontal_rule, line_num)\n\n        return horizontal_rule\n\n    def _parse_table_separator(self, separator_line: str) -> List[str]:\n        \"\"\"\n        Parse a table separator line to determine column alignments.\n\n        Args:\n            separator_line: A line containing the table column separators (e.g., |---|:---:|--:|)\n\n        Returns:\n            List of alignment strings ('left', 'center', 'right') for each column\n        \"\"\"\n        cells = [cell.strip() for cell in separator_line.split('|')[1:-1]]\n        alignments = []\n\n        for cell in cells:\n            if cell.startswith(':') and cell.endswith(':'):\n                alignments.append('center')\n\n            elif cell.endswith(':'):\n                alignments.append('right')\n\n            else:\n                alignments.append('left')\n\n        return alignments\n\n    def _handle_table_row(self, line: str, line_num: int) -> None:\n        \"\"\"\n        Handle a table row line in the parsing process.\n\n        Args:\n            line: The table row line\n            line_num: The line number\n\n        Returns:\n            None\n        \"\"\"\n        # Is this a body row?\n        if self._table_buffer.is_confirmed_table:\n            cells = [cell.strip() for cell in line.split('|')[1:-1]]\n            self._table_buffer.body_rows.append(cells)\n            self._table_buffer.current_line = line_num\n            return\n\n        # Is this another header row?  If yes, we can't have two, so emit the last one as text\n        if self._table_buffer.is_in_potential_table:\n            self._parse_text(self._table_buffer.header_line, self._table_buffer.start_line)\n\n        else:\n            self._table_buffer.is_in_potential_table = True\n            self._table_buffer.start_line = line_num\n\n        cells = [cell.strip() for cell in line.split('|')[1:-1]]\n        self._table_buffer.header_row = cells\n        self._table_buffer.header_line = line\n        self._table_buffer.current_line = line_num\n\n    def _handle_table_separator(self, line: str, line_num: int) -> None:\n        \"\"\"\n        Handle a table separator line in the parsing process.\n\n        Args:\n            line: The table separator line\n            line_num: The line number\n\n        Returns:\n            None\n        \"\"\"\n        # If we're not already in a potential table, ignore it\n        if not self._table_buffer.is_in_potential_table:\n            # Treat as normal text\n            self._parse_text(line, line_num)\n            return\n\n        # Store the separator row\n        cells = [cell.strip() for cell in line.split('|')[1:-1]]\n        self._table_buffer.separator_row = cells\n        self._table_buffer.separator_line = line\n\n        # Parse alignments\n        self._table_buffer.alignments = self._parse_table_separator(line)\n        self._table_buffer.current_line = line_num\n\n        # Mark as a confirmed table now that we have a separator\n        self._table_buffer.is_confirmed_table = True\n\n    def _create_table_from_buffer(self) -> None:\n        \"\"\"\n        Create a table node from the buffered content.\n\n        Returns:\n            None\n        \"\"\"\n        # Create the table structure\n        table_node = MarkdownTableNode()\n        header_node = MarkdownTableHeaderNode()\n        body_node = MarkdownTableBodyNode()\n\n        # Set line information\n        table_node.line_start = self._table_buffer.start_line\n        table_node.line_end = self._table_buffer.current_line\n        header_node.line_start = self._table_buffer.start_line\n\n        # Add header and body to table\n        table_node.add_child(header_node)\n        table_node.add_child(body_node)\n\n        # Process header rows\n        row_node = MarkdownTableRowNode()\n        row_line = self._table_buffer.start_line\n        row_node.line_start = row_line\n        row_node.line_end = row_line\n\n        for j, cell_content in enumerate(self._table_buffer.header_row):\n            # Determine alignment\n            alignment = 'left'\n            if j < len(self._table_buffer.alignments):\n                alignment = self._table_buffer.alignments[j]\n\n            # Create cell\n            cell_node = MarkdownTableCellNode(is_header=True, alignment=alignment)\n\n            # Add content to cell\n            for text_node in self._parse_inline_formatting(cell_content):\n                cell_node.add_child(text_node)\n\n            row_node.add_child(cell_node)\n\n        header_node.add_child(row_node)\n        self._register_node_line(row_node, row_line)\n\n        # Set header end line\n        header_node.line_end = self._table_buffer.start_line\n\n        # Process body rows\n        body_start_line = self._table_buffer.start_line + 1\n        body_node.line_start = body_start_line\n\n        for i, row_cells in enumerate(self._table_buffer.body_rows):\n            row_node = MarkdownTableRowNode()\n            row_line = body_start_line + i\n            row_node.line_start = row_line\n            row_node.line_end = row_line\n\n            for j, cell_content in enumerate(row_cells):\n                # Determine alignment\n                alignment = 'left'\n                if j < len(self._table_buffer.alignments):\n                    alignment = self._table_buffer.alignments[j]\n\n                # Create cell\n                cell_node = MarkdownTableCellNode(is_header=False, alignment=alignment)\n\n                # Add content to cell\n                for text_node in self._parse_inline_formatting(cell_content):\n                    cell_node.add_child(text_node)\n\n                row_node.add_child(cell_node)\n\n            body_node.add_child(row_node)\n            self._register_node_line(row_node, row_line)\n\n        body_node.line_end = self._table_buffer.current_line\n\n        # Add the table to the document\n        self._document.add_child(table_node)\n\n        # Register table with line mappings\n        for i in range(self._table_buffer.start_line, self._table_buffer.current_line + 1):\n            self._register_node_line(table_node, i)\n\n        # Reset table buffer\n        self._table_buffer.reset()\n\n    def _handle_incomplete_table(self) -> None:\n        \"\"\"\n        Handle buffered table content that doesn't form a complete table.\n        Convert it to regular paragraphs.\n\n        Returns:\n            None\n        \"\"\"\n        # Render header rows as regular text\n        self._parse_text(self._table_buffer.header_line, self._table_buffer.start_line)\n\n        # Handle separator if present\n        if self._table_buffer.separator_row:\n            self._parse_text(self._table_buffer.separator_line, self._table_buffer.start_line + 1)\n\n        # Reset table buffer\n        self._table_buffer.reset()\n\n    def _register_node_line(self, node: MarkdownASTNode, line_num: int) -> None:\n        \"\"\"\n        Register a node with a line number for later reference.\n\n        Args:\n            node: The AST node\n            line_num: The line number\n\n        Returns:\n            None\n        \"\"\"\n        if line_num not in self._line_to_node_map:\n            self._line_to_node_map[line_num] = []\n\n        self._line_to_node_map[line_num].append(node)\n\n    def _finalize_code_block(self, end_line: int) -> None:\n        \"\"\"\n        Finalize a code block that might be unclosed at document end.\n\n        Args:\n            end_line: The last line number in the document\n\n        Returns:\n            None\n        \"\"\"\n        # Create a code block node for the unclosed block\n        code_block = MarkdownCodeBlockNode(\n            language=self._code_block_language,\n            content='\\n'.join(self._code_block_content)\n        )\n        code_block.line_start = self._code_block_start_line\n        code_block.line_end = end_line\n\n        # Add to document\n        self._document.add_child(code_block)\n\n        # Register code block with all lines it spans\n        for i in range(self._code_block_start_line, end_line + 1):\n            self._register_node_line(code_block, i)\n\n        # Reset code block state\n        self._in_code_block = False\n        self._code_block_language = \"\"\n        self._code_block_content = []\n        self._code_block_start_line = -1\n        self._code_block_nesting_level = 0\n        self._code_block_indents = []\n        self._embedded_parser_state = None\n        self._embedded_language = ProgrammingLanguage.UNKNOWN\n\n    def _handle_text_continuation(self, text: str, line_num: int) -> bool:\n        \"\"\"\n        Handle text as a continuation of the previous paragraph or list item.\n        A text line is a continuation of a list item if it is indented\n        by at least the same amount as the list item's content indent.\n\n        Args:\n            text: The text content\n            line_num: The line number\n\n        Returns:\n            True if handled as a continuation, False otherwise\n        \"\"\"\n        # Case 1: Continue a paragraph\n        if self._last_paragraph and self._last_processed_line_type == 'text':\n            # Add a space between the continued text as long as we didn't just have a line break\n            if not isinstance(self._last_paragraph.children[-1], MarkdownLineBreakNode):\n                self._last_paragraph.add_child(MarkdownTextNode(\" \"))\n\n            for node in self._parse_inline_formatting(text):\n                self._last_paragraph.add_child(node)\n\n            self._last_paragraph.line_end = line_num\n            self._register_node_line(self._last_paragraph, line_num)\n            return True\n\n        # Case 2: Continue a list item paragraph\n        if self._list_stack and self._last_processed_line_type in ('unordered_list_item', 'ordered_list_item', 'blank', 'text'):\n            # Get the indentation of the current line\n            current_indent = len(text) - len(text.lstrip())\n\n            if self._close_lists_at_indent(current_indent, True):\n                # We closed one or more lists, we should treat it as if a blank line was encountered\n                # This will ensure proper formatting when returning to an outer list\n                if self._list_stack:\n                    self._last_processed_line_type = 'blank'\n                    self._blank_line_count = 1\n\n                # Reset the paragraph continuity as well\n                self._last_paragraph = None\n\n            # If we're continuing a list item and we've seen a blank line, mark the list as loose\n            if self._list_stack and self._blank_line_count > 0:\n                self._list_stack[-1].contains_blank_line = True\n                self._list_stack[-1].list_node.tight = False\n\n            list_state = self._current_list_state()\n            if not list_state or not list_state.last_item:\n                return False\n\n            formatted_text = text.lstrip()\n\n            # Find the paragraph within the last list item and continue it\n            last_item = list_state.last_item\n            paragraph = cast(MarkdownParagraphNode, last_item.children[-1])\n\n            # If we weren't just preceded by a line break then add a space\n            if paragraph.children and not isinstance(paragraph.children[-1], MarkdownLineBreakNode):\n                paragraph.add_child(MarkdownTextNode(\" \"))\n\n            for node in self._parse_inline_formatting(formatted_text):\n                paragraph.add_child(node)\n\n            paragraph.line_end = line_num\n            self._register_node_line(paragraph, line_num)\n\n            last_item.line_end = line_num\n            self._register_node_line(last_item, line_num)\n            return True\n\n        return False\n\n    def _reset_list_state(self) -> None:\n        \"\"\"Reset all list tracking state.\"\"\"\n        self._list_stack = []\n\n    def _parse_line(self, line: str, line_num: int) -> None:\n        \"\"\"\n        Parse a single line and add the resulting nodes to the AST.\n\n        Args:\n            line: The line to parse\n            line_num: The line number\n\n        Returns:\n            None\n        \"\"\"\n        line_type, content = self.identify_line_type(line)\n\n        # Reset paragraph tracking if not continuing text\n        if line_type not in ('text', 'blank', 'line_break'):\n            self._last_paragraph = None\n\n        # Handle table ends when a non-table line is encountered\n        if self._table_buffer.is_in_potential_table and line_type not in ('table_row', 'table_separator'):\n            # Check if we have a complete table to create\n            if self._table_buffer.is_valid_table():\n                self._create_table_from_buffer()\n\n            else:\n                # Not a valid table, render as regular text\n                self._handle_incomplete_table()\n\n        if line_type == 'line_break':\n            self._document.add_child(MarkdownLineBreakNode())\n            return\n\n        if line_type == 'blank':\n            self._blank_line_count += 1\n            self._last_processed_line_type = line_type\n            return\n\n        if line_type == 'unordered_list_item':\n            indent, marker, text = content\n            self._parse_unordered_list_item(indent, marker, text, line_num)\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        if line_type == 'ordered_list_item':\n            indent, number, text = content\n            self._parse_ordered_list_item(indent, number, text, line_num)\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        if line_type == 'code_block_start':\n            self._in_code_block = True\n            self._code_block_language = content\n            self._code_block_content = []\n            self._code_block_start_line = line_num\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        if line_type == 'code_block_content':\n            self._code_block_content.append(content)\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        if line_type == 'code_block_end':\n            self._finalize_code_block(line_num)\n            self._reset_list_state()\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        # Handle table-related lines\n        if line_type == 'table_row':\n            self._handle_table_row(content, line_num)\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        if line_type == 'table_separator':\n            self._handle_table_separator(content, line_num)\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        # Process other line types\n        if line_type == 'heading':\n            level, heading_text = content\n            self._parse_heading(level, heading_text, line_num)\n            self._reset_list_state()\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        if line_type == 'horizontal_rule':\n            horizontal_rule = self._parse_horizontal_rule(line_num)\n            self._document.add_child(horizontal_rule)\n            self._reset_list_state()\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        # We have text left\n        # Try to handle as a continuation first\n        if self._handle_text_continuation(content, line_num):\n            self._last_processed_line_type = line_type\n            return\n\n        # Regular paragraph\n        paragraph = self._parse_text(content, line_num)\n        self._last_paragraph = paragraph\n        self._reset_list_state()\n        self._last_processed_line_type = line_type\n        self._blank_line_count = 0\n\n    def build_ast(self, text: str) -> MarkdownDocumentNode:\n        \"\"\"\n        Build a complete AST from the given text.\n\n        Args:\n            text: The markdown text to parse\n\n        Returns:\n            The document root node\n        \"\"\"\n        self._document = MarkdownDocumentNode(self._source_path)\n        self._line_to_node_map = {}\n        self._reset_list_state()\n        self._last_paragraph = None\n        self._last_processed_line_type = \"\"\n        self._blank_line_count = 0\n        self._in_code_block = False\n        self._code_block_language = \"\"\n        self._code_block_content = []\n        self._code_block_start_line = -1\n        self._code_block_nesting_level = 0\n        self._code_block_indents = []\n\n        # Reset table buffer\n        self._table_buffer.reset()\n\n        # Parse line by line\n        lines = text.split('\\n')\n        for i, line in enumerate(lines):\n            self._parse_line(line, i)\n\n        # Check for any buffered table content at the end of the document\n        if self._table_buffer.is_in_potential_table:\n            if self._table_buffer.is_valid_table():\n                self._create_table_from_buffer()\n\n            else:\n                self._handle_incomplete_table()\n\n        # Handle case where document ends while still in a code block\n        if self._in_code_block:\n            self._finalize_code_block(len(lines) - 1)\n\n        return self._document\n\n    def update_ast(self, text: str, previous_text: str, path: str | None = None) -> MarkdownDocumentNode:\n        \"\"\"\n        Update the AST incrementally based on changes between previous_text and text.\n\n        Args:\n            text: The new markdown text\n            previous_text: The previous markdown text, or None if this is the first update\n            path: Optional path to the source markdown file\n\n        Returns:\n            The updated document root node\n        \"\"\"\n        self._source_path = path\n        if previous_text is None or not self._document.children:\n            # First update or empty document, build from scratch\n            return self.build_ast(text)\n\n        # Split into lines\n        new_lines = text.split('\\n')\n        old_lines = previous_text.split('\\n')\n\n        # Find common prefix length (unchanged lines)\n        common_prefix_len = 0\n        for i, (old, new) in enumerate(zip(old_lines, new_lines)):\n            if old == new:\n                common_prefix_len = i + 1\n\n            else:\n                break\n\n        # Find common suffix length (unchanged lines from the end)\n        common_suffix_len = 0\n        for i, (old, new) in enumerate(zip(reversed(old_lines), reversed(new_lines))):\n            if old == new and common_prefix_len + common_suffix_len < min(len(old_lines), len(new_lines)):\n                common_suffix_len = i + 1\n\n            else:\n                break\n\n        # Calculate changed region\n        start = common_prefix_len\n        old_end = len(old_lines) - common_suffix_len\n        new_end = len(new_lines) - common_suffix_len\n\n        # If nothing changed, return existing document\n        if start >= old_end and start >= new_end:\n            return self._document\n\n        # For now, just rebuild the entire AST\n        # In the future we might implement incremental updates\n        return self.build_ast(text)\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/markdown/markdown_ast_printer.py\n\n```python\n\"\"\"\nVisitor class to print markdown AST structures for debugging\n\"\"\"\nfrom typing import List, Any, cast\n\nfrom humbug.ast.ast import ASTNode\nfrom humbug.markdown.markdown_ast_node import (\n    MarkdownASTVisitor, MarkdownTextNode, MarkdownHeadingNode, MarkdownInlineCodeNode,\n    MarkdownCodeBlockNode, MarkdownASTNode, MarkdownTableNode, MarkdownTableHeaderNode,\n    MarkdownTableBodyNode, MarkdownTableRowNode, MarkdownTableCellNode, MarkdownHorizontalRuleNode,\n    MarkdownLinkNode, MarkdownImageNode\n)\n\n\nclass MarkdownASTPrinter(MarkdownASTVisitor):\n    \"\"\"Visitor that prints the AST structure for debugging.\"\"\"\n    def __init__(self) -> None:\n        \"\"\"Initialize the AST printer with zero indentation.\"\"\"\n        super().__init__()\n        self.indent_level = 0\n\n    def _indent(self) -> str:\n        \"\"\"\n        Get the current indentation string.\n\n        Returns:\n            A string of spaces for the current indentation level\n        \"\"\"\n        return \"  \" * self.indent_level\n\n    def generic_visit(self, node: ASTNode) -> List[Any]:\n        \"\"\"\n        Default visit method that prints the node type.\n\n        Args:\n            node: The node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        ast_node = cast(MarkdownASTNode, node)\n        node_name = node.__class__.__name__\n        line_range = \"\"\n        if ast_node.line_start is not None and ast_node.line_end is not None:\n            line_range = f\" (lines {ast_node.line_start}-{ast_node.line_end})\"\n\n        print(f\"{self._indent()}{node_name}{line_range}\")\n        self.indent_level += 1\n        results = super().generic_visit(ast_node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownTextNode(self, node: MarkdownTextNode) -> str:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a text node and print its content.\n\n        Args:\n            node: The text node to visit\n\n        Returns:\n            The text content\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None:\n            line_range = f\" (line {node.line_start})\"\n\n        print(f\"{self._indent()}Text{line_range}: '{node.content}'\")\n        return node.content\n\n    def visit_MarkdownHeadingNode(self, node: MarkdownHeadingNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a heading node and print its level.\n\n        Args:\n            node: The heading node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None:\n            line_range = f\" (line {node.line_start})\"\n\n        print(f\"{self._indent()}Heading (level {node.level}){line_range}\")\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownInlineCodeNode(self, node: MarkdownInlineCodeNode) -> str:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit an inline code node and print its content.\n\n        Args:\n            node: The inline code node to visit\n\n        Returns:\n            The inline code content\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None:\n            line_range = f\" (line {node.line_start})\"\n\n        print(f\"{self._indent()}InlineCode{line_range}: '{node.content}'\")\n        return node.content\n\n    def visit_MarkdownLinkNode(self, node: MarkdownLinkNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a link node and print its URL and title.\n\n        Args:\n            node: The link node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None and node.line_end is not None:\n            line_range = f\" (lines {node.line_start}-{node.line_end})\"\n\n        title_info = f\", title='{node.title}'\" if node.title else \"\"\n        print(f\"{self._indent()}Link{line_range}: url='{node.url}'{title_info}\")\n\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownImageNode(self, node: MarkdownImageNode) -> str:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit an image node and print its URL, alt text, and title.\n\n        Args:\n            node: The image node to visit\n\n        Returns:\n            The image URL\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None and node.line_end is not None:\n            line_range = f\" (lines {node.line_start}-{node.line_end})\"\n\n        title_info = f\", title='{node.title}'\" if node.title else \"\"\n        print(f\"{self._indent()}Image{line_range}: url='{node.url}', alt='{node.alt_text}'{title_info}\")\n        return node.url\n\n    def visit_MarkdownCodeBlockNode(self, node: MarkdownCodeBlockNode) -> str:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a code block node and print its language and content.\n\n        Args:\n            node: The code block node to visit\n\n        Returns:\n            The code block content\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None and node.line_end is not None:\n            line_range = f\" (lines {node.line_start}-{node.line_end})\"\n\n        print(f\"{self._indent()}CodeBlock{line_range}: language='{node.language}'\")\n        self.indent_level += 1\n        print(f\"{self._indent()}Content: '{node.content[:30]}...' ({len(node.content)} chars)\")\n        self.indent_level -= 1\n        return node.content\n\n    def visit_MarkdownTableNode(self, node: MarkdownTableNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a table node and print its structure.\n\n        Args:\n            node: The table node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None and node.line_end is not None:\n            line_range = f\" (lines {node.line_start}-{node.line_end})\"\n\n        print(f\"{self._indent()}Table{line_range}\")\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownTableHeaderNode(self, node: MarkdownTableHeaderNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a table header node and print its info.\n\n        Args:\n            node: The table header node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        print(f\"{self._indent()}TableHeader\")\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownTableBodyNode(self, node: MarkdownTableBodyNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a table body node and print its info.\n\n        Args:\n            node: The table body node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        print(f\"{self._indent()}TableBody\")\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownTableRowNode(self, node: MarkdownTableRowNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a table row node and print its info.\n\n        Args:\n            node: The table row node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None and node.line_end is not None:\n            line_range = f\" (lines {node.line_start}-{node.line_end})\"\n\n        print(f\"{self._indent()}TableRow{line_range}\")\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownTableCellNode(self, node: MarkdownTableCellNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a table cell node and print its properties.\n\n        Args:\n            node: The table cell node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        cell_type = \"HeaderCell\" if node.is_header else \"Cell\"\n        print(f\"{self._indent()}{cell_type} (alignment: {node.alignment})\")\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownHorizontalRuleNode(self, node: MarkdownHorizontalRuleNode) -> None:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a horizontal rule node and print its details.\n\n        Args:\n            node: The horizontal rule node to visit\n\n        Returns:\n            None\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None:\n            line_range = f\" (line {node.line_start})\"\n\n        print(f\"{self._indent()}HorizontalRule{line_range}\")\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/syntax/programming_language.py\n\n```python\nfrom enum import IntEnum, auto\n\n\nclass ProgrammingLanguage(IntEnum):\n    \"\"\"Programming language enum.\"\"\"\n    UNKNOWN = -1\n    C = auto()\n    CPP = auto()\n    CSHARP = auto()\n    CSS = auto()\n    GO = auto()\n    HTML = auto()\n    JAVA = auto()\n    JAVASCRIPT = auto()\n    JSON = auto()\n    KOTLIN = auto()\n    MARKDOWN = auto()\n    METAPHOR = auto()\n    MOVE = auto()\n    PYTHON = auto()\n    RUST = auto()\n    SCHEME = auto()\n    SOLIDITY = auto()\n    SWIFT = auto()\n    TEXT = auto()\n    TYPESCRIPT = auto()\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/syntax/lexer.py\n\n```python\nfrom abc import ABC, abstractmethod\nfrom dataclasses import dataclass\nfrom enum import IntEnum, auto\nfrom typing import List, Callable, Set, ClassVar, Dict\n\n\nclass TokenType(IntEnum):\n    \"\"\"Type of lexical token.\"\"\"\n    ADDRESS = auto()\n    ANNOTATION = auto()\n    ARGUMENT = auto()\n    ATTRIBUTE = auto()\n    BACKTICK = auto()\n    BLOCKQUOTE = auto()\n    BOLD = auto()\n    BOLD_END = auto()\n    BOLD_START = auto()\n    BOOLEAN = auto()\n    CHARACTER = auto()\n    CODE = auto()\n    COMMAND = auto()\n    COMMENT = auto()\n    CSS_AT_RULE = auto()\n    DIMENSION = auto()\n    DIRECTIVE = auto()\n    DOC_COMMENT = auto()\n    DOCTYPE = auto()\n    DOT = auto()\n    ELEMENT = auto()\n    ERROR = auto()\n    FENCE = auto()\n    FENCE_END = auto()\n    FENCE_START = auto()\n    FUNCTION_OR_METHOD = auto()\n    GENERIC_END = auto()\n    GENERIC_METHOD = auto()\n    GENERIC_START = auto()\n    GENERIC_TYPE = auto()\n    HASH = auto()\n    HEADING = auto()\n    HEX = auto()\n    HORIZONTAL_RULE = auto()\n    HTML_ATTRIBUTE = auto()\n    HTML_TAG = auto()\n    IDENTIFIER = auto()\n    IMAGE_ALT_END = auto()\n    IMAGE_ALT_TEXT = auto()\n    IMAGE_END = auto()\n    IMAGE_START = auto()\n    IMAGE_URL = auto()\n    INLINE_CODE = auto()\n    INLINE_CODE_END = auto()\n    INLINE_CODE_START = auto()\n    ITALIC = auto()\n    ITALIC_END = auto()\n    ITALIC_START = auto()\n    KEYWORD = auto()\n    LANGUAGE = auto()\n    LIFETIME = auto()\n    LINK_END = auto()\n    LINK_START = auto()\n    LINK_TEXT = auto()\n    LINK_TEXT_END = auto()\n    LINK_URL = auto()\n    LINQ_KEYWORD = auto()\n    LIST_MARKER = auto()\n    LPAREN = auto()\n    METHOD_REFERENCE_OPERATOR = auto()\n    NUMBER = auto()\n    OPERATOR = auto()\n    OPTION = auto()\n    OPTION_VALUE = auto()\n    PREPROCESSOR = auto()\n    REGEXP = auto()\n    RPAREN = auto()\n    RUNE = auto()\n    SCRIPT = auto()\n    STRING = auto()\n    STYLE = auto()\n    TABLE = auto()\n    TEXT = auto()\n    TYPE = auto()\n    TYPE_PARAMETER = auto()\n    VECTOR_START = auto()\n    XML_DOC = auto()\n\n@dataclass\nclass Token:\n    \"\"\"\n    Represents a token in the input stream.\n\n    Attributes:\n        type: The type of the token\n        value: The string value of the token\n        start: The starting position of the token in the input stream\n    \"\"\"\n    type: TokenType\n    value: str\n    start: int\n\n\n@dataclass\nclass LexerState:\n    \"\"\"\n    State information for the Lexer.\n    \"\"\"\n\n\nclass Lexer(ABC):\n    \"\"\"\n    Base lexer class with optimized implementation.\n\n    Key optimizations:\n    - Character lookup via sets instead of range comparisons\n    - Common character classification pre-computation\n    - Static lookup tables shared across instances\n    - Optimized token handling\n    \"\"\"\n\n    # Character lookup tables - shared by all subclasses\n    _WHITESPACE_CHARS: ClassVar[Set[str]] = set(\" \\t\\r\\v\\f\\u00A0\\u1680\\u2028\\u2029\\u202F\\u205F\\u3000\")\n    _LETTER_CHARS: ClassVar[Set[str]] = set(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n    _LETTER_DIGIT_CHARS: ClassVar[Set[str]] = set(\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n    _LETTER_DIGIT_UNDERSCORE_CHARS: ClassVar[Set[str]] = set(\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_\")\n    _DIGIT_CHARS: ClassVar[Set[str]] = set(\"0123456789\")\n    _HEX_CHARS: ClassVar[Set[str]] = set(\"0123456789abcdefABCDEF\")\n    _BINARY_CHARS: ClassVar[Set[str]] = set(\"01\")\n    _OCTAL_CHARS: ClassVar[Set[str]] = set(\"01234567\")\n\n    # Add the Unicode whitespace range \\u2000-\\u200A\n    for i in range(0x2000, 0x200B):\n        _WHITESPACE_CHARS.add(chr(i))\n\n    # Default empty operator map - to be overridden by subclasses\n    _OPERATORS: ClassVar[List[str]] = []\n    _OPERATORS_MAP: ClassVar[Dict[str, List[str]]] = {}\n\n    def __init__(self) -> None:\n        self._input: str = \"\"\n        self._input_len: int = 0\n        self._position: int = 0\n        self._tokens: List[Token] = []\n        self._next_token: int = 0\n\n    @abstractmethod\n    def _get_lexing_function(self, ch: str) -> Callable[[], None]:\n        \"\"\"\n        Get the lexing function that matches a given start character.\n\n        Args:\n            ch: The start character\n\n        Returns:\n            The appropriate lexing function for the character\n        \"\"\"\n\n    @abstractmethod\n    def lex(self, prev_lexer_state: LexerState | None, input_str: str) -> LexerState | None:\n        \"\"\"\n        Parse the input string\n\n        Args:\n            prev_lexer_state: The previous lexer state, if any\n            input_str: The input string to lex\n\n        Returns:\n            The updated lexer state\n        \"\"\"\n\n    def _inner_lex(self) -> None:\n        \"\"\"\n        Lex all the tokens in the input.\n        \"\"\"\n        while self._position < self._input_len:\n            ch = self._input[self._position]\n            self._get_lexing_function(ch)()\n\n    def get_next_token(self) -> Token | None:\n        \"\"\"\n        Gets the next token from the input.\n\n        Returns:\n            The next Token available or None if there are no tokens left.\n        \"\"\"\n        if self._next_token >= len(self._tokens):\n            return None\n\n        token = self._tokens[self._next_token]\n        self._next_token += 1\n        return token\n\n    def peek_next_token(self, offset: int = 0) -> Token | None:\n        \"\"\"\n        Get the token that is 'offset' positions ahead.\n\n        Args:\n            offset: How many non-filtered tokens to look ahead (default 0)\n\n        Returns:\n            The token at the specified offset, or None if none found\n        \"\"\"\n        current_token_index = self._next_token\n        skipped = 0\n        token = None\n\n        while skipped <= offset:\n            token = self.get_next_token()\n            if not token:\n                break\n\n            skipped += 1\n\n        self._next_token = current_token_index\n        return token\n\n    def _read_string(self) -> None:\n        \"\"\"\n        Reads a string token.\n        \"\"\"\n        quote = self._input[self._position]\n        start = self._position\n        self._position += 1\n\n        while self._position < self._input_len and self._input[self._position] != quote:\n            if self._input[self._position] == '\\\\' and (self._position + 1) < self._input_len:\n                self._position += 1  # Skip the escape character\n\n            self._position += 1\n\n        if self._position < self._input_len:  # Skip the closing quote if found\n            self._position += 1\n\n        string_value = self._input[start:self._position]\n        self._tokens.append(Token(type=TokenType.STRING, value=string_value, start=start))\n\n    def _read_whitespace(self) -> None:\n        \"\"\"\n        Reads whitespace in the input.\n        \"\"\"\n        self._position += 1\n\n        # Fast path using set-based character classification\n        while self._position < self._input_len and self._input[self._position] in self._WHITESPACE_CHARS:\n            self._position += 1\n\n    def _read_operator(self) -> None:\n        \"\"\"\n        Generic implementation of operator reading using the operator map.\n\n        The operator map should be a dictionary where:\n        - Keys are the first characters of operators\n        - Values are lists of operators starting with that character,\n          ordered from longest to shortest to ensure greedy matching\n        \"\"\"\n        first_char = self._input[self._position]\n        potential_operators = self._OPERATORS_MAP.get(first_char, [])\n\n        # Try to match the longest operator first\n        for op in potential_operators:\n            if self._input[self._position:].startswith(op):\n                start = self._position\n                self._position += len(op)\n                self._tokens.append(Token(\n                    type=TokenType.OPERATOR,\n                    value=op,\n                    start=start\n                ))\n                return\n\n        # If no operator matched, it's an error or a single character\n        start = self._position\n        ch = self._input[self._position]\n        self._position += 1\n        self._tokens.append(Token(type=TokenType.ERROR, value=ch, start=start))\n\n    @staticmethod\n    def build_operator_map(operators: List[str]) -> Dict[str, List[str]]:\n        \"\"\"\n        Build an operator map from a list of operators.\n\n        Args:\n            operators: List of operator strings\n\n        Returns:\n            A dictionary mapping first characters to lists of operators\n            starting with that character, sorted by length (longest first)\n        \"\"\"\n        operator_map: Dict[str, List[str]] = {}\n        for op in operators:\n            if not op:\n                continue\n\n            first_char = op[0]\n            if first_char not in operator_map:\n                operator_map[first_char] = []\n\n            operator_map[first_char].append(op)\n\n        # Sort each list by length, longest first to ensure greedy matching\n        for _first_char, operators_list in operator_map.items():\n            operators_list.sort(key=len, reverse=True)\n\n        return operator_map\n\n    def _is_letter(self, ch: str) -> bool:\n        \"\"\"\n        Determines if a character is a letter.\n        \"\"\"\n        return ch in self._LETTER_CHARS\n\n    def _is_octal_digit(self, ch: str) -> bool:\n        \"\"\"\n        Determines if a character is an octal digit.\n        \"\"\"\n        return ch in self._OCTAL_CHARS\n\n    def _is_binary_digit(self, ch: str) -> bool:\n        \"\"\"\n        Determines if a character is a binary digit.\n        \"\"\"\n        return ch in self._BINARY_CHARS\n\n    def _is_digit(self, ch: str) -> bool:\n        \"\"\"\n        Determines if a character is a digit.\n        \"\"\"\n        return ch in self._DIGIT_CHARS\n\n    def _is_hex_digit(self, ch: str) -> bool:\n        \"\"\"\n        Determines if a character is a hexadecimal digit.\n        \"\"\"\n        return ch in self._HEX_CHARS\n\n    def _is_letter_or_digit(self, ch: str) -> bool:\n        \"\"\"\n        Determines if a character is a letter or digit.\n        \"\"\"\n        return ch in self._LETTER_DIGIT_CHARS\n\n    def _is_letter_or_digit_or_underscore(self, ch: str) -> bool:\n        \"\"\"\n        Determines if a character is a letter, digit, or underscore.\n        \"\"\"\n        return ch in self._LETTER_DIGIT_UNDERSCORE_CHARS\n\n    def _is_whitespace(self, ch: str) -> bool:\n        \"\"\"\n        Determines if a character is a non-newline whitespace.\n        \"\"\"\n        return ch in self._WHITESPACE_CHARS\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/syntax/parser.py\n\n```python\nfrom abc import ABC, abstractmethod\nfrom dataclasses import dataclass\nfrom typing import List\n\nfrom humbug.syntax.lexer import Lexer, LexerState, Token\n\n\n@dataclass\nclass ParserState:\n    \"\"\"\n    State information for the Parser.\n    \"\"\"\n    lexer_state: LexerState | None = None\n    parsing_continuation: bool = False\n    continuation_state: int = 0\n\n\nclass Parser(ABC):\n    \"\"\"\n    Abstract base class for all parsers.\n\n    This class provides the basic functionality for parsing input strings\n    and managing the state of the parser.\n    \"\"\"\n    def __init__(self) -> None:\n        self._lexer: Lexer | None = None\n        self._tokens: List[Token] = []\n        self._next_token: int = 0\n\n    @abstractmethod\n    def parse(self, prev_parser_state: ParserState | None, input_str: str) -> ParserState | None:\n        \"\"\"\n        Parse the input string\n        \"\"\"\n\n    def get_next_token(self) -> Token | None:\n        \"\"\"\n        Gets the next token from the input.\n\n        Returns:\n            The next Token available or None if there are no tokens left.\n        \"\"\"\n        if self._next_token >= len(self._tokens):\n            return None\n\n        token = self._tokens[self._next_token]\n        self._next_token += 1\n        return token\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/syntax/parser_registry.py\n\n```python\nfrom typing import Dict, Type, Callable\n\nfrom humbug.syntax.parser import Parser\nfrom humbug.syntax.programming_language import ProgrammingLanguage\n\n\nclass ParserRegistry:\n    \"\"\"\n    A registry for parser classes that handles parser creation and dependency management.\n\n    This registry serves as a central location for registering parser classes and\n    creating parser instances, avoiding cyclic dependencies between parsers and the\n    parser factory.\n\n    The registry uses a lazy initialization pattern to avoid import cycles, allowing\n    parser classes to be registered after the registry is created.\n    \"\"\"\n\n    _instance = None\n    _parser_classes: Dict[ProgrammingLanguage, Type[Parser]] = {}\n\n    def __new__(cls) -> \"ParserRegistry\":\n        \"\"\"\n        Implement the singleton pattern to ensure only one registry exists.\n\n        Returns:\n            The single ParserRegistry instance\n        \"\"\"\n        if cls._instance is None:\n            cls._instance = super(ParserRegistry, cls).__new__(cls)\n\n        return cls._instance\n\n    @classmethod\n    def register_parser(cls, language: ProgrammingLanguage) -> Callable[[Type[Parser]], Type[Parser]]:\n        \"\"\"\n        Register a parser class for a specific programming language.\n\n        This is designed to be used as a decorator on parser classes.\n\n        Args:\n            language: The programming language enum value to register the parser for\n\n        Returns:\n            A decorator function that registers the parser class\n\n        Example:\n            @ParserRegistry.register_parser(ProgrammingLanguage.PYTHON)\n            class PythonParser(Parser):\n                ...\n        \"\"\"\n        def decorator(parser_class: Type[Parser]) -> Type[Parser]:\n            cls._parser_classes[language] = parser_class\n            return parser_class\n\n        return decorator\n\n    @classmethod\n    def create_parser(cls, language: ProgrammingLanguage) -> Parser | None:\n        \"\"\"\n        Create and return a parser instance for the specified programming language.\n\n        Args:\n            language: The programming language enum value indicating which parser to create\n\n        Returns:\n            A parser instance appropriate for the specified language, or None if the\n            language is unknown or no parser is registered for it\n\n        Example:\n            >>> parser = ParserRegistry.create_parser(ProgrammingLanguage.PYTHON)\n            >>> python_parser = parser.parse(None, \"def example():\")\n        \"\"\"\n        parser_class = cls._parser_classes.get(language)\n        if parser_class:\n            return parser_class()\n\n        return None\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/syntax/parser_imports.py\n\n```python\n\"\"\"Imports all parsers to ensure they are registered in the ParserRegistry.\"\"\"\n\n# pylint: disable=unused-import\nfrom humbug.syntax.c.c_parser import CParser\nfrom humbug.syntax.cpp.cpp_parser import CppParser\nfrom humbug.syntax.csharp.csharp_parser import CSharpParser\nfrom humbug.syntax.css.css_parser import CSSParser\nfrom humbug.syntax.go.go_parser import GoParser\nfrom humbug.syntax.html.html_parser import HTMLParser\nfrom humbug.syntax.java.java_parser import JavaParser\nfrom humbug.syntax.javascript.javascript_parser import JavaScriptParser\nfrom humbug.syntax.json.json_parser import JSONParser\nfrom humbug.syntax.kotlin.kotlin_parser import KotlinParser\nfrom humbug.syntax.markdown.markdown_parser import MarkdownParser\nfrom humbug.syntax.metaphor.metaphor_parser import MetaphorParser\nfrom humbug.syntax.move.move_parser import MoveParser\nfrom humbug.syntax.python.python_parser import PythonParser\nfrom humbug.syntax.rust.rust_parser import RustParser\nfrom humbug.syntax.scheme.scheme_parser import SchemeParser\nfrom humbug.syntax.solidity.solidity_parser import SolidityParser\nfrom humbug.syntax.swift.swift_parser import SwiftParser\nfrom humbug.syntax.text.text_parser import TextParser\nfrom humbug.syntax.typescript.typescript_parser import TypeScriptParser\nfrom humbug.syntax.parser_registry import ParserRegistry\n# pylint: enable=unused-import\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/syntax/programming_language_utils.py\n\n```python\n\"\"\"\nUtilities for handling programming language detection, conversion, and display.\n\nThis module centralizes conversion between language names, ProgrammingLanguage enum values,\nfile extensions, and display names, eliminating code duplication across the application.\n\"\"\"\n\nimport os\nimport logging\nfrom typing import Dict, List, Tuple\n\nfrom humbug.syntax.programming_language import ProgrammingLanguage\n\n\nclass ProgrammingLanguageUtils:\n    \"\"\"\n    Utility class for handling programming language conversions and metadata.\n\n    This class centralizes all language-related operations including:\n    - Converting between string identifiers and ProgrammingLanguage enum values\n    - Getting display names for languages\n    - Getting file extensions for languages\n    - Detecting language from file extensions\n    \"\"\"\n\n    # Logger for the class\n    _logger = logging.getLogger(\"LanguageUtils\")\n\n    # Mapping from lowercase language names to enum members\n    _NAME_TO_LANGUAGE: Dict[str, ProgrammingLanguage] = {\n        \"c\": ProgrammingLanguage.C,\n        \"c++\": ProgrammingLanguage.CPP,\n        \"cpp\": ProgrammingLanguage.CPP,\n        \"cs\": ProgrammingLanguage.CSHARP,\n        \"csharp\": ProgrammingLanguage.CSHARP,\n        \"css\": ProgrammingLanguage.CSS,\n        \"go\": ProgrammingLanguage.GO,\n        \"html\": ProgrammingLanguage.HTML,\n        \"java\": ProgrammingLanguage.JAVA,\n        \"javascript\": ProgrammingLanguage.JAVASCRIPT,\n        \"js\": ProgrammingLanguage.JAVASCRIPT,\n        \"json\": ProgrammingLanguage.JSON,\n        \"kotlin\": ProgrammingLanguage.KOTLIN,\n        \"kt\": ProgrammingLanguage.KOTLIN,\n        \"markdown\": ProgrammingLanguage.MARKDOWN,\n        \"md\": ProgrammingLanguage.MARKDOWN,\n        \"metaphor\": ProgrammingLanguage.METAPHOR,\n        \"m6r\": ProgrammingLanguage.METAPHOR,\n        \"move\": ProgrammingLanguage.MOVE,\n        \"python\": ProgrammingLanguage.PYTHON,\n        \"py\": ProgrammingLanguage.PYTHON,\n        \"rust\": ProgrammingLanguage.RUST,\n        \"rs\": ProgrammingLanguage.RUST,\n        \"scheme\": ProgrammingLanguage.SCHEME,\n        \"scm\": ProgrammingLanguage.SCHEME,\n        'sol': ProgrammingLanguage.SOLIDITY,\n        'solidity': ProgrammingLanguage.SOLIDITY,\n        \"swift\": ProgrammingLanguage.SWIFT,\n        \"typescript\": ProgrammingLanguage.TYPESCRIPT,\n        \"ts\": ProgrammingLanguage.TYPESCRIPT,\n        \"text\": ProgrammingLanguage.TEXT,\n        \"plaintext\": ProgrammingLanguage.TEXT,\n        \"txt\": ProgrammingLanguage.TEXT,\n        # Empty string defaults to text\n        \"\": ProgrammingLanguage.TEXT\n    }\n\n    # Mapping from file extensions to programming languages\n    _EXTENSION_TO_LANGUAGE: Dict[str, ProgrammingLanguage] = {\n        '.c': ProgrammingLanguage.C,\n        '.cc': ProgrammingLanguage.CPP,\n        '.conv': ProgrammingLanguage.JSON,\n        '.cpp': ProgrammingLanguage.CPP,\n        '.cs': ProgrammingLanguage.CSHARP,\n        '.css': ProgrammingLanguage.CSS,\n        '.cxx': ProgrammingLanguage.CPP,\n        '.go': ProgrammingLanguage.GO,\n        '.h': ProgrammingLanguage.C,\n        '.hh': ProgrammingLanguage.CPP,\n        '.hpp': ProgrammingLanguage.CPP,\n        '.html': ProgrammingLanguage.HTML,\n        '.htm': ProgrammingLanguage.HTML,\n        '.hxx': ProgrammingLanguage.CPP,\n        '.java': ProgrammingLanguage.JAVA,\n        '.js': ProgrammingLanguage.JAVASCRIPT,\n        '.json': ProgrammingLanguage.JSON,\n        '.jsx': ProgrammingLanguage.JAVASCRIPT,\n        '.kt': ProgrammingLanguage.KOTLIN,\n        '.kts': ProgrammingLanguage.KOTLIN,\n        '.m6r': ProgrammingLanguage.METAPHOR,\n        '.md': ProgrammingLanguage.MARKDOWN,\n        '.move': ProgrammingLanguage.MOVE,\n        '.py': ProgrammingLanguage.PYTHON,\n        '.pyw': ProgrammingLanguage.PYTHON,\n        '.pyi': ProgrammingLanguage.PYTHON,\n        '.rs': ProgrammingLanguage.RUST,\n        '.scm': ProgrammingLanguage.SCHEME,\n        '.sol': ProgrammingLanguage.SOLIDITY,\n        '.swift': ProgrammingLanguage.SWIFT,\n        '.ts': ProgrammingLanguage.TYPESCRIPT,\n        '.tsx': ProgrammingLanguage.TYPESCRIPT,\n        '.txt': ProgrammingLanguage.TEXT,\n    }\n\n    # Mapping from programming languages to display names\n    _LANGUAGE_TO_DISPLAY_NAME: Dict[ProgrammingLanguage, str] = {\n        ProgrammingLanguage.C: \"C\",\n        ProgrammingLanguage.CPP: \"C++\",\n        ProgrammingLanguage.CSHARP: \"C#\",\n        ProgrammingLanguage.CSS: \"CSS\",\n        ProgrammingLanguage.GO: \"Go\",\n        ProgrammingLanguage.HTML: \"HTML\",\n        ProgrammingLanguage.JAVA: \"Java\",\n        ProgrammingLanguage.JAVASCRIPT: \"JavaScript\",\n        ProgrammingLanguage.JSON: \"JSON\",\n        ProgrammingLanguage.KOTLIN: \"Kotlin\",\n        ProgrammingLanguage.MARKDOWN: \"Markdown\",\n        ProgrammingLanguage.METAPHOR: \"Metaphor\",\n        ProgrammingLanguage.MOVE: \"Move\",\n        ProgrammingLanguage.PYTHON: \"Python\",\n        ProgrammingLanguage.RUST: \"Rust\",\n        ProgrammingLanguage.SCHEME: \"Scheme\",\n        ProgrammingLanguage.SOLIDITY: \"Solidity\",\n        ProgrammingLanguage.SWIFT: \"Swift\",\n        ProgrammingLanguage.TYPESCRIPT: \"TypeScript\",\n        ProgrammingLanguage.TEXT: \"None\",\n        ProgrammingLanguage.UNKNOWN: \"Unknown\"\n    }\n\n    # Mapping from programming languages to file extensions (with leading dot)\n    _LANGUAGE_TO_EXTENSION: Dict[ProgrammingLanguage, str] = {\n        ProgrammingLanguage.C: \".c\",\n        ProgrammingLanguage.CPP: \".cpp\",\n        ProgrammingLanguage.CSHARP: \".cs\",\n        ProgrammingLanguage.CSS: \".css\",\n        ProgrammingLanguage.GO: \".go\",\n        ProgrammingLanguage.HTML: \".html\",\n        ProgrammingLanguage.JAVA: \".java\",\n        ProgrammingLanguage.JAVASCRIPT: \".js\",\n        ProgrammingLanguage.JSON: \".json\",\n        ProgrammingLanguage.KOTLIN: \".kt\",\n        ProgrammingLanguage.MARKDOWN: \".md\",\n        ProgrammingLanguage.METAPHOR: \".m6r\",\n        ProgrammingLanguage.MOVE: \".move\",\n        ProgrammingLanguage.PYTHON: \".py\",\n        ProgrammingLanguage.RUST: \".rs\",\n        ProgrammingLanguage.SCHEME: \".scm\",\n        ProgrammingLanguage.SOLIDITY: \".sol\",\n        ProgrammingLanguage.SWIFT: \".swift\",\n        ProgrammingLanguage.TYPESCRIPT: \".ts\",\n        ProgrammingLanguage.TEXT: \".txt\",\n        ProgrammingLanguage.UNKNOWN: \".txt\"\n    }\n\n    @classmethod\n    def get_all_programming_languages(cls) -> List[ProgrammingLanguage]:\n        \"\"\"\n        Get a list of all available programming languages.\n\n        Returns:\n            List of all programming language enum values excluding UNKNOWN\n        \"\"\"\n        return [lang for lang in ProgrammingLanguage if lang != ProgrammingLanguage.UNKNOWN]\n\n    @classmethod\n    def get_all_display_names(cls) -> List[Tuple[ProgrammingLanguage, str]]:\n        \"\"\"\n        Get all language display names.\n\n        Returns:\n            List of (language enum, display name) tuples\n        \"\"\"\n        return [(lang, cls.get_display_name(lang)) for lang in cls.get_all_programming_languages()]\n\n    @classmethod\n    def from_name(cls, name: str) -> ProgrammingLanguage:\n        \"\"\"\n        Convert a language name string to a ProgrammingLanguage enum value.\n\n        Args:\n            name: The name of the programming language\n\n        Returns:\n            The corresponding ProgrammingLanguage enum value,\n            or ProgrammingLanguage.TEXT if not found\n        \"\"\"\n        if not name:\n            return ProgrammingLanguage.TEXT\n\n        normalized = name.strip().lower()\n        return cls._NAME_TO_LANGUAGE.get(normalized, ProgrammingLanguage.TEXT)\n\n    @classmethod\n    def from_file_extension(cls, filename: str | None) -> ProgrammingLanguage:\n        \"\"\"\n        Detect programming language from file extension.\n\n        Args:\n            filename: Path to file or None\n\n        Returns:\n            The detected programming language enum value,\n            or ProgrammingLanguage.TEXT if not detected\n        \"\"\"\n        if not filename:\n            return ProgrammingLanguage.TEXT\n\n        ext = os.path.splitext(filename)[1].lower()\n        return cls._EXTENSION_TO_LANGUAGE.get(ext, ProgrammingLanguage.TEXT)\n\n    @classmethod\n    def get_display_name(cls, language: ProgrammingLanguage) -> str:\n        \"\"\"\n        Get the human-readable display name for a programming language.\n\n        Args:\n            language: The programming language enum value\n\n        Returns:\n            Human-readable language name for display\n        \"\"\"\n        return cls._LANGUAGE_TO_DISPLAY_NAME.get(language, \"Code\")\n\n    @classmethod\n    def get_file_extension(cls, language: ProgrammingLanguage | None) -> str:\n        \"\"\"\n        Get the file extension for a programming language.\n\n        Args:\n            language: The programming language or None\n\n        Returns:\n            The file extension with leading dot, or empty string if language is None\n        \"\"\"\n        if language is None:\n            return \"\"\n\n        return cls._LANGUAGE_TO_EXTENSION.get(language, \".txt\")\n\n    @classmethod\n    def get_supported_file_extensions(cls) -> List[str]:\n        \"\"\"\n        Get a list of all supported file extensions.\n\n        Returns:\n            List of supported file extensions with leading dots\n        \"\"\"\n        return list(cls._EXTENSION_TO_LANGUAGE.keys())\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/syntax/c/c_lexer.py\n\n```python\n\"\"\"\nC Lexer\n\nThis module implements a lexer for C code, extending the functionality of the base lexer.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Callable\n\nfrom humbug.syntax.lexer import Lexer, LexerState, Token, TokenType\n\n\n@dataclass\nclass CLexerState(LexerState):\n    \"\"\"\n    State information for the C lexer.\n\n    Attributes:\n        in_block_comment: Indicates if we're currently parsing a block comment\n    \"\"\"\n    in_block_comment: bool = False\n\n\nclass CLexer(Lexer):\n    \"\"\"\n    Lexer for C code.\n\n    This lexer handles C-specific syntax including keywords, operators, numbers,\n    strings, comments, and preprocessor directives.\n    \"\"\"\n\n    # Operators list\n    _OPERATORS = [\n        '>>=', '<<=', '&&=', '||=', '!=', '==', '+=', '-=', '*=',\n        '/=', '%=', '&=', '|=', '^=', '<=', '>=', '&&', '||', '<<',\n        '>>', '++', '--', '->', '+', '-', '*', '/', '%', '&',\n        '~', '!', '|', '^', '=', '<', '>', '(', ')', '{', '}', '[',\n        ']', ';', ':', '?', '.', ','\n    ]\n\n    # Build the operator map\n    _OPERATORS_MAP = Lexer.build_operator_map(_OPERATORS)\n\n    def __init__(self) -> None:\n        super().__init__()\n        self._in_block_comment = False\n\n    def lex(self, prev_lexer_state: LexerState | None, input_str: str) -> CLexerState:\n        \"\"\"\n        Lex all the tokens in the input.\n\n        Args:\n            prev_lexer_state: Optional previous lexer state\n            input_str: The input string to parse\n\n        Returns:\n            The updated lexer state after processing\n        \"\"\"\n        self._input = input_str\n        self._input_len = len(input_str)\n        if prev_lexer_state is not None:\n            assert isinstance(prev_lexer_state, CLexerState), \\\n                f\"Expected CLexerState, got {type(prev_lexer_state).__name__}\"\n            self._in_block_comment = prev_lexer_state.in_block_comment\n\n        if self._in_block_comment:\n            self._read_block_comment(0)\n\n        if not self._in_block_comment:\n            self._inner_lex()\n\n        lexer_state = CLexerState()\n        lexer_state.in_block_comment = self._in_block_comment\n        return lexer_state\n\n    def _get_lexing_function(self, ch: str) -> Callable[[], None]:\n        \"\"\"\n        Get the lexing function that matches a given start character.\n\n        Args:\n            ch: The start character\n\n        Returns:\n            The appropriate lexing function for the character\n        \"\"\"\n        if self._is_whitespace(ch):\n            return self._read_whitespace\n\n        if ch == 'L':\n            return self._read_l\n\n        if self._is_letter(ch) or ch == '_':\n            return self._read_identifier_or_keyword\n\n        if self._is_digit(ch):\n            return self._read_number\n\n        if ch in ('\"', \"'\"):\n            return self._read_string\n\n        if ch == '.':\n            return self._read_dot\n\n        if ch == '/':\n            return self._read_forward_slash\n\n        if ch == '#':\n            return self._read_preprocessor_directive\n\n        return self._read_operator\n\n    def _read_l(self) -> None:\n        \"\"\"\n        Read an L character, which could be the start of a wide string literal\n        or an identifier.\n        \"\"\"\n        if (self._position + 1 < self._input_len and\n                self._input[self._position + 1] == '\"'):\n            self._read_string()\n            return\n\n        self._read_identifier_or_keyword()\n\n    def _read_dot(self) -> None:\n        \"\"\"\n        Read a dot operator or decimal point in a number.\n        \"\"\"\n        if (self._position + 1 < self._input_len and\n                self._is_digit(self._input[self._position + 1])):\n            self._read_number()\n            return\n\n        self._read_operator()\n\n    def _read_forward_slash(self) -> None:\n        \"\"\"\n        Read a forward slash, which could be the start of a comment or an operator.\n        \"\"\"\n        if self._position + 1 < self._input_len:\n            if self._input[self._position + 1] == '/':\n                self._read_comment()\n                return\n\n            if self._input[self._position + 1] == '*':\n                self._read_block_comment(2)\n                return\n\n        self._read_operator()\n\n    def _read_string(self) -> None:\n        \"\"\"\n        Read a string literal token, including wide string literals.\n\n        Handles escape sequences within strings.\n        \"\"\"\n        start = self._position\n        quote = self._input[self._position]\n        self._position += 1\n\n        if quote == 'L':\n            self._position += 1\n            quote = '\"'\n\n        while self._position < self._input_len and self._input[self._position] != quote:\n            if (self._input[self._position] == '\\\\' and\n                    self._position + 1 < self._input_len):\n                self._position += 2\n                continue\n\n            self._position += 1\n\n        if self._position < self._input_len:\n            self._position += 1\n\n        self._tokens.append(Token(\n            type=TokenType.STRING,\n            value=self._input[start:self._position],\n            start=start\n        ))\n\n    def _read_number(self) -> None:\n        \"\"\"\n        Read a numeric literal token.\n\n        Handles decimal, hexadecimal, binary numbers, and their suffixes.\n        \"\"\"\n        start = self._position\n        has_suffix = False\n\n        if (self._position + 1 < self._input_len and\n                self._input[self._position] == '0'):\n            next_char = self._input[self._position + 1].lower()\n            if next_char == 'x':  # Hexadecimal\n                self._position += 2\n                while (self._position < self._input_len and\n                       self._is_hex_digit(self._input[self._position])):\n                    self._position += 1\n            elif next_char == 'b':  # Binary\n                self._position += 2\n                while (self._position < self._input_len and\n                       self._is_binary_digit(self._input[self._position])):\n                    self._position += 1\n            else:  # Decimal or floating-point\n                self._read_decimal_number()\n        else:\n            self._read_decimal_number()\n\n        # Handle suffixes\n        suffix_start = self._position\n        while (self._position < self._input_len and\n               self._input[self._position].lower() in 'ulfj'):\n            self._position += 1\n            has_suffix = True\n\n        # Validate suffix combination\n        if has_suffix:\n            suffix = self._input[suffix_start:self._position].lower()\n            valid_integer_suffixes = {'u', 'ul', 'ull', 'lu', 'llu'}\n            valid_float_suffixes = {'f', 'l'}\n            if suffix not in valid_integer_suffixes and suffix not in valid_float_suffixes:\n                self._position = suffix_start\n\n        self._tokens.append(Token(\n            type=TokenType.NUMBER,\n            value=self._input[start:self._position],\n            start=start\n        ))\n\n    def _read_decimal_number(self) -> None:\n        \"\"\"\n        Read a decimal or floating-point number.\n        \"\"\"\n        while (self._position < self._input_len and\n               self._is_digit(self._input[self._position])):\n            self._position += 1\n\n        if (self._position < self._input_len and\n                self._input[self._position] == '.'):\n            self._position += 1\n            while (self._position < self._input_len and\n                   self._is_digit(self._input[self._position])):\n                self._position += 1\n\n        if (self._position < self._input_len and\n                self._input[self._position].lower() == 'e'):\n            self._position += 1\n            if self._input[self._position] in ('+', '-'):\n                self._position += 1\n\n            while (self._position < self._input_len and\n                   self._is_digit(self._input[self._position])):\n                self._position += 1\n\n    def _read_comment(self) -> None:\n        \"\"\"\n        Read a single-line comment token.\n        \"\"\"\n        self._tokens.append(Token(\n            type=TokenType.COMMENT,\n            value=self._input[self._position:],\n            start=self._position\n        ))\n        self._position = self._input_len\n\n    def _read_block_comment(self, skip_chars: int) -> None:\n        \"\"\"\n        Read a block comment token.\n        \"\"\"\n        self._in_block_comment = True\n        start = self._position\n        self._position += skip_chars  # Skip /*\n        while (self._position + 1) < self._input_len:\n            if self._input[self._position] == '*' and self._input[self._position + 1] == '/':\n                self._in_block_comment = False\n                self._position += 2\n                break\n\n            self._position += 1\n\n        # If we're still in a block comment we've got one character left on this line and\n        # we need to include it in the comment too.\n        if self._in_block_comment:\n            self._position = self._input_len\n\n        self._tokens.append(Token(\n            type=TokenType.COMMENT,\n            value=self._input[start:self._position],\n            start=start\n        ))\n\n    def _read_identifier_or_keyword(self) -> None:\n        \"\"\"\n        Read an identifier or keyword token.\n        \"\"\"\n        start = self._position\n        self._position += 1\n        while (self._position < self._input_len and\n                self._is_letter_or_digit_or_underscore(self._input[self._position])):\n            self._position += 1\n\n        value = self._input[start:self._position]\n        if self._is_keyword(value):\n            self._tokens.append(Token(type=TokenType.KEYWORD, value=value, start=start))\n            return\n\n        self._tokens.append(Token(type=TokenType.IDENTIFIER, value=value, start=start))\n\n    def _read_preprocessor_directive(self) -> None:\n        \"\"\"\n        Read a preprocessor directive token.\n        \"\"\"\n        self._tokens.append(Token(\n            type=TokenType.PREPROCESSOR,\n            value=self._input[self._position:],\n            start=self._position\n        ))\n        self._position = self._input_len\n\n    def _is_keyword(self, value: str) -> bool:\n        \"\"\"\n        Check if a given value is a C keyword.\n\n        Args:\n            value: The string to check\n\n        Returns:\n            True if the value is a C keyword, False otherwise\n        \"\"\"\n        keywords = {\n            'auto', 'break', 'case', 'char', 'const', 'continue',\n            'default', 'do', 'double', 'else', 'enum', 'extern',\n            'float', 'for', 'goto', 'if', 'inline', 'int', 'long',\n            'register', 'restrict', 'return', 'short', 'signed',\n            'sizeof', 'static', 'struct', 'switch', 'typedef',\n            'union', 'unsigned', 'void', 'volatile', 'while',\n            '_Bool', '_Complex', '_Imaginary'\n        }\n        return value in keywords\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/syntax/c/c_parser.py\n\n```python\n\"\"\"\nC parser\n\nThis module implements a parser for C code, extending the functionality of the base parser.\n\"\"\"\n\nfrom dataclasses import dataclass\n\nfrom humbug.syntax.c.c_lexer import CLexer\nfrom humbug.syntax.lexer import TokenType\nfrom humbug.syntax.parser import Parser, ParserState\nfrom humbug.syntax.parser_registry import ParserRegistry\nfrom humbug.syntax.programming_language import ProgrammingLanguage\n\n\n@dataclass\nclass CParserState(ParserState):\n    \"\"\"\n    State information for the C parser.\n\n    Attributes:\n        in_element: Indicates if we're currently parsing an element\n    \"\"\"\n    in_element: bool = False\n\n\n@ParserRegistry.register_parser(ProgrammingLanguage.C)\nclass CParser(Parser):\n    \"\"\"\n    Parser for C code.\n\n    This parser processes tokens from the C lexer and handles special cases\n    like function calls and element access.\n    \"\"\"\n\n    def parse(self, prev_parser_state: ParserState | None, input_str: str) -> CParserState:\n        \"\"\"\n        Parse the input string using the provided parser state.\n\n        Args:\n            prev_parser_state: Optional previous parser state of type CParserState.\n                If provided with a different ParserState subclass, TypeError will be raised.\n            input_str: The input string to parse\n\n        Returns:\n            The updated CParserState after parsing\n\n        Note:\n            The parser converts identifier tokens to FUNCTION_OR_METHOD tokens\n            when they're followed by parentheses, and to ELEMENT tokens when\n            they're part of a dotted or arrow access chain.\n        \"\"\"\n        in_element = False\n        prev_lexer_state = None\n\n        if prev_parser_state is not None:\n            assert isinstance(prev_parser_state, CParserState), \\\n                f\"Expected CParserState, got {type(prev_parser_state).__name__}\"\n            in_element = prev_parser_state.in_element\n            prev_lexer_state = prev_parser_state.lexer_state\n\n        lexer = CLexer()\n        lexer_state = lexer.lex(prev_lexer_state, input_str)\n\n        while True:\n            token = lexer.get_next_token()\n            if not token:\n                break\n\n            if token.type != TokenType.IDENTIFIER:\n                self._tokens.append(token)\n                continue\n\n            # Look at the next token. If it's a '(' operator then we're making a\n            # function or method call!\n            cur_in_element = in_element\n            next_token = lexer.peek_next_token()\n            in_element = cur_in_element\n\n            next_in_element = False\n            if next_token and next_token.type == TokenType.OPERATOR:\n                if next_token.value == '(':\n                    in_element = False\n                    token.type = TokenType.FUNCTION_OR_METHOD\n                    self._tokens.append(token)\n                    continue\n\n                # Is the next token going to be an element?\n                if next_token.value in ('.', '->'):\n                    next_in_element = True\n\n            in_element = next_in_element\n\n            if cur_in_element:\n                token.type = TokenType.ELEMENT\n                self._tokens.append(token)\n                continue\n\n            self._tokens.append(token)\n\n        parser_state = CParserState()\n        parser_state.continuation_state = 1 if lexer_state.in_block_comment else 0\n        parser_state.parsing_continuation = lexer_state.in_block_comment\n        parser_state.lexer_state = lexer_state\n        parser_state.in_element = in_element\n        return parser_state\n```\n\nFile: /Users/dave/github/m6r/humbug/tests/markdown/test_markdown_ast_builder.py\n\n```python\n\"\"\"\nTests for the markdown AST builder\n\"\"\"\nimport os\nimport pytest\n\nfrom humbug.markdown.markdown_ast_builder import MarkdownASTBuilder\n\n# pylint: disable=unused-import\nimport humbug.syntax.parser_imports\n# pylint: enable=unused-import\n\nfrom markdown_test_utils import (\n    find_test_files,\n    parse_and_compare\n)\n\n\n@pytest.fixture\ndef ast_builder():\n    \"\"\"Fixture providing a markdown AST builder instance.\"\"\"\n    return MarkdownASTBuilder(no_underscores=False)\n\n\n@pytest.fixture\ndef ast_builder_no_underscores():\n    \"\"\"Fixture providing a markdown AST builder instance with underscores disabled.\"\"\"\n    return MarkdownASTBuilder(no_underscores=True)\n\n\n@pytest.mark.parametrize(\"markdown_path,expected_json_path\", find_test_files())\ndef test_parse_fixture_files(markdown_path, expected_json_path):\n    \"\"\"Test parsing markdown files against expected JSON outputs.\"\"\"\n    is_match, diff = parse_and_compare(markdown_path, expected_json_path)\n    assert is_match, f\"AST mismatch for {os.path.basename(markdown_path)}:\\n{diff}\"\n\n\ndef test_empty_document(ast_builder):\n    \"\"\"Test parsing an empty document.\"\"\"\n    doc = ast_builder.build_ast(\"\")\n    assert doc is not None\n    assert len(doc.children) == 0\n\n\ndef test_document_property(ast_builder):\n    \"\"\"Test the document property returns the current document.\"\"\"\n    # Test with empty document\n    initial_doc = ast_builder.document()\n    assert initial_doc is not None\n    assert len(initial_doc.children) == 0\n\n    # Test after parsing content\n    ast_builder.build_ast(\"# Test Heading\")\n    updated_doc = ast_builder.document()\n    assert updated_doc is not None\n    assert len(updated_doc.children) == 1\n    assert updated_doc.children[0].__class__.__name__ == \"MarkdownHeadingNode\"\n\n    # Verify same document instance is returned\n    assert updated_doc is ast_builder.document()\n\n\ndef test_simple_paragraph(ast_builder):\n    \"\"\"Test parsing a simple paragraph.\"\"\"\n    doc = ast_builder.build_ast(\"This is a paragraph.\")\n    assert doc is not None\n    assert len(doc.children) == 1\n    assert doc.children[0].__class__.__name__ == \"MarkdownParagraphNode\"\n    assert len(doc.children[0].children) == 1\n    assert doc.children[0].children[0].__class__.__name__ == \"MarkdownTextNode\"\n    assert doc.children[0].children[0].content == \"This is a paragraph.\"\n\n\ndef test_heading(ast_builder):\n    \"\"\"Test parsing a heading.\"\"\"\n    doc = ast_builder.build_ast(\"# Heading 1\")\n    assert doc is not None\n    assert len(doc.children) == 1\n    assert doc.children[0].__class__.__name__ == \"MarkdownHeadingNode\"\n    assert doc.children[0].level == 1\n    assert len(doc.children[0].children) == 1\n    assert doc.children[0].children[0].__class__.__name__ == \"MarkdownTextNode\"\n    assert doc.children[0].children[0].content == \"Heading 1\"\n\n\ndef test_bold_text(ast_builder):\n    \"\"\"Test parsing bold text.\"\"\"\n    doc = ast_builder.build_ast(\"This is **bold** text.\")\n    assert doc is not None\n    assert len(doc.children) == 1\n    paragraph = doc.children[0]\n    assert paragraph.__class__.__name__ == \"MarkdownParagraphNode\"\n    assert len(paragraph.children) == 3\n    assert paragraph.children[0].__class__.__name__ == \"MarkdownTextNode\"\n    assert paragraph.children[0].content == \"This is \"\n    assert paragraph.children[1].__class__.__name__ == \"MarkdownBoldNode\"\n    assert paragraph.children[1].children[0].__class__.__name__ == \"MarkdownTextNode\"\n    assert paragraph.children[1].children[0].content == \"bold\"\n    assert paragraph.children[2].__class__.__name__ == \"MarkdownTextNode\"\n    assert paragraph.children[2].content == \" text.\"\n\n\ndef test_underscore_formatting(ast_builder, ast_builder_no_underscores):\n    \"\"\"Test underscore formatting behavior.\"\"\"\n    # With underscores enabled\n    doc = ast_builder.build_ast(\"_italic_ and __bold__\")\n    assert doc.children[0].children[0].__class__.__name__ == \"MarkdownEmphasisNode\"\n    assert doc.children[0].children[2].__class__.__name__ == \"MarkdownBoldNode\"\n\n    # With underscores disabled\n    doc = ast_builder_no_underscores.build_ast(\"_italic_ and __bold__\")\n    assert doc.children[0].children[0].__class__.__name__ == \"MarkdownTextNode\"\n    assert doc.children[0].children[0].content == \"_italic_ and __bold__\"\n\n\ndef test_nested_formatting(ast_builder):\n    \"\"\"Test nested formatting.\"\"\"\n    doc = ast_builder.build_ast(\"This is **bold with *italic* inside**.\")\n    paragraph = doc.children[0]\n    bold_node = paragraph.children[1]\n    assert bold_node.__class__.__name__ == \"MarkdownBoldNode\"\n    assert len(bold_node.children) == 3\n    assert bold_node.children[0].__class__.__name__ == \"MarkdownTextNode\"\n    assert bold_node.children[0].content == \"bold with \"\n    assert bold_node.children[1].__class__.__name__ == \"MarkdownEmphasisNode\"\n\n\ndef test_headings(ast_builder):\n    \"\"\"Test parsing different levels of headings.\"\"\"\n    markdown = \"\"\"\n# Heading A\n## Heading 1\n# Heading B\n## Heading 1\n### 3rd level\n### Another 3rd level\n\"\"\"\n    doc = ast_builder.build_ast(markdown)\n    assert len(doc.children) == 6\n    assert doc.children[0].__class__.__name__ == \"MarkdownHeadingNode\"\n    assert doc.children[0].level == 1\n    assert doc.children[1].__class__.__name__ == \"MarkdownHeadingNode\"\n    assert doc.children[1].level == 2\n    assert doc.children[2].__class__.__name__ == \"MarkdownHeadingNode\"\n    assert doc.children[2].level == 1\n    assert doc.children[3].__class__.__name__ == \"MarkdownHeadingNode\"\n    assert doc.children[3].level == 2\n    assert doc.children[4].__class__.__name__ == \"MarkdownHeadingNode\"\n    assert doc.children[4].level == 3\n    assert doc.children[5].__class__.__name__ == \"MarkdownHeadingNode\"\n    assert doc.children[5].level == 3\n\n\ndef test_unordered_list(ast_builder):\n    \"\"\"Test parsing an unordered list.\"\"\"\n    markdown = \"\"\"\n- Item 1\n- Item 2\n- Item 3\n\"\"\"\n    doc = ast_builder.build_ast(markdown)\n    assert len(doc.children) == 1\n    list_node = doc.children[0]\n    assert list_node.__class__.__name__ == \"MarkdownUnorderedListNode\"\n    assert len(list_node.children) == 3\n    for item in list_node.children:\n        assert item.__class__.__name__ == \"MarkdownListItemNode\"\n\n\ndef test_ordered_list(ast_builder):\n    \"\"\"Test parsing an ordered list.\"\"\"\n    markdown = \"\"\"\n1. First item\n2. Second item\n3. Third item\n\"\"\"\n    doc = ast_builder.build_ast(markdown)\n    assert len(doc.children) == 1\n    list_node = doc.children[0]\n    assert list_node.__class__.__name__ == \"MarkdownOrderedListNode\"\n    assert len(list_node.children) == 3\n    assert list_node.start == 1\n\n\ndef test_nested_list(ast_builder):\n    \"\"\"Test parsing a nested list.\"\"\"\n    markdown = \"\"\"\n- Item 1\n  - Nested 1.1\n  - Nested 1.2\n- Item 2\n- Item 3\n\"\"\"\n    doc = ast_builder.build_ast(markdown)\n    assert len(doc.children) == 1\n    list_node = doc.children[0]\n    assert len(list_node.children) == 3\n\n    # Check first item has a nested list\n    first_item = list_node.children[0]\n    assert len(first_item.children) == 2\n    nested_list = first_item.children[0]\n    assert nested_list.__class__.__name__ == \"MarkdownParagraphNode\"\n    nested_list = first_item.children[1]\n    assert nested_list.__class__.__name__ == \"MarkdownUnorderedListNode\"\n    assert len(nested_list.children) == 2\n\n\ndef test_nested_list2(ast_builder):\n    \"\"\"Test parsing a nested list.\"\"\"\n    markdown = \"\"\"\n- Item 1\n  - Nested 1.1\n  - Nested 1.2\n  1. Nested n.1\n  2. Nested n.2\n- Item 2\n- Item 3\n\"\"\"\n    doc = ast_builder.build_ast(markdown)\n    assert len(doc.children) == 1\n    list_node = doc.children[0]\n    assert len(list_node.children) == 3\n\n    # Check first item has a nested list\n    first_item = list_node.children[0]\n    assert len(first_item.children) == 3\n    nested_list = first_item.children[0]\n    assert nested_list.__class__.__name__ == \"MarkdownParagraphNode\"\n    first_nested_list = first_item.children[1]\n    assert first_nested_list.__class__.__name__ == \"MarkdownUnorderedListNode\"\n    assert len(first_nested_list.children) == 2\n    second_nested_list = first_item.children[2]\n    assert second_nested_list.__class__.__name__ == \"MarkdownOrderedListNode\"\n    assert len(second_nested_list.children) == 2\n\n\ndef test_nested_list3(ast_builder):\n    \"\"\"Test parsing a nested list.\"\"\"\n    markdown = \"\"\"\n- Item 1\n  1. Nested n.1\n  2. Nested n.2\n  - Nested 1.1\n  - Nested 1.2\n- Item 2\n- Item 3\n\"\"\"\n    doc = ast_builder.build_ast(markdown)\n    assert len(doc.children) == 1\n    list_node = doc.children[0]\n    assert len(list_node.children) == 3\n\n    # Check first item has a nested list\n    first_item = list_node.children[0]\n    assert len(first_item.children) == 3\n    nested_list = first_item.children[0]\n    assert nested_list.__class__.__name__ == \"MarkdownParagraphNode\"\n    first_nested_list = first_item.children[1]\n    assert first_nested_list.__class__.__name__ == \"MarkdownOrderedListNode\"\n    assert len(first_nested_list.children) == 2\n    second_nested_list = first_item.children[2]\n    assert second_nested_list.__class__.__name__ == \"MarkdownUnorderedListNode\"\n    assert len(second_nested_list.children) == 2\n\n\ndef test_code_block(ast_builder):\n    \"\"\"Test parsing a code block.\"\"\"\n    markdown = \"\"\"```python\ndef hello():\nprint(\"Hello, world!\")\n```\"\"\"\n    doc = ast_builder.build_ast(markdown)\n    assert len(doc.children) == 1\n    code_block = doc.children[0]\n    assert code_block.__class__.__name__ == \"MarkdownCodeBlockNode\"\n    assert code_block.language == \"python\"\n    assert \"def hello():\" in code_block.content\n    assert \"print(\\\"Hello, world!\\\")\" in code_block.content\n\n\ndef test_table(ast_builder):\n    \"\"\"Test parsing a table.\"\"\"\n    markdown = \"\"\"\n| Header 1 | Header 2 |\n|----------|----------|\n| Cell 1   | Cell 2   |\n| Cell 3   | Cell 4   |\n\"\"\"\n    doc = ast_builder.build_ast(markdown)\n    assert len(doc.children) == 1\n    table = doc.children[0]\n    assert table.__class__.__name__ == \"MarkdownTableNode\"\n    assert len(table.children) == 2\n\n    # Check header\n    header = table.children[0]\n    assert header.__class__.__name__ == \"MarkdownTableHeaderNode\"\n    assert len(header.children) == 1  # One row\n\n    # Check body\n    body = table.children[1]\n    assert body.__class__.__name__ == \"MarkdownTableBodyNode\"\n    assert len(body.children) == 2  # Two rows\n\ndef test_horizontal_rule(ast_builder):\n    \"\"\"Test parsing a horizontal rule.\"\"\"\n    markdown = \"\"\"\nBefore rule\n\n---\n\nAfter rule\n\"\"\"\n    doc = ast_builder.build_ast(markdown)\n    assert len(doc.children) == 3\n    assert doc.children[0].__class__.__name__ == \"MarkdownParagraphNode\"\n    assert doc.children[1].__class__.__name__ == \"MarkdownHorizontalRuleNode\"\n    assert doc.children[2].__class__.__name__ == \"MarkdownParagraphNode\"\n\n\ndef test_link(ast_builder):\n    \"\"\"Test parsing a link.\"\"\"\n    doc = ast_builder.build_ast(\"Here is a [link](https://example.com) to a website.\")\n    paragraph = doc.children[0]\n    assert len(paragraph.children) == 3\n    link = paragraph.children[1]\n    assert link.__class__.__name__ == \"MarkdownLinkNode\"\n    assert link.url == \"https://example.com\"\n    assert len(link.children) == 1\n    assert link.children[0].content == \"link\"\n\n\ndef test_image(ast_builder):\n    \"\"\"Test parsing an image.\"\"\"\n    doc = ast_builder.build_ast(\"![Alt text](image.jpg \\\"Image title\\\")\")\n    paragraph = doc.children[0]\n    image = paragraph.children[0]\n    assert image.__class__.__name__ == \"MarkdownImageNode\"\n    assert image.url == \"image.jpg\"\n    assert image.alt_text == \"Alt text\"\n    assert image.title == \"Image title\"\n\n\ndef test_line_to_node_mapping(ast_builder):\n    \"\"\"Test the line to node mapping functionality.\"\"\"\n    markdown = \"\"\"# Heading\n\nParagraph 1.\n\nParagraph 2.\n\"\"\"\n    ast_builder.build_ast(markdown)\n\n    # Check mapping exists for each line\n    assert 0 in ast_builder._line_to_node_map  # Heading\n    assert 2 in ast_builder._line_to_node_map  # Paragraph 1\n    assert 4 in ast_builder._line_to_node_map  # Paragraph 2\n\n\ndef test_update_ast(ast_builder):\n    \"\"\"Test updating an AST incrementally.\"\"\"\n    original = \"# Original heading\\n\\nOriginal paragraph.\"\n    updated = \"# Updated heading\\n\\nUpdated paragraph.\"\n\n    # Build original AST\n    ast_builder.build_ast(original)\n\n    # Update AST\n    doc = ast_builder.update_ast(updated, original)\n\n    # Check that the AST was updated\n    assert doc.children[0].children[0].content == \"Updated heading\"\n    assert doc.children[1].children[0].content == \"Updated paragraph.\"\n\n\ndef test_complex_nested_formatting(ast_builder):\n    \"\"\"Test deeply nested and complex formatting combinations.\"\"\"\n    test_cases = [\n        # Nested formatting\n        \"**Bold with *italic* and `code` inside**\",\n        \"*Italic with **bold** inside*\",\n        \"`Code with **bold** inside`\",\n\n        # Adjacent formatting\n        \"**Bold**_italic_`code`\",\n        \"*italic*`code`**bold**\",\n\n        # Formatting with links\n        \"**Bold [link](url) text**\",\n        \"*Italic ![image](url) text*\",\n        \"[Link with **bold** text](url)\",\n\n        # Complex nesting\n        \"***Bold italic*** text\",\n        \"**Bold *with italic* and more bold**\",\n        \"*Italic **with bold** and more italic*\",\n    ]\n\n    for markdown in test_cases:\n        doc = ast_builder.build_ast(markdown)\n        # Verify document parses without errors\n        assert doc is not None\n        assert len(doc.children) >= 1\n        paragraph = doc.children[0]\n        assert paragraph.__class__.__name__ == \"MarkdownParagraphNode\"\n\n\ndef test_malformed_formatting_edge_cases(ast_builder):\n    \"\"\"Test handling of malformed or incomplete formatting.\"\"\"\n    test_cases = [\n        # Unclosed formatting\n        \"**Unclosed bold\",\n        \"*Unclosed italic\",\n        \"`Unclosed code\",\n        \"__Unclosed underscore bold\",\n        \"_Unclosed underscore italic\",\n\n        # Empty formatting\n        \"****\",\n        \"**\",\n        \"``\",\n        \"____\",\n        \"__\",\n\n        # Mismatched formatting\n        \"**Bold with *italic**\",\n        \"*Italic with **bold*\",\n\n        # Formatting at boundaries\n        \"**start bold\",\n        \"end bold**\",\n        \"*start italic\",\n        \"end italic*\",\n    ]\n\n    for markdown in test_cases:\n        doc = ast_builder.build_ast(markdown)\n        # Verify document parses without errors\n        assert doc is not None\n        assert len(doc.children) >= 1\n\n\ndef test_complex_link_parentheses(ast_builder):\n    \"\"\"Test links with nested parentheses in URLs (tests _find_closing_parenthesis).\"\"\"\n    test_cases = [\n        \"[Link](http://example.com/path(with)parentheses)\",\n        \"[Link](http://example.com/path(nested(deep)parentheses))\",\n        \"[Link](url(a(b(c)b)a))\",\n        \"![Image](image(1).jpg)\",\n        \"![Image](path/to/image(version)(2).png)\",\n        \"[Complex](http://site.com/api/func(param1(nested)param2))\",\n    ]\n\n    for markdown in test_cases:\n        doc = ast_builder.build_ast(markdown)\n        paragraph = doc.children[0]\n\n        if markdown.startswith('!'):\n            # Image\n            image = paragraph.children[0]\n            assert image.__class__.__name__ == \"MarkdownImageNode\"\n            assert '(' in image.url and ')' in image.url\n\n        else:\n            # Link\n            link = paragraph.children[0]\n            assert link.__class__.__name__ == \"MarkdownLinkNode\"\n            assert '(' in link.url and ')' in link.url\n\n\ndef test_inline_code_with_formatting_inside(ast_builder):\n    \"\"\"Test inline code that contains formatting characters.\"\"\"\n    test_cases = [\n        \"`code with **asterisks**`\",\n        \"`code with *single asterisk*`\",\n        \"`code with __underscores__`\",\n        \"`code with _single underscore_`\",\n        \"`code with [brackets](url)`\",\n        \"`code with ![image](url)`\",\n    ]\n\n    for markdown in test_cases:\n        doc = ast_builder.build_ast(markdown)\n        paragraph = doc.children[0]\n        code_node = paragraph.children[0]\n        assert code_node.__class__.__name__ == \"MarkdownInlineCodeNode\"\n        # Content should be preserved as-is without formatting\n        assert \"**\" in code_node.content or \"*\" in code_node.content or \"__\" in code_node.content or \"_\" in code_node.content or \"[\" in code_node.content\n\n\ndef test_incomplete_link_info(ast_builder):\n    \"\"\"Test handling of links with incomplete or malformed information.\"\"\"\n    test_cases = [\n        \"[Incomplete link](http://example.com\",\n        \"[Incomplete link(http://example.com\",\n        \"[Link with empty URL](\",\n        \"![Incomplete image](image.jpg\",\n        \"![Incomplete image(image.jpg\",\n    ]\n\n    for markdown in test_cases:\n        doc = ast_builder.build_ast(markdown)\n        paragraph = doc.children[0]\n        assert len(paragraph.children) == 1\n        image = paragraph.children[0]\n        assert image.__class__.__name__ == \"MarkdownTextNode\"\n\n\ndef test_code_block_with_programming_languages(ast_builder):\n    \"\"\"Test code blocks with various programming languages.\"\"\"\n    # Test Python with incomplete statements that should continue\n    python_code = '''```python\ndef incomplete_function(\n    param1,\n    param2\n):\n    str = \"\"\"\nThis is a multi-line string that should trigger a continuation\n\"\"\"\n    if condition:\n        return value\n```'''\n\n    # Test JavaScript with objects\n    js_code = '''```javascript\n/*\nconst obj = {\n    property1: value1,\n    property2: {\n        nested: true\n    }\n*/\n};\n```'''\n\n    # Test C++ with templates\n    cpp_code = '''```cpp\ntemplate<typename T>\nclass MyClass {\npublic:\n    T getValue() {\n        return value;\n    }\n\n/*\n * This is a continued comment.\n */\n};\n```'''\n\n    # Test for text.\n    text_code = '''```text\nthis is text\nand more text\n```'''\n\n    for code in [python_code, js_code, cpp_code, text_code]:\n        doc = ast_builder.build_ast(code)\n        assert len(doc.children) == 1\n        code_block = doc.children[0]\n        assert code_block.__class__.__name__ == \"MarkdownCodeBlockNode\"\n        assert len(code_block.content.strip()) > 0\n\n\ndef test_code_block_continuation_edge_cases(ast_builder):\n    \"\"\"Test edge cases in code block continuation parsing.\"\"\"\n    # Code block with nested fences\n    nested_fences = '''```\nOuter code block\n  ```\n  Nested code block\n  ```\nOuter code block continues\n```'''\n\n    doc = ast_builder.build_ast(nested_fences)\n    assert len(doc.children) == 1\n    code_block = doc.children[0]\n    assert code_block.__class__.__name__ == \"MarkdownCodeBlockNode\"\n    assert \"Nested code block\" in code_block.content\n\n\ndef test_code_block_with_mixed_content(ast_builder):\n    \"\"\"Test code blocks containing markdown-like content.\"\"\"\n    code_with_markdown = '''```\n# This looks like a heading\n- This looks like a list\n**This looks like bold**\n[This looks like a link](url)\n```'''\n\n    doc = ast_builder.build_ast(code_with_markdown)\n    assert len(doc.children) == 1\n    code_block = doc.children[0]\n    assert code_block.__class__.__name__ == \"MarkdownCodeBlockNode\"\n    # Content should be preserved as-is\n    assert \"# This looks like a heading\" in code_block.content\n    assert \"- This looks like a list\" in code_block.content\n\n\ndef test_loose_vs_tight_ordered_lists(ast_builder):\n    \"\"\"Test detection of loose vs tight ordered lists.\"\"\"\n    # Tight list (no blank lines)\n    tight_list = \"\"\"1. Item 1\n2. Item 2\n3. Item 3\"\"\"\n\n    # Loose list (with blank lines)\n    loose_list = \"\"\"1. Item 1\n\n2. Item 2\n\n3. Item 3\"\"\"\n\n    # Mixed scenario - becomes loose due to blank line\n    mixed_list = \"\"\"1. Item 1\n2. Item 2\n\n3. Item 3\"\"\"\n\n    # Test tight list\n    doc = ast_builder.build_ast(tight_list)\n    assert len(doc.children) == 1\n    list_node = doc.children[0]\n    assert list_node.__class__.__name__ == \"MarkdownOrderedListNode\"\n    assert list_node.tight is True\n\n    # Test loose list\n    doc = ast_builder.build_ast(loose_list)\n    list_node = doc.children[0]\n    assert list_node.tight is False\n\n    # Test mixed list\n    doc = ast_builder.build_ast(mixed_list)\n    list_node = doc.children[0]\n    assert list_node.tight is False\n\n\ndef test_loose_vs_tight_unordered_lists(ast_builder):\n    \"\"\"Test detection of loose vs tight unordered lists.\"\"\"\n    # Tight list (no blank lines)\n    tight_list = \"\"\"- Item 1\n- Item 2\n- Item 3\"\"\"\n\n    # Loose list (with blank lines)\n    loose_list = \"\"\"- Item 1\n\n- Item 2\n\n- Item 3\"\"\"\n\n    # Mixed scenario - becomes loose due to blank line\n    mixed_list = \"\"\"- Item 1\n- Item 2\n\n- Item 3\"\"\"\n\n    # Test tight list\n    doc = ast_builder.build_ast(tight_list)\n    assert len(doc.children) == 1\n    list_node = doc.children[0]\n    assert list_node.__class__.__name__ == \"MarkdownUnorderedListNode\"\n    assert list_node.tight is True\n\n    # Test loose list\n    doc = ast_builder.build_ast(loose_list)\n    list_node = doc.children[0]\n    assert list_node.tight is False\n\n    # Test mixed list\n    doc = ast_builder.build_ast(mixed_list)\n    list_node = doc.children[0]\n    assert list_node.tight is False\n\ndef test_complex_nested_list_structures(ast_builder):\n    \"\"\"Test complex nested list scenarios.\"\"\"\n    complex_nested = \"\"\"- Level 1 Item 1\n  - Level 2 Item 1\n    - Level 3 Item 1\n    - Level 3 Item 2\n  - Level 2 Item 2\n- Level 1 Item 2\n  1. Ordered nested item 1\n  2. Ordered nested item 2\n- Level 1 Item 3\"\"\"\n\n    doc = ast_builder.build_ast(complex_nested)\n    assert len(doc.children) == 1\n    main_list = doc.children[0]\n    assert main_list.__class__.__name__ == \"MarkdownUnorderedListNode\"\n    assert len(main_list.children) == 3\n\n    # Check first item has nested unordered list\n    first_item = main_list.children[0]\n    assert len(first_item.children) == 2  # paragraph + nested list\n    nested_list = first_item.children[1]\n    assert nested_list.__class__.__name__ == \"MarkdownUnorderedListNode\"\n\n    # Check second item has nested ordered list\n    second_item = main_list.children[1]\n    assert len(second_item.children) == 2  # paragraph + nested list\n    ordered_nested = second_item.children[1]\n    assert ordered_nested.__class__.__name__ == \"MarkdownOrderedListNode\"\n\ndef test_list_continuation_and_interruption(ast_builder):\n    \"\"\"Test text continuation within lists and list interruption.\"\"\"\n    # List with continued text\n    list_with_continuation = \"\"\"- First list item\n  continues on this line\n  and this line too\n- Second list item\n  also continues\"\"\"\n\n    doc = ast_builder.build_ast(list_with_continuation)\n    assert len(doc.children) == 1\n    list_node = doc.children[0]\n\n    # First item should have continued text\n    first_item = list_node.children[0]\n    first_paragraph = first_item.children[0]\n    assert \"continues on this line\" in first_paragraph.children[2].content\n\n    # List interrupted by other content\n    interrupted_list = \"\"\"- Item 1\n- Item 2\n\nNot a list item\n\n- Item 3\"\"\"\n\n    doc = ast_builder.build_ast(interrupted_list)\n    # Should create two separate lists with paragraph in between\n    assert len(doc.children) == 3\n    assert doc.children[0].__class__.__name__ == \"MarkdownUnorderedListNode\"\n    assert doc.children[1].__class__.__name__ == \"MarkdownParagraphNode\"\n    assert doc.children[2].__class__.__name__ == \"MarkdownUnorderedListNode\"\n\n\ndef test_ordered_list_with_custom_start(ast_builder):\n    \"\"\"Test ordered lists with non-standard start numbers.\"\"\"\n    custom_start = \"\"\"5. Fifth item\n6. Sixth item\n7. Seventh item\"\"\"\n\n    doc = ast_builder.build_ast(custom_start)\n    assert len(doc.children) == 1\n    list_node = doc.children[0]\n    assert list_node.__class__.__name__ == \"MarkdownOrderedListNode\"\n    assert list_node.start == 5\n\n    complex_lists_with_continuation = \"\"\"- First list item\n  continues on this line\n  and this line too\n  1. Indented\n  2. Indented\n  And back here\n- Second list item  \n  also continues\"\"\"\n\n    doc = ast_builder.build_ast(complex_lists_with_continuation)\n    assert len(doc.children) == 1\n    list_node = doc.children[0]\n\n    # First item should have continued text\n    first_item = list_node.children[0]\n    first_paragraph = first_item.children[0]\n    assert \"continues on this line\" in first_paragraph.children[2].content\n\n\ndef test_table_alignment_variations(ast_builder):\n    \"\"\"Test different table column alignments.\"\"\"\n    table_markdown = \"\"\"| Left | Center | Right |\n|:-----|:------:|------:|\n| L1   | C1     | R1    |\n| L2   | C2     | R2    |\"\"\"\n\n    doc = ast_builder.build_ast(table_markdown)\n    assert len(doc.children) == 1\n    table = doc.children[0]\n    assert table.__class__.__name__ == \"MarkdownTableNode\"\n\n    # Check header row for alignment\n    header = table.children[0]\n    header_row = header.children[0]\n\n    # Verify alignment is set correctly on cells\n    left_cell = header_row.children[0]\n    center_cell = header_row.children[1]\n    right_cell = header_row.children[2]\n\n    assert left_cell.alignment == \"left\"\n    assert center_cell.alignment == \"center\"\n    assert right_cell.alignment == \"right\"\n\n    # Check body row alignment matches\n    body = table.children[1]\n    body_row = body.children[0]\n\n    body_left_cell = body_row.children[0]\n    body_center_cell = body_row.children[1]\n    body_right_cell = body_row.children[2]\n\n    assert body_left_cell.alignment == \"left\"\n    assert body_center_cell.alignment == \"center\"\n    assert body_right_cell.alignment == \"right\"\n\n\ndef test_double_header_row(ast_builder):\n    \"\"\"Test different table column alignments.\"\"\"\n    table_markdown = \"\"\"| Left | Center | Right |\n| Lef2 | Cen2   | Rig2  |\n|------|--------|-------|\n| L1   | C1     | R1    |\n| L2   | C2     | R2    |\"\"\"\n\n    doc = ast_builder.build_ast(table_markdown)\n    assert len(doc.children) == 2\n    text = doc.children[0]\n    assert text.__class__.__name__ == \"MarkdownParagraphNode\"\n\n    table = doc.children[1]\n    assert table.__class__.__name__ == \"MarkdownTableNode\"\n\n    # Check header row for alignment\n    header = table.children[0]\n    header_row = header.children[0]\n\n    # Verify alignment is set correctly on cells\n    left_cell = header_row.children[0]\n    center_cell = header_row.children[1]\n    right_cell = header_row.children[2]\n\n    assert left_cell.children[0].content == \"Lef2\"\n    assert center_cell.children[0].content == \"Cen2\"\n    assert right_cell.children[0].content == \"Rig2\"\n\n\ndef test_incomplete_table_alignment_variations(ast_builder):\n    \"\"\"Test different table column alignments.\"\"\"\n    table_markdown = \"\"\"| Left | Center | Right |\n|:-----|:------:|------:|\"\"\"\n\n    doc = ast_builder.build_ast(table_markdown)\n    assert len(doc.children) == 2\n    line0 = doc.children[0]\n    assert line0.__class__.__name__ == \"MarkdownParagraphNode\"\n    assert line0.children[0].content == \"| Left | Center | Right |\"\n    line1 = doc.children[1]\n    assert line1.__class__.__name__ == \"MarkdownParagraphNode\"\n    assert line1.children[0].content == \"|:-----|:------:|------:|\"\n\n\ndef test_solitary_table_separator(ast_builder):\n    \"\"\"Test different table column alignments.\"\"\"\n    table_markdown = \"\"\"|:-----|:------:|------:|\"\"\"\n\n    doc = ast_builder.build_ast(table_markdown)\n    assert len(doc.children) == 1\n    line0 = doc.children[0]\n    assert line0.__class__.__name__ == \"MarkdownParagraphNode\"\n    assert line0.children[0].content == \"|:-----|:------:|------:|\"\n\n\ndef test_table_with_complex_content(ast_builder):\n    \"\"\"Test tables containing formatted text.\"\"\"\n    complex_table = \"\"\"| **Bold** | *Italic* | `Code` |\n|----------|----------|--------|\n| **B1**   | *I1*     | `C1`   |\n| [Link](url) | ![Image](img.jpg) | Normal |\"\"\"\n\n    doc = ast_builder.build_ast(complex_table)\n    assert len(doc.children) == 1\n    table = doc.children[0]\n    assert table.__class__.__name__ == \"MarkdownTableNode\"\n\n    # Check header contains formatted content\n    header = table.children[0]\n    header_row = header.children[0]\n\n    # First header cell should contain bold text\n    bold_cell = header_row.children[0]\n    assert len(bold_cell.children) == 1\n    assert bold_cell.children[0].__class__.__name__ == \"MarkdownBoldNode\"\n\n    # Second header cell should contain italic text\n    italic_cell = header_row.children[1]\n    assert len(italic_cell.children) == 1\n    assert italic_cell.children[0].__class__.__name__ == \"MarkdownEmphasisNode\"\n\n    # Third header cell should contain code\n    code_cell = header_row.children[2]\n    assert len(code_cell.children) == 1\n    assert code_cell.children[0].__class__.__name__ == \"MarkdownInlineCodeNode\"\n\n\ndef test_table_edge_cases(ast_builder):\n    \"\"\"Test table parsing edge cases.\"\"\"\n    # Table with missing cells\n    uneven_table = \"\"\"| Col1 | Col2 | Col3 | Col4 |\n|------|------|------|\n| A1   | A2   |\n| B1   | B2   | B3   | B4 |\"\"\"\n\n    doc = ast_builder.build_ast(uneven_table)\n    assert len(doc.children) == 1\n    table = doc.children[0]\n    assert table.__class__.__name__ == \"MarkdownTableNode\"\n\n    # Should handle uneven rows gracefully\n    body = table.children[1]\n    assert len(body.children) == 2  # Two body rows\n\n\ndef test_paragraph_continuation(ast_builder):\n    \"\"\"Test paragraph continuation across multiple lines.\"\"\"\n    paragraph_continuation = \"\"\"This is the first line\nand this continues the same paragraph\nwith even more text on this line.\"\"\"\n\n    doc = ast_builder.build_ast(paragraph_continuation)\n    assert len(doc.children) == 1\n    paragraph = doc.children[0]\n    assert paragraph.__class__.__name__ == \"MarkdownParagraphNode\"\n\n    # Should contain all text with spaces between lines\n    full_text = \"\"\n    for child in paragraph.children:\n        if child.__class__.__name__ == \"MarkdownTextNode\":\n            full_text += child.content\n\n    assert \"This is the first line\" in full_text\n    assert \"and this continues\" in full_text\n    assert \"with even more text\" in full_text\n\n\ndef test_list_item_continuation(ast_builder):\n    \"\"\"Test text continuation within list items.\"\"\"\n    list_continuation = \"\"\"- First list item\n  continues on this line\n  and continues further\n- Second list item\n  also continues here\"\"\"\n\n    doc = ast_builder.build_ast(list_continuation)\n    assert len(doc.children) == 1\n    list_node = doc.children[0]\n\n    # First item should contain continued text\n    first_item = list_node.children[0]\n    first_paragraph = first_item.children[0]\n\n    # Extract all text content\n    full_text = \"\"\n    for child in first_paragraph.children:\n        if child.__class__.__name__ == \"MarkdownTextNode\":\n            full_text += child.content\n\n    assert \"First list item\" in full_text\n    assert \"continues on this line\" in full_text\n    assert \"and continues further\" in full_text\n\n\ndef test_continuation_with_line_breaks(ast_builder):\n    \"\"\"Test text continuation with explicit line breaks.\"\"\"\n    text_with_breaks = \"\"\"First line  \nSecond line with break\nThird line continues normally\"\"\"\n\n    doc = ast_builder.build_ast(text_with_breaks)\n    assert len(doc.children) == 1\n    paragraph = doc.children[0]\n\n    # Should contain line break node\n    has_line_break = False\n    for child in paragraph.children:\n        if child.__class__.__name__ == \"MarkdownLineBreakNode\":\n            has_line_break = True\n            break\n\n    assert has_line_break\n\n\ndef test_continuation_edge_cases(ast_builder):\n    \"\"\"Test edge cases in text continuation.\"\"\"\n    # Continuation after different elements\n    mixed_continuation = \"\"\"# Heading\n\nParagraph starts here\nand continues on next line\n\n- List item\n  continues here\n  \nAnother paragraph\ncontinues normally\"\"\"\n\n    doc = ast_builder.build_ast(mixed_continuation)\n    # Should have heading, paragraph, list, line break, and another paragraph\n    assert len(doc.children) == 5\n    assert doc.children[0].__class__.__name__ == \"MarkdownHeadingNode\"\n    assert doc.children[1].__class__.__name__ == \"MarkdownParagraphNode\"\n    assert doc.children[2].__class__.__name__ == \"MarkdownUnorderedListNode\"\n    assert doc.children[3].__class__.__name__ == \"MarkdownLineBreakNode\"\n    assert doc.children[4].__class__.__name__ == \"MarkdownParagraphNode\"\n\n\ndef test_unclosed_code_block(ast_builder):\n    \"\"\"Test handling of unclosed code blocks.\"\"\"\n    markdown = \"\"\"```python\ndef unclosed_function():\n    print(\"This code block is not closed\")\n\"\"\"\n    doc = ast_builder.build_ast(markdown)\n    assert len(doc.children) == 1\n    code_block = doc.children[0]\n    assert code_block.__class__.__name__ == \"MarkdownCodeBlockNode\"\n    assert code_block.language == \"python\"\n\n\ndef test_nested_code_blocks(ast_builder):\n    \"\"\"Test handling of nested code blocks.\"\"\"\n    markdown = \"\"\"```\nOuter code block\n  ```\n  Nested code block\n  ```\nOuter code block continues\n```\n\"\"\"\n    doc = ast_builder.build_ast(markdown)\n    assert len(doc.children) == 1\n    code_block = doc.children[0]\n    assert code_block.__class__.__name__ == \"MarkdownCodeBlockNode\"\n    assert \"Nested code block\" in code_block.content\n\n\ndef test_incomplete_table(ast_builder):\n    \"\"\"Test handling of incomplete tables.\"\"\"\n    markdown = \"\"\"\n| Header 1 | Header 2 |\n|----------|----------|\n\"\"\"\n    doc = ast_builder.build_ast(markdown)\n    # The AST builder should not create a table without any body rows\n    assert len(doc.children) == 2\n    assert doc.children[0].__class__.__name__ == \"MarkdownParagraphNode\"\n    assert doc.children[1].__class__.__name__ == \"MarkdownParagraphNode\"\n\n\ndef test_invalid_table_separator(ast_builder):\n    \"\"\"Test handling of invalid table separators.\"\"\"\n    markdown = \"\"\"\n| Header 1 | Header 2 |\n| Invalid | Separator |\n| Cell 1   | Cell 2   |\n\"\"\"\n    doc = ast_builder.build_ast(markdown)\n    # Should be treated as paragraphs\n    assert len(doc.children) == 3\n    assert all(child.__class__.__name__ == \"MarkdownParagraphNode\" for child in doc.children)\n\n\ndef test_mixed_list_markers(ast_builder):\n    \"\"\"Test lists with mixed markers.\"\"\"\n    mixed_markers = \"\"\"- Item with dash\n* Item with asterisk\n+ Item with plus\n- Back to dash\"\"\"\n\n    doc = ast_builder.build_ast(mixed_markers)\n    # Should create separate lists for different markers\n    assert len(doc.children) >= 1\n    # All should be unordered lists\n    for child in doc.children:\n        assert child.__class__.__name__ == \"MarkdownUnorderedListNode\"\n\n\ndef test_empty_elements(ast_builder):\n    \"\"\"Test handling of empty elements.\"\"\"\n    empty_elements = \"\"\"\n\n\n# \n\n**\n\n[]()\n\n![]()\n\n```\n```\n\n| |\n|-|\n| |\n\"\"\"\n    doc = ast_builder.build_ast(empty_elements)\n    # Should handle empty elements gracefully without crashing\n    assert doc is not None\n    assert len(doc.children) >= 0\n\n\n@pytest.fixture\ndef ast_builder():\n    \"\"\"Fixture providing a markdown AST builder instance.\"\"\"\n    return MarkdownASTBuilder(no_underscores=False)\n\n\ndef test_first_update_with_none_previous(ast_builder):\n    \"\"\"Test update_ast when previous_text is None (first update).\"\"\"\n    text = \"# Initial heading\\n\\nInitial paragraph.\"\n\n    # First update with None previous text should build from scratch\n    doc = ast_builder.update_ast(text, None)\n\n    assert doc is not None\n    assert len(doc.children) == 2\n    assert doc.children[0].__class__.__name__ == \"MarkdownHeadingNode\"\n    assert doc.children[0].children[0].content == \"Initial heading\"\n    assert doc.children[1].__class__.__name__ == \"MarkdownParagraphNode\"\n    assert doc.children[1].children[0].content == \"Initial paragraph.\"\n\n\ndef test_update_with_empty_document(ast_builder):\n    \"\"\"Test update_ast when document is empty.\"\"\"\n    previous = \"\"\n    new_text = \"# New heading\"\n\n    # Build empty document first\n    ast_builder.build_ast(previous)\n\n    # Update with new content\n    doc = ast_builder.update_ast(new_text, previous)\n\n    assert len(doc.children) == 1\n    assert doc.children[0].__class__.__name__ == \"MarkdownHeadingNode\"\n    assert doc.children[0].children[0].content == \"New heading\"\n\n\ndef test_update_to_empty_document(ast_builder):\n    \"\"\"Test update_ast when updating to empty content.\"\"\"\n    previous = \"# Heading to remove\\n\\nParagraph to remove.\"\n    new_text = \"\"\n\n    # Build initial document\n    ast_builder.build_ast(previous)\n\n    # Update to empty\n    doc = ast_builder.update_ast(new_text, previous)\n\n    assert len(doc.children) == 0\n\n\ndef test_simple_text_change(ast_builder):\n    \"\"\"Test simple text content changes.\"\"\"\n    previous = \"# Original heading\\n\\nOriginal paragraph.\"\n    new_text = \"# Updated heading\\n\\nUpdated paragraph.\"\n\n    # Build original\n    ast_builder.build_ast(previous)\n\n    # Update\n    doc = ast_builder.update_ast(new_text, previous)\n\n    assert doc.children[0].children[0].content == \"Updated heading\"\n    assert doc.children[1].children[0].content == \"Updated paragraph.\"\n\n\ndef test_heading_level_change(ast_builder):\n    \"\"\"Test changing heading levels.\"\"\"\n    previous = \"# Level 1\\n## Level 2\\n### Level 3\"\n    new_text = \"## Level 2\\n# Level 1\\n#### Level 4\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    assert len(doc.children) == 3\n    assert doc.children[0].level == 2\n    assert doc.children[1].level == 1\n    assert doc.children[2].level == 4\n\n\ndef test_structure_type_change(ast_builder):\n    \"\"\"Test changing element types (heading to paragraph, etc.).\"\"\"\n    previous = \"# Heading\\n\\nParagraph\\n\\n- List item\"\n    new_text = \"Regular text\\n\\n## New heading\\n\\nNew paragraph\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    assert len(doc.children) == 3\n    assert doc.children[0].__class__.__name__ == \"MarkdownParagraphNode\"\n    assert doc.children[1].__class__.__name__ == \"MarkdownHeadingNode\"\n    assert doc.children[1].level == 2\n    assert doc.children[2].__class__.__name__ == \"MarkdownParagraphNode\"\n\n\ndef test_add_content_beginning(ast_builder):\n    \"\"\"Test adding content at the beginning.\"\"\"\n    previous = \"# Existing heading\\n\\nExisting paragraph.\"\n    new_text = \"# New first heading\\n\\nNew paragraph.\\n\\n# Existing heading\\n\\nExisting paragraph.\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    assert len(doc.children) == 4\n    assert doc.children[0].children[0].content == \"New first heading\"\n    assert doc.children[2].children[0].content == \"Existing heading\"\n\n\ndef test_add_content_middle(ast_builder):\n    \"\"\"Test adding content in the middle.\"\"\"\n    previous = \"# First\\n\\n# Third\"\n    new_text = \"# First\\n\\n# Second\\n\\n# Third\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    assert len(doc.children) == 3\n    assert doc.children[0].children[0].content == \"First\"\n    assert doc.children[1].children[0].content == \"Second\"\n    assert doc.children[2].children[0].content == \"Third\"\n\n\ndef test_add_content_end(ast_builder):\n    \"\"\"Test adding content at the end.\"\"\"\n    previous = \"# Existing heading\"\n    new_text = \"# Existing heading\\n\\n# New ending\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    assert len(doc.children) == 2\n    assert doc.children[0].children[0].content == \"Existing heading\"\n    assert doc.children[1].children[0].content == \"New ending\"\n\n\ndef test_remove_content_beginning(ast_builder):\n    \"\"\"Test removing content from the beginning.\"\"\"\n    previous = \"# Remove me\\n\\n# Keep me\\n\\nKeep this paragraph.\"\n    new_text = \"# Keep me\\n\\nKeep this paragraph.\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    assert len(doc.children) == 2\n    assert doc.children[0].children[0].content == \"Keep me\"\n    assert doc.children[1].children[0].content == \"Keep this paragraph.\"\n\n\ndef test_remove_content_middle(ast_builder):\n    \"\"\"Test removing content from the middle.\"\"\"\n    previous = \"# First\\n\\n# Remove me\\n\\n# Last\"\n    new_text = \"# First\\n\\n# Last\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    assert len(doc.children) == 2\n    assert doc.children[0].children[0].content == \"First\"\n    assert doc.children[1].children[0].content == \"Last\"\n\n\ndef test_remove_content_end(ast_builder):\n    \"\"\"Test removing content from the end.\"\"\"\n    previous = \"# Keep me\\n\\n# Remove me\"\n    new_text = \"# Keep me\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    assert len(doc.children) == 1\n    assert doc.children[0].children[0].content == \"Keep me\"\n\n\ndef test_list_modifications(ast_builder):\n    \"\"\"Test modifications to list structures.\"\"\"\n    previous = \"\"\"- Item 1\n- Item 2\n- Item 3\"\"\"\n\n    new_text = \"\"\"- Modified Item 1\n- Item 2\n- Item 3\n- New Item 4\"\"\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    list_node = doc.children[0]\n    assert list_node.__class__.__name__ == \"MarkdownUnorderedListNode\"\n    assert len(list_node.children) == 4\n\n    # Check first item was modified\n    first_item = list_node.children[0]\n    first_paragraph = first_item.children[0]\n    assert first_paragraph.children[0].content == \"Modified Item 1\"\n\n\ndef test_list_type_change(ast_builder):\n    \"\"\"Test changing list types (unordered to ordered).\"\"\"\n    previous = \"\"\"- Item 1\n- Item 2\n- Item 3\"\"\"\n\n    new_text = \"\"\"1. Item 1\n2. Item 2\n3. Item 3\"\"\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    list_node = doc.children[0]\n    assert list_node.__class__.__name__ == \"MarkdownOrderedListNode\"\n    assert len(list_node.children) == 3\n\n\ndef test_nested_list_modifications(ast_builder):\n    \"\"\"Test modifications to nested list structures.\"\"\"\n    previous = \"\"\"- Item 1\n  - Nested 1\n  - Nested 2\n- Item 2\"\"\"\n\n    new_text = \"\"\"- Item 1\n  - Nested 1\n  - Modified Nested 2\n  - New Nested 3\n- Item 2\n- New Item 3\"\"\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    main_list = doc.children[0]\n    assert len(main_list.children) == 3\n\n    # Check nested list was modified\n    first_item = main_list.children[0]\n    nested_list = first_item.children[1]\n    assert len(nested_list.children) == 3\n\n\ndef test_table_modifications(ast_builder):\n    \"\"\"Test modifications to table structures.\"\"\"\n    previous = \"\"\"| Col1 | Col2 |\n|------|------|\n| A1   | A2   |\n| B1   | B2   |\"\"\"\n\n    new_text = \"\"\"| Col1 | Col2 | Col3 |\n|------|------|------|\n| A1   | A2   | A3   |\n| B1   | B2   | B3   |\n| C1   | C2   | C3   |\"\"\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    table = doc.children[0]\n    assert table.__class__.__name__ == \"MarkdownTableNode\"\n\n    # Check header has 3 columns\n    header = table.children[0]\n    header_row = header.children[0]\n    assert len(header_row.children) == 3\n\n    # Check body has 3 rows\n    body = table.children[1]\n    assert len(body.children) == 3\n\n\ndef test_table_to_paragraph_conversion(ast_builder):\n    \"\"\"Test converting table to paragraphs by removing separator.\"\"\"\n    previous = \"\"\"| Col1 | Col2 |\n|------|------|\n| A1   | A2   |\"\"\"\n\n    new_text = \"\"\"| Col1 | Col2 |\n| A1   | A2   |\"\"\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    # Should be converted to paragraphs\n    assert len(doc.children) == 2\n    assert doc.children[0].__class__.__name__ == \"MarkdownParagraphNode\"\n    assert doc.children[1].__class__.__name__ == \"MarkdownParagraphNode\"\n\n\ndef test_code_block_modifications(ast_builder):\n    \"\"\"Test modifications to code blocks.\"\"\"\n    previous = \"\"\"```python\ndef old_function():\n    return \"old\"\n```\"\"\"\n\n    new_text = \"\"\"```python\ndef new_function():\n    return \"new\"\n\ndef another_function():\n    return \"another\"\n```\"\"\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    code_block = doc.children[0]\n    assert code_block.__class__.__name__ == \"MarkdownCodeBlockNode\"\n    assert \"new_function\" in code_block.content\n    assert \"another_function\" in code_block.content\n\n\ndef test_code_block_language_change(ast_builder):\n    \"\"\"Test changing code block language.\"\"\"\n    previous = \"\"\"```python\nprint(\"hello\")\n```\"\"\"\n\n    new_text = \"\"\"```javascript\nconsole.log(\"hello\");\n```\"\"\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    code_block = doc.children[0]\n    assert code_block.language == \"javascript\"\n    assert code_block.content.strip() == 'console.log(\"hello\");'\n\n\ndef test_inline_formatting_changes(ast_builder):\n    \"\"\"Test changes to inline formatting.\"\"\"\n    previous = \"This has **bold** text.\"\n    new_text = \"This has *italic* text.\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    paragraph = doc.children[0]\n    formatting_node = paragraph.children[1]\n    assert formatting_node.__class__.__name__ == \"MarkdownEmphasisNode\"\n\n\ndef test_link_modifications(ast_builder):\n    \"\"\"Test modifications to links.\"\"\"\n    previous = \"Visit [old site](http://old.com) for info.\"\n    new_text = \"Visit [new site](http://new.com) for info.\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    paragraph = doc.children[0]\n    link = paragraph.children[1]\n    assert link.__class__.__name__ == \"MarkdownLinkNode\"\n    assert link.url == \"http://new.com\"\n    assert link.children[0].content == \"new site\"\n\n\ndef test_image_modifications(ast_builder):\n    \"\"\"Test modifications to images.\"\"\"\n    previous = \"![old alt](old.jpg)\"\n    new_text = \"![new alt](new.jpg \\\"New title\\\")\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    paragraph = doc.children[0]\n    image = paragraph.children[0]\n    assert image.__class__.__name__ == \"MarkdownImageNode\"\n    assert image.url == \"new.jpg\"\n    assert image.alt_text == \"new alt\"\n    assert image.title == \"New title\"\n\n\ndef test_horizontal_rule_changes(ast_builder):\n    \"\"\"Test changes involving horizontal rules.\"\"\"\n    previous = \"Before\\n\\n---\\n\\nAfter\"\n    new_text = \"Before\\n\\nMiddle\\n\\nAfter\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    assert len(doc.children) == 3\n    assert doc.children[0].__class__.__name__ == \"MarkdownParagraphNode\"\n    assert doc.children[1].__class__.__name__ == \"MarkdownParagraphNode\"\n    assert doc.children[1].children[0].content == \"Middle\"\n    assert doc.children[2].__class__.__name__ == \"MarkdownParagraphNode\"\n\n\ndef test_multiple_updates_sequence(ast_builder):\n    \"\"\"Test a sequence of multiple updates.\"\"\"\n    # Start with simple content\n    content1 = \"# Initial\"\n    doc = ast_builder.update_ast(content1, None)\n    assert len(doc.children) == 1\n\n    # Add content\n    content2 = \"# Initial\\n\\nAdded paragraph.\"\n    doc = ast_builder.update_ast(content2, content1)\n    assert len(doc.children) == 2\n\n    # Modify content\n    content3 = \"# Modified\\n\\nAdded paragraph.\"\n    doc = ast_builder.update_ast(content3, content2)\n    assert doc.children[0].children[0].content == \"Modified\"\n\n    # Remove content\n    content4 = \"# Modified\"\n    doc = ast_builder.update_ast(content4, content3)\n    assert len(doc.children) == 1\n\n\ndef test_line_break_modifications(ast_builder):\n    \"\"\"Test modifications involving line breaks.\"\"\"\n    previous = \"Line 1  \\nLine 2\\nLine 3\"\n    new_text = \"Line 1\\nLine 2  \\nLine 3\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    paragraph = doc.children[0]\n    # Should have line break in different position\n    has_line_break = any(\n        child.__class__.__name__ == \"MarkdownLineBreakNode\"\n        for child in paragraph.children\n    )\n    assert has_line_break\n\n\ndef test_source_path_preservation(ast_builder):\n    \"\"\"Test that source path is preserved during updates.\"\"\"\n    previous = \"# Heading\"\n    new_text = \"# Updated heading\"\n\n    # Build with source path\n    doc = ast_builder.update_ast(previous, None, path=\"/test/path.md\")\n    assert doc.source_path == \"/test/path.md\"\n\n    # Update should preserve path\n    doc = ast_builder.update_ast(new_text, previous, path=\"/test/path.md\")\n    assert doc.source_path == \"/test/path.md\"\n\n\ndef test_complex_document_update(ast_builder):\n    \"\"\"Test updating a complex document with multiple element types.\"\"\"\n    previous = \"\"\"# Document Title\n\nIntroduction paragraph with **bold** and *italic* text.\n\n## Section 1\n\n- List item 1\n- List item 2\n  - Nested item\n\nHere's a [link](http://example.com) and an image:\n![Alt text](image.jpg)\n\n```python\ndef hello():\n    print(\"world\")\n```\n\n| Col1 | Col2 |\n|------|------|\n| A    | B    |\n\n---\n\nFinal paragraph.\"\"\"\n\n    new_text = \"\"\"# Updated Document Title\n\nModified introduction paragraph with **bold** text only.\n\n## Modified Section 1\n\n1. Ordered item 1\n2. Ordered item 2\n   - Mixed nested item\n\nHere's an updated [link](http://newexample.com):\n\n```javascript\nfunction hello() {\n    console.log(\"world\");\n}\n```\n\n| Col1 | Col2 | Col3 |\n|------|------|------|\n| A    | B    | C    |\n| D    | E    | F    |\n\nUpdated final paragraph.\"\"\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    # Verify structure changes\n    assert len(doc.children) > 5  # Should have multiple elements\n\n    # Check title was updated\n    title = doc.children[0]\n    assert title.children[0].content == \"Updated Document Title\"\n\n    # Check list type changed to ordered\n    list_element = None\n    for child in doc.children:\n        if child.__class__.__name__ == \"MarkdownOrderedListNode\":\n            list_element = child\n            break\n    assert list_element is not None\n\n    # Check code block language changed\n    code_element = None\n    for child in doc.children:\n        if child.__class__.__name__ == \"MarkdownCodeBlockNode\":\n            code_element = child\n            break\n    assert code_element is not None\n    assert code_element.language == \"javascript\"\n\n\ndef test_whitespace_only_changes(ast_builder):\n    \"\"\"Test updates that only change whitespace.\"\"\"\n    previous = \"#Heading\\nParagraph.\"\n    new_text = \"# Heading\\n\\nParagraph.\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    # Structure should be the same but properly formatted\n    assert len(doc.children) == 2\n    assert doc.children[0].__class__.__name__ == \"MarkdownHeadingNode\"\n    assert doc.children[1].__class__.__name__ == \"MarkdownParagraphNode\"\n\n\ndef test_identical_content_update(ast_builder):\n    \"\"\"Test updating with identical content.\"\"\"\n    content = \"# Same heading\\n\\nSame paragraph.\"\n\n    ast_builder.build_ast(content)\n    original_doc = ast_builder.document()\n\n    doc = ast_builder.update_ast(content, content)\n\n    # Should return same structure\n    assert len(doc.children) == len(original_doc.children)\n    assert doc.children[0].children[0].content == \"Same heading\"\n\n\ndef test_update_with_malformed_content(ast_builder):\n    \"\"\"Test updates with malformed markdown content.\"\"\"\n    previous = \"# Valid heading\"\n    new_text = \"**Unclosed bold\\n`Unclosed code\\n[Unclosed link(\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    # Should handle malformed content gracefully\n    assert doc is not None\n    assert len(doc.children) >= 1\n\n\ndef test_very_large_content_change(ast_builder):\n    \"\"\"Test updating with very large content changes.\"\"\"\n    # Create large previous content\n    previous_lines = []\n    for i in range(100):\n        previous_lines.append(f\"# Heading {i}\")\n        previous_lines.append(f\"Paragraph {i} content.\")\n        previous_lines.append(\"\")\n    previous = \"\\n\".join(previous_lines)\n\n    # Create completely different large content\n    new_lines = []\n    for i in range(150):\n        new_lines.append(f\"## New Heading {i}\")\n        new_lines.append(f\"- List item {i}\")\n        new_lines.append(\"\")\n    new_text = \"\\n\".join(new_lines)\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    # Should handle large changes without error\n    assert doc is not None\n    assert len(doc.children) > 100\n\n\ndef test_update_preserves_line_mapping(ast_builder):\n    \"\"\"Test that line mapping is properly updated.\"\"\"\n    previous = \"# Line 0\\n\\nLine 2 paragraph.\"\n    new_text = \"# Line 0\\n\\n## Line 2 heading\\n\\nLine 4 paragraph.\"\n\n    ast_builder.build_ast(previous)\n    doc = ast_builder.update_ast(new_text, previous)\n\n    # Verify line mapping exists and has correct entries\n    assert hasattr(ast_builder, '_line_to_node_map')\n    assert len(ast_builder._line_to_node_map) > 0\n\n    # Check specific line mappings\n    assert 0 in ast_builder._line_to_node_map  # First heading\n    assert 2 in ast_builder._line_to_node_map  # Second heading\n    assert 4 in ast_builder._line_to_node_map  # Paragraph\n```\n\nFile: /Users/dave/github/m6r/humbug/tests/markdown/markdown_test_gen.py\n\n```python\n#!/usr/bin/env python\n\"\"\"\nUtility script to generate test fixtures from markdown files.\n\"\"\"\nimport argparse\nimport os\nimport sys\nfrom pathlib import Path\n\nfrom humbug.markdown.markdown_ast_builder import MarkdownASTBuilder\n\n# pylint: disable=unused-import\nimport humbug.syntax.parser_imports\n# pylint: enable=unused-import\n\nfrom tests.markdown.markdown_ast_serializer import save_ast_to_json\n\n\ndef main():\n    \"\"\"Main entry point for the script.\"\"\"\n    parser = argparse.ArgumentParser(description='Generate test fixtures from markdown files.')\n    parser.add_argument('markdown_file', help='Path to the markdown file')\n    parser.add_argument('--no-underscores', action='store_true', help='Disable underscore formatting')\n    parser.add_argument('--output', '-o', help='Output JSON file (defaults to <markdown_file>.json)')\n    parser.add_argument('--line-numbers', action='store_true', help='Include line numbers in output')\n\n    args = parser.parse_args()\n\n    # Determine output file\n    output_file = args.output\n    if not output_file:\n        output_file = os.path.splitext(args.markdown_file)[0] + '.json'\n\n    # Parse the markdown\n    with open(args.markdown_file, 'r', encoding='utf-8') as f:\n        markdown_text = f.read()\n\n    md_ast_builder = MarkdownASTBuilder(no_underscores=args.no_underscores)\n    ast = md_ast_builder.build_ast(markdown_text)\n\n    # Save the AST\n    save_ast_to_json(ast, output_file, include_line_numbers=args.line_numbers)\n    print(f\"Saved AST to {output_file}\")\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\nFile: /Users/dave/github/m6r/humbug/tests/markdown/markdown_test_utils.py\n\n```python\n\"\"\"\nUtility functions for markdown AST builder tests\n\"\"\"\nimport os\nimport json\nfrom pathlib import Path\nimport difflib\nfrom typing import Dict, Any, List, Tuple, Optional\n\nfrom humbug.markdown.markdown_ast_builder import MarkdownASTBuilder\nfrom markdown_ast_serializer import serialize_ast, load_ast_from_json\n\n\ndef get_test_fixtures_dir() -> Path:\n    \"\"\"\n    Get the directory containing test fixtures.\n\n    Returns:\n        Path to the test fixtures directory\n    \"\"\"\n    current_dir = Path(__file__).parent\n    return current_dir / \"fixtures\"\n\n\ndef load_markdown_file(file_path: str) -> str:\n    \"\"\"\n    Load a markdown file.\n\n    Args:\n        file_path: Path to the markdown file\n\n    Returns:\n        The contents of the markdown file\n    \"\"\"\n    with open(file_path, 'r', encoding='utf-8') as f:\n        return f.read()\n\n\ndef find_test_files() -> List[Tuple[str, str]]:\n    \"\"\"\n    Find all test files (markdown files with corresponding JSON files).\n\n    Returns:\n        List of tuples containing (markdown_path, json_path)\n    \"\"\"\n    fixtures_dir = get_test_fixtures_dir()\n    test_files = []\n\n    for root, _, files in os.walk(fixtures_dir):\n        for file in files:\n            if file.endswith('.md'):\n                md_path = os.path.join(root, file)\n                json_path = md_path.replace('.md', '.json')\n\n                if os.path.exists(json_path):\n                    test_files.append((md_path, json_path))\n\n    return test_files\n\n\ndef compare_ast_with_expected(\n    actual_ast: Dict[str, Any],\n    expected_ast: Dict[str, Any]\n) -> Tuple[bool, Optional[str]]:\n    \"\"\"\n    Compare an actual AST with an expected AST.\n\n    Args:\n        actual_ast: The actual AST dictionary\n        expected_ast: The expected AST dictionary\n\n    Returns:\n        Tuple of (is_match, diff_message)\n    \"\"\"\n    # Convert to JSON strings for comparison\n    actual_json = json.dumps(actual_ast, indent=2, sort_keys=True)\n    expected_json = json.dumps(expected_ast, indent=2, sort_keys=True)\n\n    if actual_json == expected_json:\n        return True, None\n\n    # Generate a diff if they don't match\n    diff = difflib.unified_diff(\n        expected_json.splitlines(keepends=True),\n        actual_json.splitlines(keepends=True),\n        fromfile='expected',\n        tofile='actual'\n    )\n\n    diff_message = ''.join(diff)\n    return False, diff_message\n\n\ndef parse_and_compare(\n    markdown_path: str,\n    expected_json_path: str,\n    no_underscores: bool = False\n) -> Tuple[bool, Optional[str]]:\n    \"\"\"\n    Parse a markdown file and compare the result with an expected JSON file.\n\n    Args:\n        markdown_path: Path to the markdown file\n        expected_json_path: Path to the expected JSON file\n        no_underscores: Whether to disable underscore formatting\n\n    Returns:\n        Tuple of (is_match, diff_message)\n    \"\"\"\n    # Load the markdown and parse it\n    markdown_text = load_markdown_file(markdown_path)\n    ast_builder = MarkdownASTBuilder(no_underscores=no_underscores)\n    ast = ast_builder.build_ast(markdown_text)\n\n    # Serialize the AST\n    actual_ast = serialize_ast(ast)\n\n    # Load the expected AST\n    expected_ast = load_ast_from_json(expected_json_path)\n\n    # Compare\n    return compare_ast_with_expected(actual_ast, expected_ast)\n```\n\nFile: /Users/dave/github/m6r/humbug/tests/markdown/markdown_ast_serializer.py\n\n```python\n\"\"\"\nVisitor class for serializing and comparing markdown AST structures\n\"\"\"\nfrom typing import Dict, Any\nimport json\n\nfrom humbug.markdown.markdown_ast_node import (\n    MarkdownASTVisitor, MarkdownASTNode, MarkdownDocumentNode,\n    MarkdownTextNode, MarkdownLineBreakNode, MarkdownEmphasisNode,\n    MarkdownBoldNode, MarkdownHeadingNode, MarkdownParagraphNode,\n    MarkdownOrderedListNode, MarkdownUnorderedListNode, MarkdownListItemNode,\n    MarkdownInlineCodeNode, MarkdownCodeBlockNode, MarkdownTableNode,\n    MarkdownTableHeaderNode, MarkdownTableBodyNode, MarkdownTableRowNode,\n    MarkdownTableCellNode, MarkdownHorizontalRuleNode, MarkdownImageNode,\n    MarkdownLinkNode\n)\n\n\nclass MarkdownASTSerializer(MarkdownASTVisitor):\n    \"\"\"Visitor that serializes the AST structure for comparison.\"\"\"\n\n    def __init__(self, include_line_numbers: bool = False) -> None:\n        \"\"\"\n        Initialize the AST serializer.\n        \n        Args:\n            include_line_numbers: Whether to include line numbers in the serialized output\n        \"\"\"\n        super().__init__()\n        self.include_line_numbers = include_line_numbers\n\n    def _add_line_info(self, result: Dict[str, Any], node: MarkdownASTNode) -> None:\n        \"\"\"Add line information to the result if requested.\"\"\"\n        if not self.include_line_numbers:\n            return\n\n        if node.line_start is not None:\n            result[\"line_start\"] = node.line_start\n\n        if node.line_end is not None:\n            result[\"line_end\"] = node.line_end\n\n    def visit_MarkdownDocumentNode(self, node: MarkdownDocumentNode) -> Dict[str, Any]:\n        \"\"\"Serialize a document node.\"\"\"\n        result = {\n            \"type\": \"document\",\n            \"children\": []\n        }\n\n        if node.source_path:\n            result[\"source_path\"] = node.source_path\n\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownTextNode(self, node: MarkdownTextNode) -> Dict[str, Any]:\n        \"\"\"Serialize a text node.\"\"\"\n        result = {\n            \"type\": \"text\",\n            \"content\": node.content\n        }\n        self._add_line_info(result, node)\n        return result\n\n    def visit_MarkdownLineBreakNode(self, node: MarkdownLineBreakNode) -> Dict[str, Any]:\n        \"\"\"Serialize a line break node.\"\"\"\n        result = {\"type\": \"linebreak\"}\n        self._add_line_info(result, node)\n        return result\n\n    def visit_MarkdownEmphasisNode(self, node: MarkdownEmphasisNode) -> Dict[str, Any]:\n        \"\"\"Serialize an emphasis node.\"\"\"\n        result = {\n            \"type\": \"emphasis\",\n            \"children\": []\n        }\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownBoldNode(self, node: MarkdownBoldNode) -> Dict[str, Any]:\n        \"\"\"Serialize a bold node.\"\"\"\n        result = {\n            \"type\": \"bold\",\n            \"children\": []\n        }\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownHeadingNode(self, node: MarkdownHeadingNode) -> Dict[str, Any]:\n        \"\"\"Serialize a heading node.\"\"\"\n        result = {\n            \"type\": \"heading\",\n            \"level\": node.level,\n            \"id\": node.anchor_id,\n            \"children\": []\n        }\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownParagraphNode(self, node: MarkdownParagraphNode) -> Dict[str, Any]:\n        \"\"\"Serialize a paragraph node.\"\"\"\n        result = {\n            \"type\": \"paragraph\",\n            \"children\": []\n        }\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownOrderedListNode(self, node: MarkdownOrderedListNode) -> Dict[str, Any]:\n        \"\"\"Serialize an ordered list node.\"\"\"\n        result = {\n            \"type\": \"ordered_list\",\n            \"indent\": node.indent,\n            \"start\": node.start,\n            \"children\": []\n        }\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownUnorderedListNode(self, node: MarkdownUnorderedListNode) -> Dict[str, Any]:\n        \"\"\"Serialize an unordered list node.\"\"\"\n        result = {\n            \"type\": \"unordered_list\",\n            \"indent\": node.indent,\n            \"children\": []\n        }\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownListItemNode(self, node: MarkdownListItemNode) -> Dict[str, Any]:\n        \"\"\"Serialize a list item node.\"\"\"\n        result = {\n            \"type\": \"list_item\",\n            \"children\": []\n        }\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownInlineCodeNode(self, node: MarkdownInlineCodeNode) -> Dict[str, Any]:\n        \"\"\"Serialize an inline code node.\"\"\"\n        result = {\n            \"type\": \"inline_code\",\n            \"content\": node.content\n        }\n        self._add_line_info(result, node)\n        return result\n\n    def visit_MarkdownCodeBlockNode(self, node: MarkdownCodeBlockNode) -> Dict[str, Any]:\n        \"\"\"Serialize a code block node.\"\"\"\n        result = {\n            \"type\": \"code_block\",\n            \"language\": node.language,\n            \"content\": node.content\n        }\n        self._add_line_info(result, node)\n        return result\n\n    def visit_MarkdownTableNode(self, node: MarkdownTableNode) -> Dict[str, Any]:\n        \"\"\"Serialize a table node.\"\"\"\n        result = {\n            \"type\": \"table\",\n            \"children\": []\n        }\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownTableHeaderNode(self, node: MarkdownTableHeaderNode) -> Dict[str, Any]:\n        \"\"\"Serialize a table header node.\"\"\"\n        result = {\n            \"type\": \"table_header\",\n            \"children\": []\n        }\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownTableBodyNode(self, node: MarkdownTableBodyNode) -> Dict[str, Any]:\n        \"\"\"Serialize a table body node.\"\"\"\n        result = {\n            \"type\": \"table_body\",\n            \"children\": []\n        }\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownTableRowNode(self, node: MarkdownTableRowNode) -> Dict[str, Any]:\n        \"\"\"Serialize a table row node.\"\"\"\n        result = {\n            \"type\": \"table_row\",\n            \"children\": []\n        }\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownTableCellNode(self, node: MarkdownTableCellNode) -> Dict[str, Any]:\n        \"\"\"Serialize a table cell node.\"\"\"\n        result = {\n            \"type\": \"table_cell\",\n            \"is_header\": node.is_header,\n            \"alignment\": node.alignment,\n            \"children\": []\n        }\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownHorizontalRuleNode(self, node: MarkdownHorizontalRuleNode) -> Dict[str, Any]:\n        \"\"\"Serialize a horizontal rule node.\"\"\"\n        result = {\"type\": \"horizontal_rule\"}\n        self._add_line_info(result, node)\n        return result\n\n    def visit_MarkdownLinkNode(self, node: MarkdownLinkNode) -> Dict[str, Any]:\n        \"\"\"Serialize a link node.\"\"\"\n        result = {\n            \"type\": \"link\",\n            \"url\": node.url,\n            \"children\": []\n        }\n\n        if node.title:\n            result[\"title\"] = node.title\n\n        self._add_line_info(result, node)\n\n        # Visit children\n        children = super().generic_visit(node)\n        result[\"children\"] = children\n\n        return result\n\n    def visit_MarkdownImageNode(self, node: MarkdownImageNode) -> Dict[str, Any]:\n        \"\"\"Serialize an image node.\"\"\"\n        result = {\n            \"type\": \"image\",\n            \"url\": node.url,\n            \"alt_text\": node.alt_text\n        }\n\n        if node.title:\n            result[\"title\"] = node.title\n\n        self._add_line_info(result, node)\n        return result\n\n\ndef serialize_ast(node: MarkdownASTNode, include_line_numbers: bool = False) -> Dict[str, Any]:\n    \"\"\"\n    Serialize an AST node to a dictionary.\n\n    Args:\n        node: The AST node to serialize\n        include_line_numbers: Whether to include line numbers in the output\n\n    Returns:\n        A dictionary representation of the AST\n    \"\"\"\n    serializer = MarkdownASTSerializer(include_line_numbers)\n    return serializer.visit(node)\n\n\ndef save_ast_to_json(node: MarkdownASTNode, file_path: str, include_line_numbers: bool = False) -> None:\n    \"\"\"\n    Save an AST node to a JSON file.\n\n    Args:\n        node: The AST node to serialize\n        file_path: The path to save the JSON file to\n        include_line_numbers: Whether to include line numbers in the output\n    \"\"\"\n    serialized = serialize_ast(node, include_line_numbers)\n    with open(file_path, 'w', encoding='utf-8') as f:\n        json.dump(serialized, f, indent=2)\n\n\ndef load_ast_from_json(file_path: str) -> Dict[str, Any]:\n    \"\"\"\n    Load an AST from a JSON file.\n\n    Args:\n        file_path: The path to the JSON file\n\n    Returns:\n        A dictionary representation of the AST\n    \"\"\"\n    with open(file_path, 'r', encoding='utf-8') as f:\n        return json.load(f)\n```\n\nFile: /Users/dave/github/m6r/humbug/tests/markdown/conftest.py\n\n```python\nimport os\nimport sys\nfrom pathlib import Path\n\n# Add the src directory to Python path\nproject_root = Path(__file__).parent.parent\nsys.path.insert(0, str(project_root / \"src\"))\n```\n\n# Action:\n\nIn the current design I have a markdown AST builder class that has excellent test coverage.  The important part\nof this comes from using the markdown_test_gen.py script to create a reference JSON output from a \".md\" file.\n\nThis is used within the unit test framework, which uses pytest.\n\nI would like to add unit tests that make use of the parser_registry.py file's parser registry to create parsers\nbased on a programming language file extension, the generate a token stream and that checks the token stream\nmatches the reference JSON output from a new syntax_test_gen.py script.  The logic for this should be added\nto a new unit test file, but that test file does not currently need any other tests.\n\nIs this requirement clear?  Do you have all the files you require?  If yes, then please propose a set of design\nchanges to meet it.",
      "completed": true,
      "usage": null,
      "error": null,
      "model": null,
      "temperature": null
    },
    {
      "id": "d89b8560-da2a-4f27-83ae-33c3617cb11b",
      "timestamp": "2025-06-12T06:14:47.362478",
      "type": "ai_response",
      "content": "Yes, the requirement is clear! You want to create a unit testing framework for syntax parsers that mirrors your existing markdown AST testing approach. Let me analyze what you have and propose the design changes needed.\n\n## Current State Analysis\n\nI can see you have:\n- A well-tested markdown AST builder with JSON reference generation\n- A parser registry system for different programming languages\n- Existing parsers (like CParser) that produce token streams\n- A test generation script (`markdown_test_gen.py`) for creating reference outputs\n\n## Missing Components\n\nI notice I don't have access to the base AST classes (`humbug.ast.ast`) that define `ASTNode` and `ASTVisitor`, but I can infer their structure from usage patterns.\n\n## Proposed Design Changes\n\n### 1. Create `syntax_test_gen.py` Script\n\n**File:** `/Users/dave/github/m6r/humbug/tests/syntax/syntax_test_gen.py`\n\n```python\n#!/usr/bin/env python\n\"\"\"\nUtility script to generate test fixtures from source code files using the parser registry.\n\"\"\"\nimport argparse\nimport os\nfrom pathlib import Path\n\nfrom humbug.syntax.parser_registry import ParserRegistry\nfrom humbug.syntax.programming_language_utils import ProgrammingLanguageUtils\n\n# Import all parsers to ensure registry is populated\nimport humbug.syntax.parser_imports\n\nfrom syntax_test_serializer import save_tokens_to_json\n\n\ndef main():\n    \"\"\"Main entry point for the script.\"\"\"\n    parser = argparse.ArgumentParser(description='Generate test fixtures from source code files.')\n    parser.add_argument('source_file', help='Path to the source code file')\n    parser.add_argument('--output', '-o', help='Output JSON file (defaults to <source_file>.json)')\n    parser.add_argument('--language', '-l', help='Override language detection (use language name or extension)')\n\n    args = parser.parse_args()\n\n    # Determine output file\n    output_file = args.output\n    if not output_file:\n        output_file = args.source_file + '.json'\n\n    # Determine programming language\n    if args.language:\n        language = ProgrammingLanguageUtils.from_name(args.language)\n    else:\n        language = ProgrammingLanguageUtils.from_file_extension(args.source_file)\n\n    if language.name == 'UNKNOWN':\n        print(f\"Error: Could not determine programming language for {args.source_file}\")\n        print(\"Use --language to specify the language explicitly\")\n        return 1\n\n    # Read the source file\n    try:\n        with open(args.source_file, 'r', encoding='utf-8') as f:\n            source_text = f.read()\n    except FileNotFoundError:\n        print(f\"Error: File not found: {args.source_file}\")\n        return 1\n    except UnicodeDecodeError:\n        print(f\"Error: Could not decode file as UTF-8: {args.source_file}\")\n        return 1\n\n    # Create parser and parse the source\n    parser_instance = ParserRegistry.create_parser(language)\n    if parser_instance is None:\n        print(f\"Error: No parser available for language: {language.name}\")\n        return 1\n\n    try:\n        parser_state = parser_instance.parse(None, source_text)\n        \n        # Extract tokens from parser\n        tokens = []\n        while True:\n            token = parser_instance.get_next_token()\n            if token is None:\n                break\n            tokens.append(token)\n\n        # Save the tokens\n        save_tokens_to_json(tokens, parser_state, output_file, language, args.source_file)\n        print(f\"Saved {len(tokens)} tokens to {output_file}\")\n        return 0\n\n    except Exception as e:\n        print(f\"Error parsing {args.source_file}: {e}\")\n        return 1\n\n\nif __name__ == \"__main__\":\n    exit(main())\n```\n\n### 2. Create Token Serializer\n\n**File:** `/Users/dave/github/m6r/humbug/tests/syntax/syntax_test_serializer.py`\n\n```python\n\"\"\"\nSerializer for syntax parser tokens and parser state for test comparison.\n\"\"\"\nimport json\nfrom typing import List, Dict, Any, Optional\n\nfrom humbug.syntax.lexer import Token\nfrom humbug.syntax.parser import ParserState\nfrom humbug.syntax.programming_language import ProgrammingLanguage\n\n\ndef serialize_token(token: Token) -> Dict[str, Any]:\n    \"\"\"\n    Serialize a token to a dictionary.\n\n    Args:\n        token: The token to serialize\n\n    Returns:\n        Dictionary representation of the token\n    \"\"\"\n    return {\n        \"type\": token.type.name,\n        \"value\": token.value,\n        \"start\": token.start\n    }\n\n\ndef serialize_parser_state(parser_state: ParserState | None) -> Dict[str, Any] | None:\n    \"\"\"\n    Serialize parser state to a dictionary.\n\n    Args:\n        parser_state: The parser state to serialize\n\n    Returns:\n        Dictionary representation of the parser state, or None if state is None\n    \"\"\"\n    if parser_state is None:\n        return None\n\n    result = {\n        \"parsing_continuation\": parser_state.parsing_continuation,\n        \"continuation_state\": parser_state.continuation_state\n    }\n\n    # Add lexer state information if available\n    if hasattr(parser_state, 'lexer_state') and parser_state.lexer_state is not None:\n        lexer_state = parser_state.lexer_state\n        lexer_state_dict = {}\n        \n        # Serialize common lexer state attributes\n        if hasattr(lexer_state, 'in_block_comment'):\n            lexer_state_dict['in_block_comment'] = lexer_state.in_block_comment\n        \n        if lexer_state_dict:\n            result['lexer_state'] = lexer_state_dict\n\n    # Add parser-specific state if available\n    if hasattr(parser_state, 'in_element'):\n        result['in_element'] = parser_state.in_element\n\n    return result\n\n\ndef serialize_tokens_and_state(\n    tokens: List[Token],\n    parser_state: ParserState | None,\n    language: ProgrammingLanguage,\n    source_file: str\n) -> Dict[str, Any]:\n    \"\"\"\n    Serialize tokens and parser state to a dictionary.\n\n    Args:\n        tokens: List of tokens to serialize\n        parser_state: Parser state to serialize\n        language: Programming language used\n        source_file: Source file path\n\n    Returns:\n        Dictionary containing serialized data\n    \"\"\"\n    return {\n        \"source_file\": source_file,\n        \"language\": language.name,\n        \"tokens\": [serialize_token(token) for token in tokens],\n        \"parser_state\": serialize_parser_state(parser_state)\n    }\n\n\ndef save_tokens_to_json(\n    tokens: List[Token],\n    parser_state: ParserState | None,\n    file_path: str,\n    language: ProgrammingLanguage,\n    source_file: str\n) -> None:\n    \"\"\"\n    Save tokens and parser state to a JSON file.\n\n    Args:\n        tokens: List of tokens to save\n        parser_state: Parser state to save\n        file_path: Path to save the JSON file\n        language: Programming language used\n        source_file: Source file path\n    \"\"\"\n    serialized = serialize_tokens_and_state(tokens, parser_state, language, source_file)\n    with open(file_path, 'w', encoding='utf-8') as f:\n        json.dump(serialized, f, indent=2)\n\n\ndef load_tokens_from_json(file_path: str) -> Dict[str, Any]:\n    \"\"\"\n    Load serialized tokens and state from a JSON file.\n\n    Args:\n        file_path: Path to the JSON file\n\n    Returns:\n        Dictionary containing the serialized data\n    \"\"\"\n    with open(file_path, 'r', encoding='utf-8') as f:\n        return json.load(f)\n```\n\n### 3. Create Test Utilities\n\n**File:** `/Users/dave/github/m6r/humbug/tests/syntax/syntax_test_utils.py`\n\n```python\n\"\"\"\nUtility functions for syntax parser tests.\n\"\"\"\nimport os\nimport json\nimport difflib\nfrom pathlib import Path\nfrom typing import Dict, Any, List, Tuple, Optional\n\nfrom humbug.syntax.parser_registry import ParserRegistry\nfrom humbug.syntax.programming_language_utils import ProgrammingLanguageUtils\nfrom syntax_test_serializer import serialize_tokens_and_state, load_tokens_from_json\n\n\ndef get_test_fixtures_dir() -> Path:\n    \"\"\"\n    Get the directory containing test fixtures.\n\n    Returns:\n        Path to the test fixtures directory\n    \"\"\"\n    current_dir = Path(__file__).parent\n    return current_dir / \"fixtures\"\n\n\ndef load_source_file(file_path: str) -> str:\n    \"\"\"\n    Load a source code file.\n\n    Args:\n        file_path: Path to the source file\n\n    Returns:\n        The contents of the source file\n    \"\"\"\n    with open(file_path, 'r', encoding='utf-8') as f:\n        return f.read()\n\n\ndef find_test_files() -> List[Tuple[str, str]]:\n    \"\"\"\n    Find all test files (source files with corresponding JSON files).\n\n    Returns:\n        List of tuples containing (source_path, json_path)\n    \"\"\"\n    fixtures_dir = get_test_fixtures_dir()\n    test_files = []\n\n    # Get all supported extensions\n    supported_extensions = ProgrammingLanguageUtils.get_supported_file_extensions()\n\n    for root, _, files in os.walk(fixtures_dir):\n        for file in files:\n            file_path = os.path.join(root, file)\n            \n            # Check if this file has a supported extension\n            _, ext = os.path.splitext(file)\n            if ext.lower() in supported_extensions:\n                json_path = file_path + '.json'\n                \n                if os.path.exists(json_path):\n                    test_files.append((file_path, json_path))\n\n    return test_files\n\n\ndef compare_token_data(\n    actual_data: Dict[str, Any],\n    expected_data: Dict[str, Any]\n) -> Tuple[bool, Optional[str]]:\n    \"\"\"\n    Compare actual token data with expected token data.\n\n    Args:\n        actual_data: The actual token data dictionary\n        expected_data: The expected token data dictionary\n\n    Returns:\n        Tuple of (is_match, diff_message)\n    \"\"\"\n    # Convert to JSON strings for comparison\n    actual_json = json.dumps(actual_data, indent=2, sort_keys=True)\n    expected_json = json.dumps(expected_data, indent=2, sort_keys=True)\n\n    if actual_json == expected_json:\n        return True, None\n\n    # Generate a diff if they don't match\n    diff = difflib.unified_diff(\n        expected_json.splitlines(keepends=True),\n        actual_json.splitlines(keepends=True),\n        fromfile='expected',\n        tofile='actual'\n    )\n\n    diff_message = ''.join(diff)\n    return False, diff_message\n\n\ndef parse_and_compare(\n    source_path: str,\n    expected_json_path: str\n) -> Tuple[bool, Optional[str]]:\n    \"\"\"\n    Parse a source file and compare the result with an expected JSON file.\n\n    Args:\n        source_path: Path to the source file\n        expected_json_path: Path to the expected JSON file\n\n    Returns:\n        Tuple of (is_match, diff_message)\n    \"\"\"\n    # Determine language from file extension\n    language = ProgrammingLanguageUtils.from_file_extension(source_path)\n    if language.name == 'UNKNOWN':\n        return False, f\"Unknown language for file: {source_path}\"\n\n    # Create parser\n    parser = ParserRegistry.create_parser(language)\n    if parser is None:\n        return False, f\"No parser available for language: {language.name}\"\n\n    # Load and parse the source\n    try:\n        source_text = load_source_file(source_path)\n        parser_state = parser.parse(None, source_text)\n\n        # Extract tokens\n        tokens = []\n        while True:\n            token = parser.get_next_token()\n            if token is None:\n                break\n            tokens.append(token)\n\n        # Serialize the results\n        actual_data = serialize_tokens_and_state(tokens, parser_state, language, source_path)\n\n        # Load expected data\n        expected_data = load_tokens_from_json(expected_json_path)\n\n        # Compare (excluding source_file path which may differ)\n        actual_comparison = {k: v for k, v in actual_data.items() if k != 'source_file'}\n        expected_comparison = {k: v for k, v in expected_data.items() if k != 'source_file'}\n\n        return compare_token_data(actual_comparison, expected_comparison)\n\n    except Exception as e:\n        return False, f\"Error parsing {source_path}: {str(e)}\"\n```\n\n### 4. Create Unit Test File\n\n**File:** `/Users/dave/github/m6r/humbug/tests/syntax/test_syntax_parsers.py`\n\n```python\n\"\"\"\nTests for syntax parsers using the parser registry.\n\"\"\"\nimport os\nimport pytest\nfrom pathlib import Path\n\n# Import all parsers to ensure they are registered\nimport humbug.syntax.parser_imports\n\nfrom humbug.syntax.parser_registry import ParserRegistry\nfrom humbug.syntax.programming_language import ProgrammingLanguage\nfrom humbug.syntax.programming_language_utils import ProgrammingLanguageUtils\n\nfrom syntax_test_utils import (\n    find_test_files,\n    parse_and_compare\n)\n\n\n@pytest.mark.parametrize(\"source_path,expected_json_path\", find_test_files())\ndef test_parse_fixture_files(source_path, expected_json_path):\n    \"\"\"Test parsing source files against expected JSON token outputs.\"\"\"\n    is_match, diff = parse_and_compare(source_path, expected_json_path)\n    assert is_match, f\"Token stream mismatch for {os.path.basename(source_path)}:\\n{diff}\"\n\n\ndef test_parser_registry_has_parsers():\n    \"\"\"Test that the parser registry has parsers for supported languages.\"\"\"\n    supported_languages = ProgrammingLanguageUtils.get_all_programming_languages()\n    \n    # Verify we have at least some parsers registered\n    registered_count = 0\n    for language in supported_languages:\n        parser = ParserRegistry.create_parser(language)\n        if parser is not None:\n            registered_count += 1\n    \n    assert registered_count > 0, \"No parsers are registered in the parser registry\"\n\n\ndef test_parser_registry_c_parser():\n    \"\"\"Test that C parser is available and functional.\"\"\"\n    parser = ParserRegistry.create_parser(ProgrammingLanguage.C)\n    assert parser is not None, \"C parser should be available\"\n    \n    # Test basic parsing\n    source = 'int main() { return 0; }'\n    parser_state = parser.parse(None, source)\n    \n    # Should have some tokens\n    token_count = 0\n    while True:\n        token = parser.get_next_token()\n        if token is None:\n            break\n        token_count += 1\n    \n    assert token_count > 0, \"C parser should produce tokens\"\n    assert parser_state is not None, \"C parser should return parser state\"\n\n\ndef test_language_detection_from_extensions():\n    \"\"\"Test that language detection works for supported file extensions.\"\"\"\n    test_cases = [\n        ('.c', ProgrammingLanguage.C),\n        ('.cpp', ProgrammingLanguage.CPP),\n        ('.py', ProgrammingLanguage.PYTHON),\n        ('.js', ProgrammingLanguage.JAVASCRIPT),\n        ('.java', ProgrammingLanguage.JAVA),\n        ('.rs', ProgrammingLanguage.RUST),\n        ('.go', ProgrammingLanguage.GO),\n    ]\n    \n    for extension, expected_language in test_cases:\n        detected = ProgrammingLanguageUtils.from_file_extension(f\"test{extension}\")\n        assert detected == expected_language, f\"Expected {expected_language.name} for {extension}\"\n\n\ndef test_parser_creation_for_detected_languages():\n    \"\"\"Test that parsers can be created for languages detected from file extensions.\"\"\"\n    extensions_to_test = ['.c', '.cpp', '.py', '.js']  # Test a subset\n    \n    for extension in extensions_to_test:\n        language = ProgrammingLanguageUtils.from_file_extension(f\"test{extension}\")\n        parser = ParserRegistry.create_parser(language)\n        \n        # Not all languages may have parsers, but the registry should handle gracefully\n        if parser is not None:\n            # If parser exists, it should be functional\n            assert hasattr(parser, 'parse'), f\"Parser for {language.name} should have parse method\"\n            assert hasattr(parser, 'get_next_token'), f\"Parser for {language.name} should have get_next_token method\"\n\n\ndef test_unknown_language_handling():\n    \"\"\"Test handling of unknown languages.\"\"\"\n    # Unknown language should return None parser\n    parser = ParserRegistry.create_parser(ProgrammingLanguage.UNKNOWN)\n    assert parser is None, \"Unknown language should return None parser\"\n    \n    # Unknown file extension should return TEXT language\n    language = ProgrammingLanguageUtils.from_file_extension(\"test.unknown\")\n    assert language == ProgrammingLanguage.TEXT, \"Unknown extension should return TEXT language\"\n```\n\n### 5. Create conftest.py for Syntax Tests\n\n**File:** `/Users/dave/github/m6r/humbug/tests/syntax/conftest.py`\n\n```python\nimport os\nimport sys\nfrom pathlib import Path\n\n# Add the src directory to Python path\nproject_root = Path(__file__).parent.parent.parent\nsys.path.insert(0, str(project_root / \"src\"))\n```\n\n### 6. Create Test Fixtures Directory Structure\n\nYou'll need to create:\n```\n/Users/dave/github/m6r/humbug/tests/syntax/fixtures/\n```\n\nAnd populate it with test files like:\n- `simple.c` + `simple.c.json`\n- `hello.py` + `hello.py.json`\n- etc.\n\n## Usage Workflow\n\n1. **Create test fixtures:**\n   ```bash\n   cd tests/syntax\n   python syntax_test_gen.py fixtures/simple.c\n   ```\n\n2. **Run tests:**\n   ```bash\n   pytest test_syntax_parsers.py\n   ```\n\n## Key Design Benefits\n\n1. **Consistency:** Mirrors your existing markdown test approach\n2. **Extensibility:** Automatically picks up new parsers registered in the registry\n3. **Language-agnostic:** Works with any programming language that has a parser\n4. **Comprehensive:** Tests both token generation and parser state\n5. **Maintainable:** Clear separation of concerns with dedicated utility modules\n\nThis design reuses your proven testing patterns while extending them to cover the broader syntax parsing functionality. The parametrized tests will automatically discover and test all source files with corresponding JSON references, just like your markdown tests.",
      "completed": true,
      "usage": {
        "prompt_tokens": 52679,
        "completion_tokens": 4792,
        "total_tokens": 57471
      },
      "error": null,
      "model": "claude-4-sonnet-20250514",
      "temperature": 0.7
    }
  ]
}