{
  "metadata": {
    "version": "0.1"
  },
  "conversation": [
    {
      "id": "eb754487-fbbb-4afd-ae42-8d0aae523904",
      "timestamp": "2025-06-04T09:31:08.491261",
      "type": "user_message",
      "content": "The following preamble describes some elements of a language called Metaphor.  Please pay\nextremely close attention to the details as they will affect the way you interpret\neverything that follows after \"BEGIN DESCRIPTION IN METAPHOR:\"\n\nMetaphor is a structured natural language prompt creation language.  It is designed to\nlet a user convey their requirements to a large language model AI.\n\nMetaphor has the structure of a document tree with branches and leaves being prefixed\nby new sections containing the keywords \"Role:\", \"Context:\" or \"Action:\".  Each of\nthese indicates the start of a new block of information.  Blocks are introduced using\nMarkdown-style headings (using hash symbols).  The number of hashes gives an indication\nof the nesting depth and the parent/child relationship.\n\nBlock keywords have an optional name that will immediately follow them on the same line.\nIf this is missing then the block name is not defined.\n\nAfter a block heading there may be one or more lines of text that will describe the purpose\nof that block.  A block may also include one or more optional child blocks inside them and\nthat further clarify their parent block.\n\nWithin the text of a block, you may be presented with code or document fragments inside a\nblock delimited by 3 backticks.  Please pay close attention to the indentation level of the\nopening 3 backticks.  The identation of such code or document fragments is relative to this,\nnot relative to the block in which the code or document fragment occurs.\n\nIf \"Role:\" block exists then this contains details about the role you should fulfil.  This\nmay also describe specific skills you have, knowledge you should apply, and the\napproach you take to apply these.\n\n\"Context:\" blocks provide context necessary to understand what you will be asked to do.\n\n\"Action:\" blocks describes the task, or tasks, you should do.\n\nIf you are asked to offer any opinions on the Metaphor prompt then always provide the full\nset of parent headings leading up to any block you want to talk about.  This will allow\nthe user to understand which part of the Metaphor prompt is being discussed.\n\nWhen you process the actions please carefully ensure you do all of them accurately and\ncomplete all the elements requested.  Unless otherwise instructed, do not include any\nplaceholders in your responses.\n\nBEGIN DESCRIPTION IN METAPHOR:\n\n# Role:\n\nYou are a world class python programmer, highly skilled in accurate and performant software development.  You\nare going to assist me in making modifications to my application.\n\n# Context:\n\n## Context: Python implementation rules\n\nAs an engineer working with the application, I want the application to be easy to use and understand,\nso I can maintain and enhance it over time.\n\n### Context: Implement in Python 3\n\nThe application will be written in the latest version of Python 3.  Assume a baseline of Python 3.10.\n\n### Context: Indentation of code\n\nCode must be indented by 4 spaces.\n\n### Context: Use docstrings\n\nDocstrings must be used to describe all modules, classes, and functions.  This should follow PEP 257 guidelines.\n\n### Context: Use type hints\n\nType hints must be used for function arguments and return values.\n\nAs we're using Python 3.10 as a minimum, use union types.  E.g. use `T | None` instead of `Optional[T]`.\n\n`self` parameters do not need to have type hints.\n\n### Context: Use comments\n\nComments must be used to describe any complex logic, or rationale that would not be obvious from\nsimply reading the code.  This ensures that anyone reading the code for the first time will be able\nto understand why the code is the way it is.\n\n### Context: PEP 8 imports\n\nThe import list in any module should follow PEP 8 guidelines, including the ordering of imports.\n\n### Context: Avoid unnecessary `elif` and `else` statements\n\nTo improve readability, do not use `elif` or `else` statements if the preceding `if` branch ends with\na `return`, `continue`, or `break`.\n\nFor example, do this:\n\n```python\nif condition:\n    return\n\nnext_statement()\n```\n\ninstead of this:\n\n```python\nif condition:\n    return\nelse:\n    next_statement()\n```\n\n### Context: Handle error and exception paths early\n\nIf it is possible to detect errors and exceptions early then do so.  Always prefer to do this as early\nas possible within the code so we have the fewest possible conditional checks by the time we reach the\nmain purpose of any function or method.\n\nThis is sometimes known as \"flattening the code to the left\" as there is generally less indentation required\nwhen we do this.  This makes the code easier to read.\n\n### Context: Exception handling philosophy\n\n#### Context: Exception documentation\n\nDocument what exceptions each function may raise in its docstring.\n\n#### Context: Handling exceptions\n\nAttempt to handle and mitigate exceptions at the level closest to which they are first\ndetected.  If we cannot handle or mitigate the exception then it should be wrapped in a domain-appropriate\nexception class and this re-raised to the next level up the call stack.\n\nInclude contextual information when wrapping exceptions.\n\nPreserve the exception chain using `raise ... from e` syntax.\n\n#### Context: Avoid bare `except:` or `except Exception:` clauses.\n\nAvoid the use of bare `except:` or `except Exception:` clauses unless a function we are calling\ncan only have exceptions handled this way.\n\nWe should always catch specific exception types that could occur from an operation.\n\n#### Context: Exception logging\n\nAll exceptions should be logged when they occur, before re-raising or wrapping them.\n\nUse appropriate log levels:\n- ERROR for exceptions that indicate failure.\n- WARNING for exceptions that can be handled/recovered from.\n- DEBUG for detailed exception information during development.\n\nWe must include sufficient context in log messages to aid debugging.\n\nLogging must use lazy evaluation of any arguments rather.\n\n#### Context: Exception wrapping example\n\nDo this:\n\n```python\ntry:\n    await self.api_client.fetch_data()\n\nexcept ConnectionError as e:\n    logger.error(\"Failed to retrieve data from API endpoint\", exc_info=True)\n    raise DataFetchError(f\"Failed to retrieve data from API endpoint: {e}\") from e\n\nexcept TimeoutError as e:\n    logger.warning(\"API request timed out, will retry\", exc_info=True)\n```\n\nNot this:\n\n```python\ntry:\n    await self.api_client.fetch_data()\nexcept Exception as e:\n    logger.error(f\"Error: {e}\")  # Insufficient context, no stack trace\n    raise  # No wrapping or additional context\n```\n\n## Context: Dependencies\n\nLeverage standard library tools before custom solutions, unless specifically instructed, or\nunless a depdency is already in use.\n\n## Context: Existing code\n\nThe following files are used in my application:\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/ast/ast.py\n\n```python\n\"\"\"\nBase classes for Abstract Syntax Trees (AST).\n\nThis module provides shared infrastructure for different AST implementations,\nallowing for code reuse while maintaining separation between languages.\n\"\"\"\n\nfrom typing import List, Any\n\nclass ASTNode:\n    \"\"\"\n    Base class for all AST nodes in any language.\n\n    This class provides common tree operations like adding/removing children\n    and navigating between siblings, which are useful across different\n    language implementations.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize a base AST node with empty children list and no parent.\"\"\"\n        self.parent: ASTNode | None = None\n        self.children: List[ASTNode] = []\n\n    def add_child(self, child: 'ASTNode') -> 'ASTNode':\n        \"\"\"\n        Add a child node to this node.\n\n        Args:\n            child: The child node to add\n\n        Returns:\n            The added child node for method chaining\n        \"\"\"\n        child.parent = self  # type: ignore\n        self.children.append(child)\n        return child\n\n    def remove_child(self, child: 'ASTNode') -> None:\n        \"\"\"\n        Remove a child node from this node.\n\n        Args:\n            child: The child node to remove\n            \n        Raises:\n            ValueError: If the child is not a child of this node\n        \"\"\"\n        if not child in self.children:\n            raise ValueError(\"Node is not a child of this node\")\n\n        self.children.remove(child)\n        child.parent = None\n\n    def remove_children(self) -> None:\n        \"\"\"Remove all children from this node.\"\"\"\n        for child in self.children:\n            child.parent = None\n\n        self.children = []\n\n    def previous_sibling(self) -> 'ASTNode | None':\n        \"\"\"\n        Get the previous sibling of this node, if any.\n\n        Returns:\n            The previous sibling node, or None if this is the first child or has no parent\n        \"\"\"\n        if self.parent is None:\n            return None\n\n        index = self.parent.children.index(self)  # type: ignore\n        if index > 0:\n            return self.parent.children[index - 1]  # type: ignore\n\n        return None\n\n    def next_sibling(self) -> 'ASTNode | None':\n        \"\"\"\n        Get the next sibling of this node, if any.\n\n        Returns:\n            The next sibling node, or None if this is the last child or has no parent\n        \"\"\"\n        if self.parent is None:\n            return None\n\n        index = self.parent.children.index(self)  # type: ignore\n        if index < len(self.parent.children) - 1:  # type: ignore\n            return self.parent.children[index + 1]  # type: ignore\n\n        return None\n\n\nclass ASTVisitor:\n    \"\"\"\n    Base visitor class for AST traversal.\n\n    This implements the visitor pattern for tree traversal, allowing\n    specialized processing of different node types.\n    \"\"\"\n\n    def visit(self, node: ASTNode) -> Any:\n        \"\"\"\n        Visit a node and dispatch to the appropriate visit method.\n\n        Args:\n            node: The node to visit\n\n        Returns:\n            The result of visiting the node\n        \"\"\"\n        method_name = f'visit_{node.__class__.__name__}'\n        visitor = getattr(self, method_name, self.generic_visit)\n        return visitor(node)\n\n    def generic_visit(self, node: ASTNode) -> List[Any]:\n        \"\"\"\n        Default visit method for nodes without specific handlers.\n\n        Args:\n            node: The node to visit\n\n        Returns:\n            A list of results from visiting each child\n        \"\"\"\n        results = []\n        for child in node.children:\n            results.append(self.visit(child))\n\n        return results\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/metaphor/metaphor_embed_lexer.py\n\n```python\nfrom typing import Dict, List\n\nfrom humbug.metaphor.metaphor_token import MetaphorToken, MetaphorTokenType\n\nclass MetaphorEmbedLexer:\n    \"\"\"\n    Lexer for handling embedded content like code blocks.\n    \"\"\"\n\n    file_exts: Dict[str, str] = {\n        \"bash\": \"bash\",\n        \"c\": \"c\",\n        \"clj\": \"clojure\",\n        \"cpp\": \"cpp\",\n        \"cs\": \"csharp\",\n        \"css\": \"css\",\n        \"dart\": \"dart\",\n        \"ebnf\": \"ebnf\",\n        \"erl\": \"erlang\",\n        \"ex\": \"elixir\",\n        \"hpp\": \"cpp\",\n        \"go\": \"go\",\n        \"groovy\": \"groovy\",\n        \"h\": \"c\",\n        \"hs\": \"haskell\",\n        \"html\": \"html\",\n        \"java\": \"java\",\n        \"js\": \"javascript\",\n        \"json\": \"json\",\n        \"kt\": \"kotlin\",\n        \"lua\": \"lua\",\n        \"m6r\": \"metaphor\",\n        \"m\": \"objectivec\",\n        \"md\": \"markdown\",\n        \"mm\": \"objectivec\",\n        \"php\": \"php\",\n        \"pl\": \"perl\",\n        \"py\": \"python\",\n        \"r\": \"r\",\n        \"rkt\": \"racket\",\n        \"rb\": \"ruby\",\n        \"rs\": \"rust\",\n        \"scala\": \"scala\",\n        \"sh\": \"bash\",\n        \"sql\": \"sql\",\n        \"swift\": \"swift\",\n        \"ts\": \"typescript\",\n        \"vb\": \"vbnet\",\n        \"vbs\": \"vbscript\",\n        \"xml\": \"xml\",\n        \"yaml\": \"yaml\",\n        \"yml\": \"yaml\"\n    }\n\n    def __init__(self, input_text: str, filename: str) -> None:\n        \"\"\"\n        Initialize the MetaphorEmbedLexer for handling embedded content.\n\n        Args:\n            input_text (str): The text content to be lexically analyzed\n            filename (str): Name of the file being processed\n        \"\"\"\n        self.filename: str = filename\n        self.tokens: List[MetaphorToken] = []\n        self.current_line: int = 1\n        self.input: str = input_text\n        self._tokenize()\n\n    def get_next_token(self) -> MetaphorToken:\n        \"\"\"Return the next token from the token list.\"\"\"\n        if self.tokens:\n            return self.tokens.pop(0)\n\n        return MetaphorToken(MetaphorTokenType.END_OF_FILE, \"\", \"\", self.filename, self.current_line, 1)\n\n    def _get_language_from_file_extension(self, filename: str) -> str:\n        \"\"\"Get a language name from a filename extension.\"\"\"\n        extension: str = \"\"\n        if '.' in filename:\n            extension = (filename.rsplit('.', 1)[-1]).lower()\n\n        return self.file_exts.get(extension, \"plaintext\")\n\n    def _tokenize(self) -> None:\n        \"\"\"MetaphorTokenizes the input file and handles embedded content.\"\"\"\n        self.tokens.append(MetaphorToken(MetaphorTokenType.TEXT, f\"File: {self.filename}\", \"\", self.filename, 0, 1))\n        self.tokens.append(MetaphorToken(MetaphorTokenType.TEXT, \"\", \"\", self.filename, 0, 1))\n        self.tokens.append(\n            MetaphorToken(\n                MetaphorTokenType.CODE,\n                \"```\" + self._get_language_from_file_extension(self.filename),\n                \"\",\n                self.filename,\n                0,\n                1\n            )\n        )\n\n        lines = self.input.splitlines()\n        for line in lines:\n            token = MetaphorToken(MetaphorTokenType.CODE, line, line, self.filename, self.current_line, 1)\n            self.tokens.append(token)\n            self.current_line += 1\n\n        self.tokens.append(MetaphorToken(MetaphorTokenType.CODE, \"```\", \"\", self.filename, self.current_line, 1))\n        self.tokens.append(MetaphorToken(MetaphorTokenType.TEXT, \"\", \"\", self.filename, self.current_line, 1))\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/metaphor/metaphor_ast_builder.py\n\n```python\nimport glob\nimport os\nfrom pathlib import Path\nfrom typing import List, Set, cast\n\nfrom humbug.metaphor.metaphor_token import MetaphorToken, MetaphorTokenType\nfrom humbug.metaphor.metaphor_embed_lexer import MetaphorEmbedLexer\nfrom humbug.metaphor.metaphor_lexer import MetaphorLexer\nfrom humbug.metaphor.metaphor_ast_node import (\n    MetaphorASTNode, MetaphorTextNode, MetaphorCodeNode,\n    MetaphorRoleNode, MetaphorContextNode, MetaphorActionNode\n)\n\n\nclass MetaphorASTBuilderFileAlreadyUsedError(Exception):\n    \"\"\"Exception raised when a file is used more than once.\"\"\"\n    def __init__(self, filename: str, token: MetaphorToken) -> None:\n        super().__init__(f\"The file '{filename}' has already been used.\")\n        self.filename: str = filename\n        self.token: MetaphorToken = token\n\n\nclass MetaphorASTBuilderSyntaxError(Exception):\n    \"\"\"Exception generated when there is a syntax error.\"\"\"\n    def __init__(self, message: str, filename: str, line: int, column: int, input_text: str) -> None:\n        super().__init__(f\"{message}: file: {filename}, line {line}, column {column}, \")\n        self.message: str = message\n        self.filename: str = filename\n        self.line: int = line\n        self.column: int = column\n        self.input_text: str = input_text\n\n\nclass MetaphorASTBuilderError(Exception):\n    \"\"\"Exception wrapper generated when there is a syntax error.\"\"\"\n    def __init__(self, message: str, errors: List[MetaphorASTBuilderSyntaxError]) -> None:\n        super().__init__(message)\n        self.errors: List[MetaphorASTBuilderSyntaxError] = errors\n\n\nclass MetaphorASTBuilder:\n    \"\"\"\n    Parser class to process tokens and build an Abstract Syntax Tree (AST).\n\n    Attributes:\n        _parse_errors (List[MetaphorASTBuilderSyntaxError]): List of syntax errors encountered during parsing.\n        _lexers (List[MetaphorLexer | MetaphorEmbedLexer]): Stack of lexers used for parsing multiple files.\n        _previously_seen_files (Set[str]): Set of canonical filenames already processed.\n        _search_paths (List[str]): List of paths to search for included files.\n        embed_path (str): Path used to search for embedded files.\n        current_token (MetaphorToken | None): The current token being processed.\n    \"\"\"\n    def __init__(self) -> None:\n        self._parse_errors: List[MetaphorASTBuilderSyntaxError] = []\n        self._lexers: List[MetaphorLexer | MetaphorEmbedLexer] = []\n        self._previously_seen_files: Set[str] = set()\n        self._search_paths: List[str] = []\n        self._embed_path: str = \"\"\n        self._current_token: MetaphorToken | None = None\n        self._arguments: List[str] = []\n\n    def _has_role_node(self, node: MetaphorASTNode) -> bool:\n        \"\"\"\n        Check if the node tree contains any Role nodes.\n\n        Args:\n            node: The node to check\n\n        Returns:\n            True if the node or any of its descendants is a Role node\n        \"\"\"\n        if isinstance(node, MetaphorRoleNode):\n            return True\n\n        return any(self._has_role_node(cast(MetaphorASTNode, child)) for child in node.children)\n\n    def _has_context_node(self, node: MetaphorASTNode) -> bool:\n        \"\"\"\n        Check if the node tree contains any Context nodes.\n\n        Args:\n            node: The node to check\n\n        Returns:\n            True if the node or any of its descendants is a Context node\n        \"\"\"\n        if isinstance(node, MetaphorContextNode):\n            return True\n\n        return any(self._has_context_node(cast(MetaphorASTNode, child)) for child in node.children)\n\n    def _has_action_node(self, node: MetaphorASTNode) -> bool:\n        \"\"\"\n        Check if the node tree contains any Action nodes.\n\n        Args:\n            node: The node to check\n\n        Returns:\n            True if the node or any of its descendants is an Action node\n        \"\"\"\n        if isinstance(node, MetaphorActionNode):\n            return True\n\n        return any(self._has_action_node(cast(MetaphorASTNode, child)) for child in node.children)\n\n    def build_ast(\n        self,\n        parent_node: MetaphorASTNode,\n        input_text: str,\n        filename: str,\n        search_paths: List[str],\n        embed_path: str = \"\",\n        arguments: List[str] | None = None\n    ) -> None:\n        \"\"\"\n        Parse an input string and add the resulting nodes to the provided parent node.\n\n        Args:\n            parent_node (MetaphorASTNode): The node to which parsed content will be added.\n            input_text (str): The text to be parsed.\n            filename (str): The name of the file being parsed.\n            search_paths (List[str]): List of paths to search for included files.\n            embed_path: Path used to search for embedded files (uses CWD if None).\n            arguments (List[str] | None): List of command line arguments.\n\n        Raises:\n            MetaphorASTBuilderError: If there are syntax errors during parsing.\n        \"\"\"\n        self._search_paths = search_paths\n        self._embed_path = embed_path if embed_path else os.getcwd()\n        self._arguments = arguments if arguments else []\n\n        try:\n            self._lexers.append(MetaphorLexer(input_text, filename))\n\n            seen_action_tree: bool = self._has_action_node(parent_node)\n            seen_context_tree: bool = self._has_context_node(parent_node)\n            seen_role_tree: bool = self._has_role_node(parent_node)\n\n            while True:\n                token = self.get_next_non_blank_token()\n                if token.type == MetaphorTokenType.ACTION:\n                    if seen_action_tree and not isinstance(parent_node, MetaphorActionNode):\n                        self._record_syntax_error(token, \"'Action' already defined\")\n\n                    parent_node.add_child(self._parse_action(token))\n                    seen_action_tree = True\n                    continue\n\n                if token.type == MetaphorTokenType.CONTEXT:\n                    if seen_context_tree and not isinstance(parent_node, MetaphorContextNode):\n                        self._record_syntax_error(token, \"'Context' already defined\")\n\n                    parent_node.add_child(self._parse_context(token))\n                    seen_context_tree = True\n                    continue\n\n                if token.type == MetaphorTokenType.ROLE:\n                    if seen_role_tree and not isinstance(parent_node, MetaphorRoleNode):\n                        self._record_syntax_error(token, \"'Role' already defined\")\n\n                    parent_node.add_child(self._parse_role(token))\n                    seen_role_tree = True\n                    continue\n\n                if token.type == MetaphorTokenType.END_OF_FILE:\n                    if self._parse_errors:\n                        raise MetaphorASTBuilderError(\"parser error\", self._parse_errors)\n\n                    return  # No return value needed\n\n                if token.type in (MetaphorTokenType.TEXT, MetaphorTokenType.CODE):\n                    if parent_node.children:\n                        # If our parent is processing text or code then we can add more text or code\n                        if isinstance(parent_node.children[-1], MetaphorTextNode | MetaphorCodeNode):\n                            parent_node.add_child(self._parse_text(token))\n                            continue\n\n                        self._record_syntax_error(token, \"Text or code must come first in parent's block\")\n                        continue\n\n                    # If our parent is an action, context or role node and has no children\n                    # then we can add text or code to it.\n                    if isinstance(parent_node, MetaphorActionNode | MetaphorContextNode | MetaphorRoleNode):\n                        parent_node.add_child(self._parse_text(token))\n                        continue\n\n                self._record_syntax_error(token, f\"Unexpected token: {token.value} at top level\")\n\n        except FileNotFoundError as e:\n            err_token = cast(MetaphorToken, self._current_token)\n            self._parse_errors.append(MetaphorASTBuilderSyntaxError(\n                f\"{e}\", err_token.filename, err_token.line, err_token.column, err_token.input\n            ))\n            raise(MetaphorASTBuilderError(\"parser error\", self._parse_errors)) from e\n\n        except MetaphorASTBuilderFileAlreadyUsedError as e:\n            self._parse_errors.append(MetaphorASTBuilderSyntaxError(\n                f\"The file '{e.filename}' has already been used\",\n                e.token.filename,\n                e.token.line,\n                e.token.column,\n                e.token.input\n            ))\n            raise(MetaphorASTBuilderError(\"parser error\", self._parse_errors)) from e\n\n    def build_ast_from_file(\n        self,\n        parent_node: MetaphorASTNode,\n        filename: str,\n        search_paths: List[str],\n        embed_path: str = \"\",\n        arguments: List[str] | None = None\n    ) -> None:\n        \"\"\"\n        Parse a file and add the resulting nodes to the provided parent node.\n\n        Args:\n            parent_node (MetaphorASTNode): The node to which parsed content will be added.\n            filename (str): The path to the file to be parsed.\n            search_paths (List[str]): List of paths to search for included files.\n            embed_path: Path used to search for embedded files (uses CWD if None).\n            arguments (List[str] | None): List of command line arguments.\n\n        Raises:\n            MetaphorASTBuilderError: If there are syntax errors during parsing.\n        \"\"\"\n        try:\n            self._check_file_not_loaded(filename)\n            input_text = self._read_file(filename)\n            self.build_ast(parent_node, input_text, filename, search_paths, embed_path, arguments)\n\n        except FileNotFoundError as e:\n            self._parse_errors.append(MetaphorASTBuilderSyntaxError(\n                f\"{e}\", \"\", 0, 0, \"\"\n            ))\n            raise(MetaphorASTBuilderError(\"parser error\", self._parse_errors)) from e\n\n        except MetaphorASTBuilderError as e:\n            raise(MetaphorASTBuilderError(\"parser error\", self._parse_errors)) from e\n\n    def get_next_token(self) -> MetaphorToken:\n        \"\"\"Get the next token from the active lexer.\"\"\"\n        while self._lexers:\n            lexer = self._lexers[-1]\n            token = lexer.get_next_token()\n            self._current_token = token\n\n            if token.type == MetaphorTokenType.INCLUDE:\n                self._parse_include(token)\n\n            elif token.type == MetaphorTokenType.EMBED:\n                self._parse_embed(token)\n\n            elif token.type == MetaphorTokenType.END_OF_FILE:\n                self._lexers.pop()\n\n            else:\n                return token\n\n        return MetaphorToken(MetaphorTokenType.END_OF_FILE, \"\", \"\", \"\", 0, 0)\n\n    def get_next_non_blank_token(self) -> MetaphorToken:\n        \"\"\"Get the next token that is not a blank line.\"\"\"\n        token = None\n\n        while True:\n            token = self.get_next_token()\n            if not token or token.type != MetaphorTokenType.TEXT or token.value != \"\":\n                return token\n\n    def _record_syntax_error(self, token: MetaphorToken, message: str) -> None:\n        \"\"\"Raise a syntax error and add it to the error list.\"\"\"\n        error = MetaphorASTBuilderSyntaxError(\n            message, token.filename, token.line, token.column, token.input\n        )\n        self._parse_errors.append(error)\n\n    def _find_file_path(self, filename: str) -> str:\n        \"\"\"Try to find a valid path for a file, given all the search path options\"\"\"\n        if Path(filename).exists():\n            return filename\n\n        # If we don't have an absolute path then we can try search paths.\n        if not os.path.isabs(filename):\n            for path in self._search_paths:\n                try_name = os.path.join(path, filename)\n                if Path(try_name).exists():\n                    return try_name\n\n        raise FileNotFoundError(f\"File not found: {filename}\")\n\n    def _read_file(self, filename: str) -> str:\n        \"\"\"Read file content into memory.\"\"\"\n        try:\n            with open(filename, 'r', encoding='utf-8') as file:\n                return file.read()\n\n        except FileNotFoundError as e:\n            raise FileNotFoundError(f\"File not found: {filename}\") from e\n\n        except PermissionError as e:\n            raise FileNotFoundError(f\"You do not have permission to access: {filename}\") from e\n\n        except IsADirectoryError as e:\n            raise FileNotFoundError(f\"Is a directory: {filename}\") from e\n\n        except OSError as e:\n            raise FileNotFoundError(f\"OS error: {e}\") from e\n\n    def _check_file_not_loaded(self, filename: str) -> None:\n        \"\"\"Check we have not already loaded a file.\"\"\"\n        canonical_filename = os.path.realpath(filename)\n        if canonical_filename in self._previously_seen_files:\n            raise MetaphorASTBuilderFileAlreadyUsedError(filename, cast(MetaphorToken, self._current_token))\n\n        self._previously_seen_files.add(canonical_filename)\n\n    def _parse_text(self, token: MetaphorToken) -> MetaphorTextNode:\n        \"\"\"Parse a text block.\"\"\"\n        return MetaphorTextNode(token.value)\n\n    def _parse_code(self, token: MetaphorToken) -> MetaphorCodeNode:\n        \"\"\"Parse a code block.\"\"\"\n        return MetaphorCodeNode(token.value)\n\n    def _parse_action(self, token: MetaphorToken) -> MetaphorActionNode:\n        \"\"\"Parse an action block and construct its AST node.\"\"\"\n        label_name = \"\"\n\n        seen_token_type = MetaphorTokenType.NONE\n\n        init_token = self.get_next_token()\n        if init_token.type == MetaphorTokenType.KEYWORD_TEXT:\n            label_name = init_token.value\n            indent_token = self.get_next_non_blank_token()\n            if indent_token.type != MetaphorTokenType.INDENT:\n                self._record_syntax_error(\n                    token,\n                    \"Expected indent after keyword description for 'Action' block\"\n                )\n\n        elif init_token.type != MetaphorTokenType.INDENT:\n            self._record_syntax_error(token, \"Expected description or indent after 'Action' keyword\")\n\n        action_node = MetaphorActionNode(label_name)\n\n        while True:\n            token = self.get_next_token()\n            if token.type == MetaphorTokenType.TEXT:\n                if token.value != \"\" and seen_token_type != MetaphorTokenType.NONE:\n                    self._record_syntax_error(token, \"Text must come first in an 'Action' block\")\n\n                action_node.add_child(self._parse_text(token))\n                continue\n\n            if token.type == MetaphorTokenType.CODE:\n                if seen_token_type != MetaphorTokenType.NONE:\n                    self._record_syntax_error(token, \"Code must come first in an 'Action' block\")\n\n                action_node.add_child(self._parse_code(token))\n                continue\n\n            if token.type == MetaphorTokenType.ACTION:\n                action_node.add_child(self._parse_action(token))\n                seen_token_type = MetaphorTokenType.ACTION\n                continue\n\n            if token.type in (MetaphorTokenType.OUTDENT, MetaphorTokenType.END_OF_FILE):\n                return action_node\n\n            self._record_syntax_error(token, f\"Unexpected token: {token.value} in 'Action' block\")\n\n    def _parse_context(self, token: MetaphorToken) -> MetaphorContextNode:\n        \"\"\"Parse a Context block.\"\"\"\n        label_name = \"\"\n\n        seen_token_type = MetaphorTokenType.NONE\n\n        init_token = self.get_next_token()\n        if init_token.type == MetaphorTokenType.KEYWORD_TEXT:\n            label_name = init_token.value\n            indent_token = self.get_next_non_blank_token()\n            if indent_token.type != MetaphorTokenType.INDENT:\n                self._record_syntax_error(\n                    token,\n                    \"Expected indent after keyword description for 'Context' block\"\n                )\n\n        elif init_token.type != MetaphorTokenType.INDENT:\n            self._record_syntax_error(token, \"Expected description or indent after 'Context' keyword\")\n\n        context_node = MetaphorContextNode(label_name)\n\n        while True:\n            token = self.get_next_token()\n            if token.type == MetaphorTokenType.TEXT:\n                if token.value != \"\" and seen_token_type != MetaphorTokenType.NONE:\n                    self._record_syntax_error(token, \"Text must come first in a 'Context' block\")\n\n                context_node.add_child(self._parse_text(token))\n                continue\n\n            if token.type == MetaphorTokenType.CODE:\n                if seen_token_type != MetaphorTokenType.NONE:\n                    self._record_syntax_error(token, \"Code must come first in a 'Context' block\")\n\n                context_node.add_child(self._parse_code(token))\n                continue\n\n            if token.type == MetaphorTokenType.CONTEXT:\n                context_node.add_child(self._parse_context(token))\n                seen_token_type = MetaphorTokenType.CONTEXT\n                continue\n\n            if token.type in (MetaphorTokenType.OUTDENT, MetaphorTokenType.END_OF_FILE):\n                return context_node\n\n            self._record_syntax_error(token, f\"Unexpected token: {token.value} in 'Context' block\")\n\n    def _parse_role(self, token: MetaphorToken) -> MetaphorRoleNode:\n        \"\"\"Parse a Role block.\"\"\"\n        label_name = \"\"\n\n        seen_token_type = MetaphorTokenType.NONE\n\n        init_token = self.get_next_token()\n        if init_token.type == MetaphorTokenType.KEYWORD_TEXT:\n            label_name = init_token.value\n            indent_token = self.get_next_non_blank_token()\n            if indent_token.type != MetaphorTokenType.INDENT:\n                self._record_syntax_error(\n                    token,\n                    \"Expected indent after keyword description for 'Role' block\"\n                )\n\n        elif init_token.type != MetaphorTokenType.INDENT:\n            self._record_syntax_error(token, \"Expected description or indent after 'Role' keyword\")\n\n        role_node = MetaphorRoleNode(label_name)\n\n        while True:\n            token = self.get_next_token()\n            if token.type == MetaphorTokenType.TEXT:\n                if token.value != \"\" and seen_token_type != MetaphorTokenType.NONE:\n                    self._record_syntax_error(token, \"Text must come first in a 'Role' block\")\n\n                role_node.add_child(self._parse_text(token))\n                continue\n\n            if token.type == MetaphorTokenType.CODE:\n                if seen_token_type != MetaphorTokenType.NONE:\n                    self._record_syntax_error(token, \"Code must come first in a 'Role' block\")\n\n                role_node.add_child(self._parse_code(token))\n                continue\n\n            if token.type == MetaphorTokenType.ROLE:\n                role_node.add_child(self._parse_role(token))\n                seen_token_type = MetaphorTokenType.ROLE\n                continue\n\n            if token.type in (MetaphorTokenType.OUTDENT, MetaphorTokenType.END_OF_FILE):\n                return role_node\n\n            self._record_syntax_error(token, f\"Unexpected token: {token.value} in 'Role' block\")\n\n    def _parse_argument(self, token: MetaphorToken) -> str | None:\n        \"\"\"\n        Parse a $ argument token.\n\n        Args:\n            token: The token to parse.\n\n        Returns:\n            The parsed argument as a string or None if we could not determine the string.\n        \"\"\"\n        numeric_part = token.value[1:]\n        if not numeric_part.isdigit():\n            self._record_syntax_error(token, \"After '$', the string must contain only digits\")\n\n        arg_index = int(numeric_part)\n        if arg_index < 0 or arg_index >= len(self._arguments):\n            self._record_syntax_error(token, f\"Argument index {arg_index} is out of range\")\n            return None\n\n        return self._arguments[arg_index]\n\n    def _parse_include(self, token: MetaphorToken) -> None:\n        \"\"\"Parse an Include block and load the included file.\"\"\"\n        token_next = self.get_next_token()\n        if token_next.type != MetaphorTokenType.KEYWORD_TEXT:\n            self._record_syntax_error(token, \"Expected file name after 'Include' keyword\")\n            return\n\n        if token_next.value[0] == \"$\":\n            filename = self._parse_argument(token_next)\n            if filename is None:\n                return\n\n        else:\n            filename = token_next.value\n\n        self._check_file_not_loaded(filename)\n        try_file = self._find_file_path(filename)\n        input_text = self._read_file(try_file)\n        self._lexers.append(MetaphorLexer(input_text, try_file))\n\n    def _parse_embed(self, token: MetaphorToken) -> None:\n        \"\"\"Parse an Embed block and load the embedded file.\"\"\"\n        token_next = self.get_next_token()\n        if token_next.type != MetaphorTokenType.KEYWORD_TEXT:\n            self._record_syntax_error(token, \"Expected file name or wildcard match after 'Embed' keyword\")\n            return\n\n        if token_next.value[0] == \"$\":\n            match = self._parse_argument(token_next)\n            if match is None:\n                return\n\n        else:\n            match = token_next.value\n\n        path = os.path.join(self._embed_path, match)\n        recurse = \"**/\" in match\n        files = glob.glob(path, recursive=recurse)\n        if not files:\n            self._record_syntax_error(token_next, f\"{match} does not match any files for 'Embed' in {self._embed_path}\")\n            return\n\n        for file in files:\n            input_text = self._read_file(file)\n            self._lexers.append(MetaphorEmbedLexer(input_text, file))\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/metaphor/metaphor_token.py\n\n```python\nfrom dataclasses import dataclass\nfrom enum import IntEnum, auto\n\n\nclass MetaphorTokenType(IntEnum):\n    \"\"\"\n    Enum-like class representing different types of tokens in the source file.\n    \"\"\"\n    NONE = auto()\n    INDENT = auto()\n    OUTDENT = auto()\n    INCLUDE = auto()\n    EMBED = auto()\n    KEYWORD_TEXT = auto()\n    TEXT = auto()\n    ACTION = auto()\n    CONTEXT = auto()\n    ROLE = auto()\n    BAD_INDENT = auto()\n    BAD_OUTDENT = auto()\n    TAB = auto()\n    END_OF_FILE = auto()\n    CODE = auto()\n\n\n@dataclass(frozen=True)\nclass MetaphorToken:\n    \"\"\"\n    Represents a token in the input stream.\n\n    Attributes:\n        type (TokenType): The type of the token (e.g., TEXT, ACTION).\n        value (str): The actual string value of the token.\n        input (str): The entire line of input where the token appears.\n        filename (str): The file where the token was read from.\n        line (int): The line number in the file where the token is located.\n        column (int): The column number where the token starts.\n    \"\"\"\n    type: MetaphorTokenType\n    value: str\n    input: str\n    filename: str\n    line: int\n    column: int\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/metaphor/metaphor_format_visitor.py\n\n```python\n\"\"\"\nFormat visitor implementation for Metaphor AST.\n\"\"\"\n\nimport io\nfrom typing import Any, Dict, Final, TextIO, Type, cast\n\nfrom humbug.ast.ast import ASTNode\nfrom humbug.metaphor.metaphor_ast_node import (\n    MetaphorASTNode, MetaphorASTVisitor, MetaphorActionNode, MetaphorCodeNode,\n    MetaphorContextNode, MetaphorRoleNode, MetaphorRootNode, MetaphorTextNode\n)\n\n\nclass MetaphorFormatVisitor(MetaphorASTVisitor):\n    \"\"\"\n    Visitor that formats a Metaphor AST structure into a string representation.\n\n    This visitor implements the visitor pattern to traverse the AST and\n    generate formatted output according to the Metaphor language syntax.\n    \"\"\"\n\n    # Map node types to their keyword representations\n    NODE_CLASS_MAP: Final[Dict[Type[MetaphorASTNode], str]] = {\n        MetaphorActionNode: \"Action:\",\n        MetaphorContextNode: \"Context:\",\n        MetaphorRoleNode: \"Role:\"\n    }\n\n    def __init__(self) -> None:\n        \"\"\"Initialize the format visitor with an output buffer.\"\"\"\n        super().__init__()\n        self.output: TextIO = io.StringIO()\n        self.depth: int = 0\n\n    def format(self, node: MetaphorASTNode) -> str:\n        \"\"\"\n        Format an AST node and its children as a string.\n\n        Args:\n            node: The root node to format\n\n        Returns:\n            Formatted string representation of the AST\n        \"\"\"\n        self.depth = 0\n        self.output = io.StringIO()\n        self.visit(node)\n        return self.output.getvalue()\n\n    def generic_visit(self, node: ASTNode) -> Any:\n        \"\"\"\n        Default visit method for node types without specific handlers.\n\n        Args:\n            node: The node to visit\n\n        Returns:\n            Implementation-specific results from visiting the node\n        \"\"\"\n        results = []\n        for child in node.children:\n            results.append(self.visit(cast(MetaphorASTNode, child)))\n\n        return results\n\n    def visit_MetaphorRootNode(self, node: MetaphorRootNode) -> Any:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit the root node of the AST.\n\n        Args:\n            node: The root node to visit\n\n        Returns:\n            Implementation-specific results from visiting children\n        \"\"\"\n        self.depth = 1\n        return self.generic_visit(node)\n\n    def visit_MetaphorTextNode(self, node: MetaphorTextNode) -> Any:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a text node and format its content.\n\n        Args:\n            node: The text node to visit\n\n        Returns:\n            The text content\n        \"\"\"\n        value = node.value()\n        if value == \"\":\n            current_pos = self.output.tell()\n            if current_pos <= 1:\n                return value\n\n            self.output.seek(current_pos - 2)\n            prev_char = self.output.read(2)\n            self.output.seek(current_pos)\n            if prev_char == '\\n\\n':\n                return value\n\n        self.output.write(f\"{value}\\n\")\n        return value\n\n    def visit_MetaphorCodeNode(self, node: MetaphorCodeNode) -> Any:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a code node and format its content.\n\n        Args:\n            node: The code node to visit\n\n        Returns:\n            The code content\n        \"\"\"\n        value = node.value()\n        self.output.write(f\"{value}\\n\")\n        return value\n\n    def _format_block_node(self, node: MetaphorASTNode) -> Any:\n        \"\"\"\n        Format a block node (Role, Context, or Action).\n\n        Args:\n            node: The block node to format\n\n        Returns:\n            Implementation-specific results from visiting the node\n        \"\"\"\n        # If we don't have a blank line before this block heading then add one\n        current_pos = self.output.tell()\n        if current_pos > 1:\n            self.output.seek(current_pos - 2)\n            prev_char = self.output.read(2)\n            self.output.seek(current_pos)\n            if prev_char != '\\n\\n':\n                self.output.write(\"\\n\")\n\n        # Write the heading with the appropriate number of hash symbols\n        indent = \"#\" * self.depth\n        keyword = self.NODE_CLASS_MAP.get(node.__class__, \"\")\n        self.output.write(f\"{indent} {keyword}\")\n\n        # Add the optional label if present\n        value = node.value()\n        if value:\n            self.output.write(f\" {value}\")\n\n        self.output.write(\"\\n\\n\")\n\n        # Process children with increased depth\n        self.depth += 1\n        results = self.generic_visit(node)\n        self.depth -= 1\n\n        return results\n\n    def visit_MetaphorRoleNode(self, node: MetaphorRoleNode) -> Any:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a role node and format its content.\n\n        Args:\n            node: The role node to visit\n\n        Returns:\n            Implementation-specific results from visiting the node\n        \"\"\"\n        return self._format_block_node(node)\n\n    def visit_MetaphorContextNode(self, node: MetaphorContextNode) -> Any:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a context node and format its content.\n\n        Args:\n            node: The context node to visit\n\n        Returns:\n            Implementation-specific results from visiting the node\n        \"\"\"\n        return self._format_block_node(node)\n\n    def visit_MetaphorActionNode(self, node: MetaphorActionNode) -> Any:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit an action node and format its content.\n\n        Args:\n            node: The action node to visit\n\n        Returns:\n            Implementation-specific results from visiting the node\n        \"\"\"\n        return self._format_block_node(node)\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/metaphor/metaphor_ast_printer.py\n\n```python\n\"\"\"\nVisitor class to print Metaphor AST structures for debugging\n\"\"\"\n\nfrom typing import List, Any, Type, cast\n\nfrom humbug.ast.ast import ASTNode\nfrom humbug.metaphor.metaphor_ast_node import (\n    MetaphorASTVisitor, MetaphorASTNode, MetaphorTextNode, MetaphorCodeNode\n)\n\n\nclass MetaphorASTPrinter(MetaphorASTVisitor):\n    \"\"\"Visitor that prints the Metaphor AST structure for debugging.\"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize the AST printer with zero indentation.\"\"\"\n        super().__init__()\n        self.indent_level = 0\n\n    def _indent(self) -> str:\n        \"\"\"\n        Get the current indentation string.\n\n        Returns:\n            A string of spaces for the current indentation level\n        \"\"\"\n        return \"  \" * self.indent_level\n\n    def generic_visit(self, node: ASTNode) -> List[Any]:\n        \"\"\"\n        Default visit method that prints the node type.\n\n        Args:\n            node: The node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        # Print node information\n        node_class = node.__class__.__name__\n        ast_node = cast(MetaphorASTNode, node)\n        print(f\"{self._indent()}{node_class}: {ast_node.value()}\")\n\n        # Visit children with increased indentation\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n\n        return results\n\n    def visit_MetaphorTextNode(self, node: MetaphorTextNode) -> str:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a text node and print its content.\n\n        Args:\n            node: The text node to visit\n\n        Returns:\n            The text content\n        \"\"\"\n        value = node.value()\n        print(f\"{self._indent()}Text: '{value}'\")\n        return value\n\n    def visit_MetaphorCodeNode(self, node: MetaphorCodeNode) -> str:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a code node and print a preview of its content.\n\n        Args:\n            node: The code node to visit\n\n        Returns:\n            The code content\n        \"\"\"\n        value = node.value()\n        content_preview = value[:30] + \"...\" if len(value) > 30 else value\n        print(f\"{self._indent()}Code: '{content_preview}' ({len(value)} chars)\")\n        return value\n\n    def visit_with_specific_types(\n        self,\n        node: MetaphorASTNode,\n        types_to_show: List[Type[MetaphorASTNode]] | None = None\n    ) -> List[Any]:\n        \"\"\"\n        Visit a node and only print details for specific node classes.\n\n        Args:\n            node: The node to visit\n            types_to_show: List of node classes to display, or None for all\n\n        Returns:\n            The results of visiting the node\n        \"\"\"\n        # Check if we should display this node\n        if types_to_show is None or any(isinstance(node, t) for t in types_to_show):\n            node_class = node.__class__.__name__\n            print(f\"{self._indent()}{node_class}: {node.value()}\")\n\n        # Visit children with increased indentation\n        self.indent_level += 1\n        results = []\n        for child in node.children:\n            results.append(self.visit_with_specific_types(cast(MetaphorASTNode, child), types_to_show))\n\n        self.indent_level -= 1\n\n        return results\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/metaphor/metaphor_ast_node.py\n\n```python\n\"\"\"\nTypes and classes for representing the AST (Abstract Syntax Tree)\nof a Metaphor document.\n\"\"\"\n\nfrom typing import List, Any, cast\n\nfrom humbug.ast.ast import ASTNode, ASTVisitor\n\n\nclass MetaphorASTNode(ASTNode):\n    \"\"\"\n    Base class for all Metaphor AST nodes.\n\n    This class provides common functionality for all Metaphor nodes\n    regardless of their specific type.\n    \"\"\"\n\n    def __init__(self, value: str = \"\") -> None:\n        \"\"\"\n        Initialize a base Metaphor AST node.\n\n        Args:\n            value: The value associated with the node\n        \"\"\"\n        super().__init__()\n        self._value: str = value\n\n    def __str__(self, indent: int = 0) -> str:\n        \"\"\"\n        Returns a string representation of the node and its children in a tree format.\n\n        Args:\n            indent: The current indentation level (used recursively)\n\n        Returns:\n            A formatted string showing the node's type, value, and children\n        \"\"\"\n        # Create the indentation string\n        indent_str = \"    \" * indent\n\n        # Start with this node's information\n        node_type_name = self.__class__.__name__\n        result = f\"{indent_str}{node_type_name}: {self._value}\"\n\n        # Add all children with increased indentation\n        for child in self.children:\n            result += \"\\n\" + cast(MetaphorASTNode, child).__str__(indent + 1)\n\n        return result\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Returns a concise representation of the node for debugging.\n\n        Returns:\n            A string in format 'NodeType(value)[num_children]'\n        \"\"\"\n        node_type_name = self.__class__.__name__\n        return f\"{node_type_name}({self._value})[{len(self.children)}]\"\n\n    def value(self) -> str:\n        \"\"\"The raw text value of this node.\"\"\"\n        return self._value\n\n    def get_children_of_type(self, node_class: type) -> List['MetaphorASTNode']:\n        \"\"\"\n        Returns a list of all immediate children that are instances of the specified class.\n\n        Args:\n            node_class: The class to filter for\n\n        Returns:\n            List of child nodes matching the specified class\n        \"\"\"\n        return [cast(MetaphorASTNode, child) for child in self.children if isinstance(child, node_class)]\n\n\nclass MetaphorRootNode(MetaphorASTNode):\n    \"\"\"Root node of a Metaphor AST representing an entire document.\"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize a root node.\"\"\"\n        super().__init__(\"\")\n\n\nclass MetaphorTextNode(MetaphorASTNode):\n    \"\"\"Node representing text content in a Metaphor document.\"\"\"\n\n    def __init__(self, content: str) -> None:\n        \"\"\"\n        Initialize a text node.\n\n        Args:\n            content: The text content\n        \"\"\"\n        super().__init__(content)\n\n\nclass MetaphorCodeNode(MetaphorASTNode):\n    \"\"\"Node representing a code block in a Metaphor document.\"\"\"\n\n    def __init__(self, content: str) -> None:\n        \"\"\"\n        Initialize a code block node.\n\n        Args:\n            content: The code content\n        \"\"\"\n        super().__init__(content)\n\n\nclass MetaphorRoleNode(MetaphorASTNode):\n    \"\"\"Node representing a Role block in a Metaphor document.\"\"\"\n\n    def __init__(self, label: str = \"\") -> None:\n        \"\"\"\n        Initialize a role node.\n\n        Args:\n            label: Optional label for the role\n        \"\"\"\n        super().__init__(label)\n\n\nclass MetaphorContextNode(MetaphorASTNode):\n    \"\"\"Node representing a Context block in a Metaphor document.\"\"\"\n\n    def __init__(self, label: str = \"\") -> None:\n        \"\"\"\n        Initialize a context node.\n\n        Args:\n            label: Optional label for the context\n        \"\"\"\n        super().__init__(label)\n\n\nclass MetaphorActionNode(MetaphorASTNode):\n    \"\"\"Node representing an Action block in a Metaphor document.\"\"\"\n\n    def __init__(self, label: str = \"\") -> None:\n        \"\"\"\n        Initialize an action node.\n\n        Args:\n            label: Optional label for the action\n        \"\"\"\n        super().__init__(label)\n\n\nclass MetaphorASTVisitor(ASTVisitor):\n    \"\"\"Base visitor class for Metaphor AST traversal.\"\"\"\n\n    def visit(self, node: ASTNode) -> Any:\n        \"\"\"\n        Visit a node and dispatch to the appropriate visit method.\n\n        Args:\n            node: The node to visit\n\n        Returns:\n            The result of visiting the node\n        \"\"\"\n        method_name = f'visit_{node.__class__.__name__}'\n        visitor = getattr(self, method_name, self.generic_visit)\n        return visitor(node)\n\n    def generic_visit(self, node: ASTNode) -> List[Any]:\n        \"\"\"\n        Default visit method for nodes without specific handlers.\n\n        Args:\n            node: The node to visit\n\n        Returns:\n            A list of results from visiting each child\n        \"\"\"\n        results = []\n        for child in node.children:\n            results.append(self.visit(cast(MetaphorASTNode, child)))\n\n        return results\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/metaphor/metaphor_formatters.py\n\n```python\n\"\"\"Functions for formatting Metaphor AST nodes and error messages.\"\"\"\n\nimport io\nfrom typing import List\n\nfrom humbug.metaphor.metaphor_ast_builder import MetaphorASTBuilderSyntaxError\n\n\ndef format_preamble() -> str:\n    \"\"\"\n    Format the preamble for the Metaphor language.\n\n    Returns:\n        Formatted preamble string\n    \"\"\"\n    preamble: str = (\n        \"The following preamble describes some elements of a language called Metaphor.  Please pay\\n\" +\n        \"extremely close attention to the details as they will affect the way you interpret\\n\" +\n        \"everything that follows after \\\"BEGIN DESCRIPTION IN METAPHOR:\\\"\\n\" +\n        \"\\n\" +\n        \"Metaphor is a structured natural language prompt creation language.  It is designed to\\n\" +\n        \"let a user convey their requirements to a large language model AI.\\n\" +\n        \"\\n\" +\n        \"Metaphor has the structure of a document tree with branches and leaves being prefixed\\n\" +\n        \"by new sections containing the keywords \\\"Role:\\\", \\\"Context:\\\" or \\\"Action:\\\".  Each of\\n\" +\n        \"these indicates the start of a new block of information.  Blocks are introduced using\\n\" +\n        \"Markdown-style headings (using hash symbols).  The number of hashes gives an indication\\n\" +\n        \"of the nesting depth and the parent/child relationship.\\n\" +\n        \"\\n\" +\n        \"Block keywords have an optional name that will immediately follow them on the same line.\\n\" +\n        \"If this is missing then the block name is not defined.\\n\" +\n        \"\\n\" +\n        \"After a block heading there may be one or more lines of text that will describe the purpose\\n\" +\n        \"of that block.  A block may also include one or more optional child blocks inside them and\\n\" +\n        \"that further clarify their parent block.\\n\" +\n        \"\\n\" +\n        \"Within the text of a block, you may be presented with code or document fragments inside a\\n\" +\n        \"block delimited by 3 backticks.  Please pay close attention to the indentation level of the\\n\" +\n        \"opening 3 backticks.  The identation of such code or document fragments is relative to this,\\n\" +\n        \"not relative to the block in which the code or document fragment occurs.\\n\" +\n        \"\\n\" +\n        \"If \\\"Role:\\\" block exists then this contains details about the role you should fulfil.  This\\n\" +\n        \"may also describe specific skills you have, knowledge you should apply, and the\\n\" +\n        \"approach you take to apply these.\\n\" +\n        \"\\n\" +\n        \"\\\"Context:\\\" blocks provide context necessary to understand what you will be asked to do.\\n\" +\n        \"\\n\" +\n        \"\\\"Action:\\\" blocks describes the task, or tasks, you should do.\\n\" +\n        \"\\n\" +\n        \"If you are asked to offer any opinions on the Metaphor prompt then always provide the full\\n\" +\n        \"set of parent headings leading up to any block you want to talk about.  This will allow\\n\" +\n        \"the user to understand which part of the Metaphor prompt is being discussed.\\n\" +\n        \"\\n\" +\n        \"When you process the actions please carefully ensure you do all of them accurately and\\n\" +\n        \"complete all the elements requested.  Unless otherwise instructed, do not include any\\n\" +\n        \"placeholders in your responses.\\n\" +\n        \"\\n\" +\n        \"BEGIN DESCRIPTION IN METAPHOR:\\n\" +\n        \"\\n\"\n    )\n\n    return preamble\n\n\ndef format_errors(errors: List[MetaphorASTBuilderSyntaxError]) -> str:\n    \"\"\"Format a list of syntax errors as a string.\n\n    Args:\n        errors: List of syntax errors to format\n\n    Returns:\n        Formatted error string with each error on separate lines\n    \"\"\"\n    output = io.StringIO()\n\n    for error in errors:\n        caret = \" \" * (error.column - 1)\n        error_message = (\n            f\"{error.message}: line {error.line}, column {error.column}, \"\n            f\"file {error.filename}\\n{caret}|\\n{caret}v\\n{error.input_text}\"\n        )\n        output.write(f\"----------------\\n{error_message}\\n\")\n\n    output.write(\"----------------\\n\")\n    return output.getvalue()\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/metaphor/metaphor_lexer.py\n\n```python\nfrom typing import Dict, List, Final\n\nfrom humbug.metaphor.metaphor_token import MetaphorToken, MetaphorTokenType\n\n\nclass MetaphorLexer:\n    \"\"\"\n    Lexer for handling the Metaphor language with its specific syntax.\n\n    The Metaphor language consists of:\n    - Keywords (Action:, Context:, Role:, etc)\n    - Indented blocks\n    - Text content\n    - Include/Embed directives\n\n    This lexer handles proper indentation, text block detection, and keyword parsing.\n    \"\"\"\n\n    # Constants for language elements\n    INDENT_SPACES = 4\n\n    # Mapping of keywords to their token types\n    KEYWORDS: Final[Dict[str, MetaphorTokenType]] = {\n        \"Action:\": MetaphorTokenType.ACTION,\n        \"Context:\": MetaphorTokenType.CONTEXT,\n        \"Embed:\": MetaphorTokenType.EMBED,\n        \"Include:\": MetaphorTokenType.INCLUDE,\n        \"Role:\": MetaphorTokenType.ROLE\n    }\n\n    def __init__(self, input_text: str, filename: str) -> None:\n        \"\"\"\n        Initialize the MetaphorLexer.\n\n        Args:\n            input_text (str): The text content to be lexically analyzed\n            filename (str): Name of the file being processed\n        \"\"\"\n        self.in_text_block: bool = False\n        self.in_fenced_code: bool = False\n        self.indent_column: int = 1\n        self.filename: str = filename\n        self.tokens: List[MetaphorToken] = []\n        self.current_line: int = 1\n        self.input: str = input_text\n        self._tokenize()\n\n    def get_next_token(self) -> MetaphorToken:\n        \"\"\"Return the next token from the token list.\"\"\"\n        if self.tokens:\n            return self.tokens.pop(0)\n\n        return MetaphorToken(MetaphorTokenType.END_OF_FILE, \"\", \"\", self.filename, self.current_line, 1)\n\n    def _tokenize(self) -> None:\n        \"\"\"\n        Tokenize the input file into appropriate tokens.\n        Processes each line for indentation, keywords, and text content.\n        \"\"\"\n        if not self.input:\n            return\n\n        lines: List[str] = self.input.splitlines()\n        for line in lines:\n            self._process_line(line)\n            self.current_line += 1\n\n        # Handle remaining outdents at end of file\n        self._handle_final_outdents()\n\n    def _handle_final_outdents(self) -> None:\n        \"\"\"Handle any remaining outdents needed at the end of file.\"\"\"\n        while self.indent_column > 1:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.OUTDENT,\n                    value=\"[Outdent]\",\n                    input=\"\",\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=self.indent_column\n                )\n            )\n            self.indent_column -= self.INDENT_SPACES\n\n    def _process_line(self, line: str) -> None:\n        \"\"\"\n        Process a single line of input.\n\n        Args:\n            line: The line to process\n        \"\"\"\n        stripped_line = line.lstrip(' ')\n        start_column = len(line) - len(stripped_line) + 1\n\n        if not stripped_line:\n            self._handle_blank_line(start_column)\n            return\n\n        # Is this line a comment?\n        if stripped_line.startswith('#'):\n            return\n\n        # Does this line start with a tab character?\n        if stripped_line.startswith('\\t'):\n            self._handle_tab_character(stripped_line, start_column)\n            stripped_line = stripped_line[1:]\n            if not stripped_line:\n                return\n\n        # Does this line start with a code fence?\n        in_fenced_code = self.in_fenced_code\n        if stripped_line.startswith('```'):\n            self.in_fenced_code = True\n            in_fenced_code = not in_fenced_code\n\n        # If we're not in a fenced code block then look for keywords.\n        if not self.in_fenced_code:\n            words = stripped_line.split(maxsplit=1)\n            first_word = words[0].capitalize()\n\n            if first_word in self.KEYWORDS:\n                self._handle_keyword_line(line, words, first_word, start_column)\n                self.in_fenced_code = in_fenced_code\n                return\n\n        # Treat this as a text block.\n        self._handle_text_line(line, start_column)\n        self.in_fenced_code = in_fenced_code\n\n    def _handle_tab_character(self, line: str, column: int) -> None:\n        \"\"\"\n        Handle tab characters in the input.\n\n        Args:\n            line: The line to check\n            column: The current column number\n        \"\"\"\n        self.tokens.append(\n            MetaphorToken(\n                type=MetaphorTokenType.TAB,\n                value=\"[Tab]\",\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=column\n            )\n        )\n\n    def _handle_keyword_line(self, line: str, words: List[str], keyword: str, start_column: int) -> None:\n        \"\"\"\n        Handle a line that starts with a keyword.\n\n        Args:\n            line: The complete line\n            words: The line split into words\n            keyword: The keyword found\n            start_column: The starting column of the content\n        \"\"\"\n        self._process_indentation(line, start_column)\n\n        # Create keyword token\n        self.tokens.append(\n            MetaphorToken(\n                type=self.KEYWORDS[keyword],\n                value=keyword,\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n\n        # Handle any text after the keyword\n        if len(words) > 1:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.KEYWORD_TEXT,\n                    value=words[1],\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column + len(keyword) + 1\n                )\n            )\n\n        self.in_text_block = False\n\n    def _handle_text_line(self, line: str, start_column: int) -> None:\n        \"\"\"\n        Handle a line that contains text content.\n\n        Args:\n            line: The line to process\n            start_column: The starting column of the content\n        \"\"\"\n        # Adjust indentation for continued text blocks\n        if self.in_text_block:\n            if start_column > self.indent_column:\n                start_column = self.indent_column\n\n            elif start_column < self.indent_column:\n                self._process_indentation(line, start_column)\n\n        else:\n            self._process_indentation(line, start_column)\n\n        text_content = line[start_column - 1:]\n        token_type = MetaphorTokenType.CODE if self.in_fenced_code else MetaphorTokenType.TEXT\n        self.tokens.append(\n            MetaphorToken(\n                type=token_type,\n                value=text_content,\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n        self.in_text_block = True\n\n    def _handle_blank_line(self, start_column: int) -> None:\n        token_type = MetaphorTokenType.CODE if self.in_fenced_code else MetaphorTokenType.TEXT\n        self.tokens.append(\n            MetaphorToken(\n                type=token_type,\n                value=\"\",\n                input=\"\",\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n\n    def _process_indentation(self, line: str, start_column: int) -> None:\n        \"\"\"\n        Process the indentation of the current line.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n        \"\"\"\n        indent_offset = start_column - self.indent_column\n\n        if indent_offset > 0:\n            self._handle_indent(line, start_column, indent_offset)\n\n        elif indent_offset < 0:\n            self._handle_outdent(line, start_column, indent_offset)\n\n    def _handle_indent(self, line: str, start_column: int, indent_offset: int) -> None:\n        \"\"\"\n        Handle an increase in indentation.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n            indent_offset: The change in indentation\n        \"\"\"\n        if indent_offset % self.INDENT_SPACES != 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.BAD_INDENT,\n                    value=\"[Bad Indent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            return\n\n        while indent_offset > 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.INDENT,\n                    value=\"[Indent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            indent_offset -= self.INDENT_SPACES\n\n        self.indent_column = start_column\n\n    def _handle_outdent(self, line: str, start_column: int, indent_offset: int) -> None:\n        \"\"\"\n        Handle a decrease in indentation.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n            indent_offset: The change in indentation\n        \"\"\"\n        if abs(indent_offset) % self.INDENT_SPACES != 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.BAD_OUTDENT,\n                    value=\"[Bad Outdent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            return\n\n        while indent_offset < 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.OUTDENT,\n                    value=\"[Outdent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            indent_offset += self.INDENT_SPACES\n\n        self.indent_column = start_column\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/metaphor/__init__.py\n\n```python\n\"\"\"An embedded compiler for the Metaphor language.\"\"\"\n\n# Export main classes so users can import directly from metaphor\nfrom .metaphor_ast_node import (\n    MetaphorASTNode, MetaphorRootNode, MetaphorTextNode,\n    MetaphorCodeNode, MetaphorRoleNode, MetaphorContextNode, MetaphorActionNode,\n    MetaphorASTVisitor\n)\nfrom .metaphor_ast_builder import MetaphorASTBuilder, MetaphorASTBuilderError, MetaphorASTBuilderSyntaxError\nfrom .metaphor_format_visitor import MetaphorFormatVisitor\nfrom .metaphor_formatters import format_errors, format_preamble\n\n\n__all__ = [\n    \"MetaphorASTNode\",\n    \"MetaphorRootNode\",\n    \"MetaphorTextNode\",\n    \"MetaphorCodeNode\",\n    \"MetaphorRoleNode\",\n    \"MetaphorContextNode\",\n    \"MetaphorActionNode\",\n    \"MetaphorASTVisitor\",\n    \"MetaphorFormatVisitor\",\n    \"MetaphorASTBuilder\",\n    \"MetaphorASTBuilderError\",\n    \"MetaphorASTBuilderSyntaxError\",\n    \"format_errors\",\n    \"format_preamble\"\n]\n```\n\nI also have a markdown AST builder:\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/markdown/markdown_converter.py\n\n```python\n\"\"\"\nUtility for converting simplified markdown text to HTML.\n\nThis module provides functionality to incrementally convert simplified markdown\nto HTML while preserving code blocks and handling streaming text updates.\n\"\"\"\n\nimport logging\nfrom typing import List, Tuple, cast\n\nfrom humbug.markdown.markdown_ast_builder import MarkdownASTBuilder\nfrom humbug.markdown.markdown_ast_node import MarkdownCodeBlockNode, MarkdownASTNode, MarkdownDocumentNode\nfrom humbug.syntax.programming_language import ProgrammingLanguage\nfrom humbug.syntax.programming_language_utils import ProgrammingLanguageUtils\n\n\nclass MarkdownConverter:\n    \"\"\"\n    Converts simplified markdown to HTML using an AST-based approach.\n\n    This class handles the incremental parsing of simplified markdown into an\n    Abstract Syntax Tree (AST) representation and extraction of content sections for rendering.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initialize the markdown converter with an AST builder and HTML renderer.\n\n        Args:\n            source_path: Optional path to the source markdown file\n        \"\"\"\n        self.ast_builder = MarkdownASTBuilder(True)\n\n        self._logger = logging.getLogger(\"ConversationMarkdownConverter\")\n\n        # Keep track of the current text for incremental updates\n        self.current_text = \"\"\n\n        # Store builder state for preservation during reset\n        self.builder_state = None\n\n        self._source_path: str | None = None\n\n    def extract_sections(self, text: str, path: str | None) -> List[Tuple[MarkdownASTNode, ProgrammingLanguage | None]]:\n        \"\"\"\n        Process markdown text and extract content sections from it.\n\n        Args:\n            text: The markdown text to process\n            path: Optional path to the source markdown file\n\n        Returns:\n            List of (node, language) tuples where language is None for markdown content\n            and a ProgrammingLanguage enum for code blocks\n\n        Raises:\n            None\n        \"\"\"\n        self._source_path = path\n\n        # Update the AST based on the changes\n        self.ast_builder.update_ast(text, self.current_text, path)\n        self.current_text = text\n\n        # Extract content sections from the AST document\n        return self._extract_sections_from_ast(self.ast_builder.document())\n\n    def _extract_sections_from_ast(self, document: MarkdownASTNode) -> List[Tuple[MarkdownASTNode, ProgrammingLanguage | None]]:\n        \"\"\"\n        Extract content sections from the AST document.\n\n        Args:\n            document: The AST document node\n\n        Returns:\n            List of (node, language) tuples where language is None for markdown content\n            and a ProgrammingLanguage enum for code blocks\n        \"\"\"\n        sections: List[tuple[MarkdownASTNode, ProgrammingLanguage | None]] = []\n        current_markdown_nodes: List[MarkdownASTNode] = []\n\n        # Helper function to add accumulated markdown content as a section\n        def add_markdown_section() -> None:\n            if current_markdown_nodes:\n                # Create a container node for these markdown nodes\n                container = MarkdownDocumentNode(self._source_path)\n                for node in current_markdown_nodes:\n                    container.add_child(node)\n\n                # Add as a markdown section\n                sections.append((container, None))\n                current_markdown_nodes.clear()\n\n        # Process all nodes in the document\n        for node in document.children:\n            if isinstance(node, MarkdownCodeBlockNode):\n                # Add any accumulated markdown before this code block\n                add_markdown_section()\n\n                # Process the code block\n                language = ProgrammingLanguageUtils.from_name(node.language) if node.language else ProgrammingLanguage.TEXT\n\n                # Add the code block node as a section with its language\n                sections.append((node, language))\n\n            else:\n                # Add to current markdown content\n                current_markdown_nodes.append(cast(MarkdownASTNode, node))\n\n        # Add any remaining markdown content\n        add_markdown_section()\n\n        return sections\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/markdown/markdown_ast_node.py\n\n```python\n\"\"\"\nUtility for converting simplified markdown text to HTML.\n\nThis module provides functionality to incrementally convert simplified markdown\nto HTML while preserving code blocks and handling streaming text updates.\n\"\"\"\n\nfrom humbug.ast.ast import ASTNode, ASTVisitor\n\n\nclass MarkdownASTNode(ASTNode):\n    \"\"\"Base class for all Markdown AST nodes.\"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize an AST node with common markdown properties.\"\"\"\n        super().__init__()\n\n        # Source range information to support incremental updating\n        self.line_start: int | None = None\n        self.line_end: int | None = None\n\n\nclass MarkdownASTVisitor(ASTVisitor):\n    \"\"\"Base visitor class for Markdown AST traversal.\"\"\"\n\n\nclass MarkdownDocumentNode(MarkdownASTNode):\n    \"\"\"Root node representing an entire HTML document.\"\"\"\n\n    def __init__(self, source_path: str | None = None) -> None:\n        \"\"\"\n        Initialize a document node.\n\n        Args:\n            source_path: Optional path to the source file for resolving relative references\n        \"\"\"\n        super().__init__()\n        self.source_path = source_path\n\n\nclass MarkdownParagraphNode(MarkdownASTNode):\n    \"\"\"Node representing an HTML paragraph (<p>).\"\"\"\n\n\nclass MarkdownHeadingNode(MarkdownASTNode):\n    \"\"\"Node representing an HTML heading (<h1> through <h6>).\"\"\"\n    def __init__(self, level: int, anchor_id: str) -> None:\n        \"\"\"\n        Initialize a heading node.\n\n        Args:\n            level: The heading level (1-6)\n        \"\"\"\n        super().__init__()\n\n        # Level should be 1-6\n        self.level = max(1, min(6, level))\n        self.anchor_id = anchor_id\n\n\nclass MarkdownOrderedListNode(MarkdownASTNode):\n    \"\"\"Node representing an HTML ordered list (<ol>).\"\"\"\n    def __init__(self, indent: int = 0, start: int = 1) -> None:\n        \"\"\"\n        Initialize an ordered list node.\n\n        Args:\n            indent: The indentation level of this list\n        \"\"\"\n        super().__init__()\n        self.indent = indent\n        self.start = start\n\n        # Content indent is typically indent + marker (e.g., \"1.\") + space\n        # For ordered lists, we use a default of 3 characters for the marker (\"1. \")\n        self.content_indent = indent + 3\n\n        # Track whether this list should render tightly (without extra spacing)\n        self.tight = True\n\n\nclass MarkdownUnorderedListNode(MarkdownASTNode):\n    \"\"\"Node representing an HTML unordered list (<ul>).\"\"\"\n    def __init__(self, indent: int = 0) -> None:\n        \"\"\"\n        Initialize an unordered list node.\n\n        Args:\n            indent: The indentation level of this list\n        \"\"\"\n        super().__init__()\n        self.indent = indent\n\n        # Content indent is typically indent + marker (e.g., \"-\") + space\n        # For unordered lists, we use 2 characters for the marker (\"- \")\n        self.content_indent = indent + 2\n\n        # Track whether this list should render tightly (without extra spacing)\n        self.tight = True\n\n\nclass MarkdownListItemNode(MarkdownASTNode):\n    \"\"\"Node representing an HTML list item (<li>).\"\"\"\n\n\nclass MarkdownTextNode(MarkdownASTNode):\n    \"\"\"Node representing plain text content.\"\"\"\n    def __init__(self, content: str) -> None:\n        \"\"\"\n        Initialize a text node.\n\n        Args:\n            content: The text content\n        \"\"\"\n        super().__init__()\n        self.content = content\n\n\nclass MarkdownBoldNode(MarkdownASTNode):\n    \"\"\"Node representing bold text (<b> or <strong>).\"\"\"\n\n\nclass MarkdownEmphasisNode(MarkdownASTNode):\n    \"\"\"Node representing emphasized text (<em> or <i>).\"\"\"\n\n\nclass MarkdownInlineCodeNode(MarkdownASTNode):\n    \"\"\"Node representing inline code (<code>).\"\"\"\n    def __init__(self, content: str = \"\") -> None:\n        \"\"\"\n        Initialize an inline code node.\n\n        Args:\n            content: The code content\n        \"\"\"\n        super().__init__()\n        self.content = content\n\n\nclass MarkdownLinkNode(MarkdownASTNode):\n    \"\"\"Node representing a link (<a>).\"\"\"\n    def __init__(self, url: str = \"\", title: str | None = None) -> None:\n        \"\"\"\n        Initialize a link node.\n\n        Args:\n            url: The link URL\n            title: Optional title attribute\n        \"\"\"\n        super().__init__()\n        self.url = url\n        self.title = title\n\n\nclass MarkdownImageNode(MarkdownASTNode):\n    \"\"\"Node representing an image (<img>).\"\"\"\n    def __init__(self, url: str = \"\", alt_text: str = \"\", title: str | None = None) -> None:\n        \"\"\"\n        Initialize an image node.\n\n        Args:\n            url: The image URL\n            alt_text: Alternative text for the image\n            title: Optional title attribute\n        \"\"\"\n        super().__init__()\n        self.url = url\n        self.alt_text = alt_text\n        self.title = title\n\n\nclass MarkdownCodeBlockNode(MarkdownASTNode):\n    \"\"\"Node representing a code block (<pre><code>).\"\"\"\n    def __init__(self, language: str = \"\", content: str = \"\") -> None:\n        \"\"\"\n        Initialize a code block node.\n\n        Args:\n            language: Optional language identifier for syntax highlighting\n            content: The code content\n        \"\"\"\n        super().__init__()\n        self.language = language\n        self.content = content\n\n\nclass MarkdownLineBreakNode(MarkdownASTNode):\n    \"\"\"Node representing a line break.\"\"\"\n\n\nclass MarkdownTableNode(MarkdownASTNode):\n    \"\"\"Node representing an HTML table (<table>).\"\"\"\n\n\nclass MarkdownTableHeaderNode(MarkdownASTNode):\n    \"\"\"Node representing the header row section of a table (<thead>).\"\"\"\n\n\nclass MarkdownTableBodyNode(MarkdownASTNode):\n    \"\"\"Node representing the body section of a table (<tbody>).\"\"\"\n\n\nclass MarkdownTableRowNode(MarkdownASTNode):\n    \"\"\"Node representing a table row (<tr>).\"\"\"\n\n\nclass MarkdownTableCellNode(MarkdownASTNode):\n    \"\"\"Node representing a table cell (<td> or <th>).\"\"\"\n    def __init__(self, is_header: bool = False, alignment: str = \"left\") -> None:\n        \"\"\"\n        Initialize a table cell node.\n\n        Args:\n            is_header: Whether this is a header cell (<th>) or a data cell (<td>)\n            alignment: Cell alignment ('left', 'center', 'right')\n        \"\"\"\n        super().__init__()\n        self.is_header = is_header\n        self.alignment = alignment\n\n\nclass MarkdownHorizontalRuleNode(MarkdownASTNode):\n    \"\"\"Node representing a horizontal rule (<hr>).\"\"\"\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/markdown/markdown_ast_builder.py\n\n```python\n\"\"\"\nParser to construct an AST from Markdown.\n\"\"\"\n\nimport logging\nimport re\nfrom typing import Dict, List, Tuple, Any, cast\n\nfrom humbug.markdown.markdown_ast_node import (\n    MarkdownASTNode, MarkdownDocumentNode, MarkdownTextNode, MarkdownLineBreakNode,\n    MarkdownEmphasisNode, MarkdownBoldNode, MarkdownHeadingNode,\n    MarkdownParagraphNode, MarkdownOrderedListNode, MarkdownUnorderedListNode,\n    MarkdownListItemNode, MarkdownInlineCodeNode, MarkdownCodeBlockNode,\n    MarkdownTableNode, MarkdownTableHeaderNode, MarkdownTableBodyNode,\n    MarkdownTableRowNode, MarkdownTableCellNode, MarkdownHorizontalRuleNode,\n    MarkdownImageNode, MarkdownLinkNode\n)\nfrom humbug.syntax.parser_registry import ParserRegistry\nfrom humbug.syntax.programming_language import ProgrammingLanguage\nfrom humbug.syntax.programming_language_utils import ProgrammingLanguageUtils\n\n\nclass TableBufferState:\n    \"\"\"Class to track and buffer table elements during parsing.\"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize the table buffer state.\"\"\"\n        # Buffer for table rows before commitment\n        self.header_row: List[str] = []\n        self.header_line: str = \"\"\n        self.separator_row: List[str] = []\n        self.separator_line: str = \"\"\n        self.body_rows: List[List[str]] = []\n\n        # Table state\n        self.is_in_potential_table: bool = False\n        self.is_confirmed_table: bool = False\n        self.alignments: List[str] = []\n\n        # Line tracking for AST nodes\n        self.start_line: int = -1\n        self.current_line: int = -1\n\n    def reset(self) -> None:\n        \"\"\"Reset the table buffer state.\"\"\"\n        self.header_row = []\n        self.header_line = \"\"\n        self.separator_row = []\n        self.separator_line = \"\"\n        self.body_rows = []\n        self.is_in_potential_table = False\n        self.is_confirmed_table = False\n        self.alignments = []\n        self.start_line = -1\n        self.current_line = -1\n\n    def is_valid_table(self) -> bool:\n        \"\"\"\n        Check if we have sufficient elements for a valid table.\n\n        Returns:\n            True if we have a header row, separator row, and at least one body row\n        \"\"\"\n        return (len(self.header_row) > 0 and\n                len(self.separator_row) > 0 and\n                len(self.body_rows) > 0)\n\n\nclass ListState:\n    \"\"\"Tracks the state of a list and its items during parsing.\"\"\"\n\n    def __init__(self, list_node: MarkdownOrderedListNode | MarkdownUnorderedListNode, indent: int) -> None:\n        \"\"\"\n        Initialize a list state tracker.\n\n        Args:\n            list_node: The list node (MarkdownOrderedListNode or MarkdownUnorderedListNode)\n            indent: The indentation level of the list marker\n        \"\"\"\n        self.list_node = list_node\n        self.indent = indent\n        self.marker_length = 0\n        self.last_item: MarkdownListItemNode | None = None\n        self.contains_blank_line = False\n\n\nclass MarkdownASTBuilder:\n    \"\"\"\n    Builder class for constructing an AST from markdown text.\n\n    This class handles the incremental parsing of markdown text into an\n    Abstract Syntax Tree (AST) representation.\n    \"\"\"\n\n    def __init__(self, no_underscores: bool):\n        \"\"\"Initialize the AST builder with regex patterns for markdown elements.\"\"\"\n        self._no_underscores = no_underscores\n        self._source_path: str | None = None\n\n        # Regular expressions for markdown elements\n        self._heading_pattern = re.compile(r'^(#{1,10})\\s+(.*?)(?:\\s+#{1,10})?$', re.MULTILINE)\n        self._unordered_list_pattern = re.compile(r'^(\\s*)([*+-])\\s+(.*?)$', re.MULTILINE)\n        self._ordered_list_pattern = re.compile(r'^(\\s*)(\\d+)\\.[ \\t]+(.*?)$', re.MULTILINE)\n        self._code_block_pattern = re.compile(r'^```(?:([\\w\\-#+./*():\\s]+))?$')\n        self._table_row_pattern = re.compile(r'^(\\|.+\\|)$', re.MULTILINE)\n        self._table_separator_pattern = re.compile(r'^(\\|[\\s:-]+\\|)$', re.MULTILINE)\n        self._horizontal_rule_pattern = re.compile(r'^(?:\\s*(?:[-*_])\\s*){3,}$')\n\n        self._logger = logging.getLogger(\"MarkdownASTBuilder\")\n\n        # Initialize an empty document\n        self._document = MarkdownDocumentNode()\n\n        # Mapping from line numbers to nodes for incremental updates\n        self._line_to_node_map: Dict[int, List[MarkdownASTNode]] = {}\n\n        # Track header IDs to allow us to create unique link anchors for headings with the same text\n        self._used_header_ids: Dict[str, int] = {}\n\n        # List state tracking\n        self._list_stack: List[ListState] = []\n\n        # Text continuation tracking\n        self._last_paragraph: MarkdownParagraphNode | None = None\n        self._last_processed_line_type: str = \"\"\n        self._blank_line_count: int = 0\n\n        # Code block state tracking\n        self._in_code_block = False\n        self._code_block_language = \"\"\n        self._code_block_content: List[str] = []\n        self._code_block_start_line = -1\n        self._code_block_nesting_level = 0\n        self._code_block_indents: List[int] = []\n        self._embedded_parser_state: Any = None\n        self._embedded_language: ProgrammingLanguage = ProgrammingLanguage.UNKNOWN\n\n        # Table state tracking using the new buffer approach\n        self._table_buffer = TableBufferState()\n\n    def document(self) -> MarkdownDocumentNode:\n        \"\"\"\n        Get the current document node.\n\n        Returns:\n            The document node\n        \"\"\"\n        return self._document\n\n    def _should_parse_code_block_as_continuation(\n        self,\n        language: ProgrammingLanguage,\n        line_content: str\n    ) -> bool:\n        \"\"\"\n        Check if a line should be parsed as a continuation by the embedded parser.\n\n        Args:\n            language: The programming language of the code block\n            line_content: The content of the line to check\n\n        Returns:\n            True if this line should be treated as a continuation\n        \"\"\"\n        if language == ProgrammingLanguage.TEXT:\n            return False\n\n        # Get or create parser for this language\n        parser = ParserRegistry.create_parser(language)\n        assert parser is not None, f\"No parser registered for language: {language.name}\"\n\n        # If language changed, reset state\n        if language != self._embedded_language:\n            self._embedded_parser_state = None\n            self._embedded_language = language\n\n        # Parse the line and check if we're in a continuation\n        new_state = parser.parse(self._embedded_parser_state, line_content)\n\n        # Update stored state\n        self._embedded_parser_state = new_state\n\n        # Return whether we're in a continuation\n        return new_state is not None and new_state.parsing_continuation\n\n    def identify_line_type(self, line: str) -> Tuple[str, Any]:\n        \"\"\"\n        Identify the type of a markdown line.\n\n        Args:\n            line: The line to identify\n\n        Returns:\n            A tuple of (line_type, content) where line_type is one of:\n            'heading', 'unordered_list_item', 'ordered_list_item', 'blank', 'text',\n            'code_block_start', 'code_block_end', 'code_block_content',\n            'table_row', 'table_separator', 'line_break', 'horizontal_rule'\n        \"\"\"\n        # Handle code block state\n        lstripped_line = line.lstrip()\n        indent = len(line) - len(lstripped_line)\n\n        if self._in_code_block:\n            # Check if our embedded parser indicates this should be a continuation\n            if self._code_block_language:\n                language = ProgrammingLanguageUtils.from_name(self._code_block_language)\n                assert language != ProgrammingLanguage.UNKNOWN, \"Unknown programming language in code block\"\n                if self._should_parse_code_block_as_continuation(language, line):\n                    return 'code_block_content', line\n\n            # Check for code fence.  If we have one then we're either closing\n            # this block or nesting another.\n            code_block_match = self._code_block_pattern.match(lstripped_line)\n            if code_block_match:\n                language_name = code_block_match.group(1)\n                if language_name is not None or indent > self._code_block_indents[-1]:\n                    self._code_block_nesting_level += 1\n                    self._code_block_indents.append(indent)\n                    return 'code_block_content', line\n\n                self._code_block_indents.pop()\n                self._code_block_nesting_level -= 1\n                if self._code_block_nesting_level == 0:\n                    return 'code_block_end', None\n\n            return 'code_block_content', line\n\n        # Check for code block start\n        code_block_match = self._code_block_pattern.match(lstripped_line)\n        if code_block_match:\n            language_name = code_block_match.group(1) or \"\"\n            self._code_block_nesting_level = 1\n            self._code_block_indents.append(indent)\n            return 'code_block_start', language_name\n\n        # Check for a line break\n        if indent >= 2 and not lstripped_line:\n            return 'line_break', None\n\n        # Check for blank line\n        stripped_line = line.strip()\n        if not stripped_line:\n            return 'blank', None\n\n        # Check for heading\n        heading_match = self._heading_pattern.match(line)\n        if heading_match:\n            level = len(heading_match.group(1))\n            content = heading_match.group(2).strip()\n            return 'heading', (level, content)\n\n        # Check for table separator row\n        if stripped_line.startswith('|') and stripped_line.endswith('|'):\n            # Check if it's a separator row with at least one colon or dash\n            if '-' in line and (':-' in line or '-:' in line or '--' in line):\n                return 'table_separator', stripped_line\n\n            # Regular table row\n            return 'table_row', stripped_line\n\n        # Check for unordered list item\n        unordered_match = self._unordered_list_pattern.match(line)\n        if unordered_match:\n            indent = len(unordered_match.group(1))\n            marker = unordered_match.group(2)\n            content = unordered_match.group(3)\n            return 'unordered_list_item', (indent, marker, content)\n\n        # Check for ordered list item\n        ordered_match = self._ordered_list_pattern.match(line)\n        if ordered_match:\n            indent = len(ordered_match.group(1))\n            number = ordered_match.group(2)\n            content = ordered_match.group(3)\n            return 'ordered_list_item', (indent, number, content)\n\n        # Check for horizontal rule\n        if self._horizontal_rule_pattern.match(line):\n            return 'horizontal_rule', None\n\n        # Default to regular text\n        return 'text', line\n\n    def _find_closing_parenthesis(self, text: str, start_pos: int) -> int:\n        \"\"\"\n        Find the closing parenthesis that matches an opening one, handling nested parentheses.\n\n        Args:\n            text: The text to search in\n            start_pos: The position after the opening parenthesis\n\n        Returns:\n            The position of the closing parenthesis, or -1 if not found\n        \"\"\"\n        paren_count = 1\n        pos = start_pos\n\n        while pos < len(text):\n            if text[pos] == '(':\n                paren_count += 1\n\n            elif text[pos] == ')':\n                paren_count -= 1\n                if paren_count == 0:\n                    return pos\n\n            pos += 1\n\n        return -1\n\n    def _parse_url_and_title(self, url_title: str) -> Tuple[str, str | None]:\n        \"\"\"\n        Parse a URL string that may contain a title in quotes.\n\n        Args:\n            url_title: The string containing URL and optional title\n\n        Returns:\n            A tuple of (url, title) where title may be None\n        \"\"\"\n        # Look for title in quotes\n        title_match = re.search(r'\\s+[\\'\"](.+?)[\\'\"]$', url_title)\n        if title_match:\n            title = title_match.group(1)\n            url = url_title[:title_match.start()].strip()\n            return url, title\n\n        return url_title.strip(), None\n\n    def _parse_inline_formatting(self, text: str) -> List[MarkdownASTNode]:\n        \"\"\"\n        Parse inline formatting (bold, italic, inline code) in text and create appropriate AST nodes.\n\n        Args:\n            text: The text to parse\n\n        Returns:\n            A list of AST nodes representing the formatted text\n        \"\"\"\n        # Check if text has trailing line break\n        has_line_break = text.endswith('  ')\n        if has_line_break:\n            text = text[:-2]\n\n        # Simple state machine for inline formatting\n        i = 0\n        nodes: List[MarkdownASTNode] = []\n        current_text = \"\"\n\n        while i < len(text):\n            # Check for image (highest precedence due to the '!' prefix)\n            if text[i] == '!' and i + 1 < len(text) and text[i+1] == '[':\n                # Look for the closing '](' pattern\n                bracket_end = text.find('](', i + 2)\n                if bracket_end != -1:\n                    # Find closing parenthesis\n                    paren_end = self._find_closing_parenthesis(text, bracket_end + 2)\n                    if paren_end != -1:\n                        # Add any accumulated text before this image\n                        if current_text:\n                            nodes.append(MarkdownTextNode(current_text))\n                            current_text = \"\"\n\n                        # Extract the alt text and URL\n                        alt_text = text[i+2:bracket_end]\n                        url_title = text[bracket_end+2:paren_end]\n                        url, title = self._parse_url_and_title(url_title)\n\n                        # Create image node\n                        image_node = MarkdownImageNode(url, alt_text, title)\n                        nodes.append(image_node)\n\n                        # Move past the closing parenthesis\n                        i = paren_end + 1\n                        continue\n\n            # Check for link\n            elif text[i] == '[':\n                # Look for the closing '](' pattern\n                bracket_end = text.find('](', i + 1)\n                if bracket_end != -1:\n                    # Find closing parenthesis\n                    paren_end = self._find_closing_parenthesis(text, bracket_end + 2)\n                    if paren_end != -1:\n                        # Add any accumulated text before this link\n                        if current_text:\n                            nodes.append(MarkdownTextNode(current_text))\n                            current_text = \"\"\n\n                        # Extract the link text and URL\n                        link_text = text[i+1:bracket_end]\n                        url_title = text[bracket_end+2:paren_end]\n                        url, title = self._parse_url_and_title(url_title)\n\n                        # Create link node\n                        link_node = MarkdownLinkNode(url, title)\n\n                        # Process the content inside the link text recursively\n                        for child_node in self._parse_inline_formatting(link_text):\n                            link_node.add_child(child_node)\n\n                        nodes.append(link_node)\n\n                        # Move past the closing parenthesis\n                        i = paren_end + 1\n                        continue\n\n            # Check for inline code (high precedence)\n            elif text[i] == '`':\n                # Look for the closing backtick\n                end_pos = text.find('`', i + 1)\n                if end_pos != -1:\n                    # Add any accumulated text before this code block\n                    if current_text:\n                        nodes.append(MarkdownTextNode(current_text))\n                        current_text = \"\"\n\n                    # Extract the code content (excluding backticks)\n                    code_content = text[i+1:end_pos]\n                    nodes.append(MarkdownInlineCodeNode(code_content))\n\n                    # Move past the closing backtick\n                    i = end_pos + 1\n                    continue\n\n            # Check for bold formatting\n            elif (i + 1 < len(text) and\n                    ((text[i:i+2] == '**') or (text[i:i+2] == '__' and not self._no_underscores))):\n                # Determine which marker we're using\n                marker = text[i:i+2]\n\n                # Look for the closing marker\n                end_pos = text.find(marker, i + 2)\n                if end_pos != -1:\n                    # Add any accumulated text before this bold block\n                    if current_text:\n                        nodes.append(MarkdownTextNode(current_text))\n                        current_text = \"\"\n\n                    # Extract the bold content (excluding markers)\n                    bold_content = text[i+2:end_pos]\n\n                    # Create bold node and process its content recursively\n                    bold_node = MarkdownBoldNode()\n\n                    # Process the content inside the bold\n                    for child_node in self._parse_inline_formatting(bold_content):\n                        bold_node.add_child(child_node)\n\n                    nodes.append(bold_node)\n\n                    # Move past the closing marker\n                    i = end_pos + 2\n                    continue\n\n            # Check for italic formatting\n            elif (text[i] == '*' or (text[i] == '_' and not self._no_underscores)) and (\n                    i == 0 or text[i-1] != text[i]):  # Avoid mistaking ** as *\n\n                # Determine which marker we're using\n                marker = text[i]\n\n                # Look for the closing marker\n                end_pos = text.find(marker, i + 1)\n                if end_pos != -1 and (end_pos + 1 >= len(text) or text[end_pos+1] != marker):  # Avoid **\n                    # Add any accumulated text before this italic block\n                    if current_text:\n                        nodes.append(MarkdownTextNode(current_text))\n                        current_text = \"\"\n\n                    # Extract the italic content (excluding markers)\n                    italic_content = text[i+1:end_pos]\n\n                    # Create emphasis node and process its content recursively\n                    emphasis_node = MarkdownEmphasisNode()\n\n                    # Process the content inside the emphasis\n                    for child_node in self._parse_inline_formatting(italic_content):\n                        emphasis_node.add_child(child_node)\n\n                    nodes.append(emphasis_node)\n\n                    # Move past the closing marker\n                    i = end_pos + 1\n                    continue\n\n            # No formatting found, accumulate normal text\n            current_text += text[i]\n            i += 1\n\n        # Add any remaining accumulated text\n        if current_text:\n            nodes.append(MarkdownTextNode(current_text))\n\n        # Append a line break node if needed\n        if has_line_break:\n            nodes.append(MarkdownLineBreakNode())\n\n        return nodes\n\n    def _create_id_from_text(self, text: str) -> str:\n        \"\"\"\n        Create a simplified ID from text suitable for HTML anchor links.\n\n        Args:\n            text: The text to convert to an ID\n\n        Returns:\n            A simplified string suitable for use as an element ID\n        \"\"\"\n        # Convert to lowercase\n        text = text.lower()\n\n        # Replace spaces with hyphens\n        text = text.replace(' ', '-')\n\n        # Remove special characters\n        text = re.sub(r'[^a-z0-9-]', '', text)\n\n        # Ensure it doesn't start with a number\n        if text and text[0].isdigit():\n            text = 'h-' + text\n\n        return text\n\n    def _parse_heading(self, level: int, content: str, line_num: int) -> None:\n        \"\"\"\n        Parse a heading line and create a heading node.\n\n        Args:\n            level: The heading level (1-6)\n            content: The heading content\n            line_num: The line number\n        \"\"\"\n        anchor_id = self._create_id_from_text(content)\n\n        # Check if this ID already exists.  If it doesn't, then record we've seen it.   If it does,\n        # then add a suffix to it to make it unique.\n        if anchor_id not in self._used_header_ids:\n            self._used_header_ids[anchor_id] = 0\n\n        else:\n            # This ID already exists, increment the counter and append it\n            self._used_header_ids[anchor_id] += 1\n            anchor_id = f\"{anchor_id}-{self._used_header_ids[anchor_id]}\"\n\n        heading = MarkdownHeadingNode(level, anchor_id)\n        for node in self._parse_inline_formatting(content):\n            heading.add_child(node)\n\n        heading.line_start = line_num\n        heading.line_end = line_num\n        self._register_node_line(heading, line_num)\n\n        self._document.add_child(heading)\n\n    def _parse_text(self, text: str, line_num: int) -> MarkdownParagraphNode:\n        \"\"\"\n        Parse a text line and create a paragraph node.\n\n        Args:\n            text: The text content\n            line_num: The line number\n        \"\"\"\n        paragraph = MarkdownParagraphNode()\n        for node in self._parse_inline_formatting(text):\n            paragraph.add_child(node)\n\n        paragraph.line_start = line_num\n        paragraph.line_end = line_num\n        self._register_node_line(paragraph, line_num)\n\n        self._document.add_child(paragraph)\n        return paragraph\n\n    def _current_list_state(self) -> ListState | None:\n        \"\"\"\n        Return the current list state or None if not in a list.\n\n        Returns:\n            The current list state or None\n        \"\"\"\n        return self._list_stack[-1] if self._list_stack else None\n\n    def _close_lists_at_indent(self, indent: int, consider_marker: bool) -> bool:\n        \"\"\"\n        Close all lists deeper than the given indent level.\n\n        Args:\n            indent: The indentation level\n            consider_marker: Whether to consider the marker length for closing lists\n\n        Returns:\n            True if lists were closed, False otherwise\n        \"\"\"\n        if not self._list_stack:\n            return False\n\n        closed_lists = False\n\n        while self._list_stack:\n            marker_adjust = self._list_stack[-1].marker_length if consider_marker else 0\n            if (self._list_stack[-1].indent + marker_adjust) <= indent:\n                break\n\n            self._list_stack.pop()\n            closed_lists = True\n\n        return closed_lists\n\n    def _find_parent_for_list(self) -> MarkdownASTNode:\n        \"\"\"\n        Find the appropriate parent for a new list.\n\n        Returns:\n            The parent node\n        \"\"\"\n        if not self._list_stack:\n            return self._document\n\n        # Find the last list item of the deepest list to be the parent\n        current_list = self._list_stack[-1]\n        assert current_list.last_item is not None, \"Current list state should have a last item\"\n        return current_list.last_item\n\n    def _find_or_create_ordered_list(self, indent: int, start_number: int) -> MarkdownOrderedListNode:\n        \"\"\"\n        Find or create an ordered list at the given indent level with specified start number.\n\n        Args:\n            indent: The indentation level\n            start_number: The starting number\n\n        Returns:\n            The created ordered list node\n        \"\"\"\n        # Check if we already have an ordered list at this level\n        if self._list_stack and self._list_stack[-1].indent == indent:\n            list_state = self._list_stack[-1]\n            if isinstance(list_state.list_node, MarkdownOrderedListNode):\n                return list_state.list_node\n\n            # Different list type, close it\n            self._list_stack.pop()\n\n        # Find parent\n        parent = self._find_parent_for_list()\n\n        # Create new ordered list\n        new_list = MarkdownOrderedListNode(indent, start_number)\n        parent.add_child(new_list)\n\n        # Create and add list state\n        list_state = ListState(new_list, indent)\n        self._list_stack.append(list_state)\n\n        return new_list\n\n    def _parse_ordered_list_item(self, indent: int, number: str, content: str, line_num: int) -> None:\n        \"\"\"\n        Parse an ordered list item and create a list item node.\n\n        Args:\n            indent: The indentation level\n            number: The list item number (as a string)\n            content: The item content\n            line_num: The line number\n        \"\"\"\n        # Extract the starting number\n        start_number = int(number)\n\n        # Close deeper lists\n        self._close_lists_at_indent(indent, False)\n\n        # If we're in a list, and we've seen a blank line, then mark the list as loose\n        if self._list_stack and self._blank_line_count > 0:\n            self._list_stack[-1].contains_blank_line = True\n            self._list_stack[-1].list_node.tight = False\n\n        list_node = self._find_or_create_ordered_list(indent, start_number)\n        current_list = cast(ListState, self._current_list_state())\n\n        # Create the list item\n        item = MarkdownListItemNode()\n        list_node.add_child(item)\n\n        # Calculate the actual content indentation for this specific marker\n        current_list.marker_length = len(number) + 2  # +2 for the \".\" and space after number\n\n        # Create a paragraph for the content\n        paragraph = MarkdownParagraphNode()\n        for node in self._parse_inline_formatting(content):\n            paragraph.add_child(node)\n\n        paragraph.line_start = line_num\n        paragraph.line_end = line_num\n        item.add_child(paragraph)\n        self._register_node_line(paragraph, line_num)\n\n        item.line_start = line_num\n        item.line_end = line_num\n        self._register_node_line(item, line_num)\n\n        # Update tracking variables\n        current_list.last_item = item\n        self._last_processed_line_type = 'ordered_list_item'\n\n    def _find_or_create_unordered_list(self, indent: int) -> MarkdownUnorderedListNode:\n        \"\"\"\n        Find or create an unordered list at the given indent level.\n\n        Args:\n            indent: The indentation level\n\n        Returns:\n            The created unordered list node\n        \"\"\"\n        # Check if we already have an unordered list at this level\n        if self._list_stack and self._list_stack[-1].indent == indent:\n            list_state = self._list_stack[-1]\n            if isinstance(list_state.list_node, MarkdownUnorderedListNode):\n                return list_state.list_node\n\n            # Different list type, close it\n            self._list_stack.pop()\n\n        # Find parent\n        parent = self._find_parent_for_list()\n\n        # Create new unordered list\n        new_list = MarkdownUnorderedListNode(indent)\n        parent.add_child(new_list)\n\n        # Create and add list state\n        list_state = ListState(new_list, indent)\n        self._list_stack.append(list_state)\n\n        return new_list\n\n    def _parse_unordered_list_item(self, indent: int, marker: str, content: str, line_num: int) -> None:\n        \"\"\"\n        Parse an unordered list item and create a list item node.\n\n        Args:\n            indent: The indentation level\n            marker: The bullet marker (-, *, +)\n            content: The item content\n            line_num: The line number\n        \"\"\"\n        # Close deeper lists\n        self._close_lists_at_indent(indent, False)\n\n        # If we're in a list, and we've seen a blank line, then mark the list as loose\n        if self._list_stack and self._blank_line_count > 0:\n            self._list_stack[-1].contains_blank_line = True\n            self._list_stack[-1].list_node.tight = False\n\n        list_node = self._find_or_create_unordered_list(indent)\n        current_list = cast(ListState, self._current_list_state())\n\n        # Create the list item\n        item = MarkdownListItemNode()\n        list_node.add_child(item)\n\n        # Calculate the actual content indentation for this specific marker\n        current_list.marker_length = len(marker) + 1  # +1 for the space after marker\n\n        # Create a paragraph for the content\n        paragraph = MarkdownParagraphNode()\n        for node in self._parse_inline_formatting(content):\n            paragraph.add_child(node)\n\n        paragraph.line_start = line_num\n        paragraph.line_end = line_num\n        item.add_child(paragraph)\n        self._register_node_line(paragraph, line_num)\n\n        item.line_start = line_num\n        item.line_end = line_num\n        self._register_node_line(item, line_num)\n\n        # Update tracking variables\n        current_list.last_item = item\n        self._last_processed_line_type = 'unordered_list_item'\n\n    def _parse_horizontal_rule(self, line_num: int) -> MarkdownHorizontalRuleNode:\n        \"\"\"\n        Parse a horizontal rule line and create a horizontal rule node.\n\n        Args:\n            line_num: The line number\n\n        Returns:\n            A horizontal rule node\n        \"\"\"\n        horizontal_rule = MarkdownHorizontalRuleNode()\n        horizontal_rule.line_start = line_num\n        horizontal_rule.line_end = line_num\n        self._register_node_line(horizontal_rule, line_num)\n\n        return horizontal_rule\n\n    def _parse_table_separator(self, separator_line: str) -> List[str]:\n        \"\"\"\n        Parse a table separator line to determine column alignments.\n\n        Args:\n            separator_line: A line containing the table column separators (e.g., |---|:---:|--:|)\n\n        Returns:\n            List of alignment strings ('left', 'center', 'right') for each column\n        \"\"\"\n        cells = [cell.strip() for cell in separator_line.split('|')[1:-1]]\n        alignments = []\n\n        for cell in cells:\n            if cell.startswith(':') and cell.endswith(':'):\n                alignments.append('center')\n\n            elif cell.endswith(':'):\n                alignments.append('right')\n\n            else:\n                alignments.append('left')\n\n        return alignments\n\n    def _handle_table_row(self, line: str, line_num: int) -> None:\n        \"\"\"\n        Handle a table row line in the parsing process.\n\n        Args:\n            line: The table row line\n            line_num: The line number\n\n        Returns:\n            None\n        \"\"\"\n        # Is this a body row?\n        if self._table_buffer.is_confirmed_table:\n            cells = [cell.strip() for cell in line.split('|')[1:-1]]\n            self._table_buffer.body_rows.append(cells)\n            self._table_buffer.current_line = line_num\n            return\n\n        # Is this another header row?  If yes, we can't have two, so emit the last one as text\n        if self._table_buffer.is_in_potential_table:\n            self._parse_text(self._table_buffer.header_line, self._table_buffer.start_line)\n\n        else:\n            self._table_buffer.is_in_potential_table = True\n            self._table_buffer.start_line = line_num\n\n        cells = [cell.strip() for cell in line.split('|')[1:-1]]\n        self._table_buffer.header_row = cells\n        self._table_buffer.header_line = line\n        self._table_buffer.current_line = line_num\n\n    def _handle_table_separator(self, line: str, line_num: int) -> None:\n        \"\"\"\n        Handle a table separator line in the parsing process.\n\n        Args:\n            line: The table separator line\n            line_num: The line number\n\n        Returns:\n            None\n        \"\"\"\n        # If we're not already in a potential table, ignore it\n        if not self._table_buffer.is_in_potential_table:\n            # Treat as normal text\n            self._parse_text(line, line_num)\n            return\n\n        # Store the separator row\n        cells = [cell.strip() for cell in line.split('|')[1:-1]]\n        self._table_buffer.separator_row = cells\n        self._table_buffer.separator_line = line\n\n        # Parse alignments\n        self._table_buffer.alignments = self._parse_table_separator(line)\n        self._table_buffer.current_line = line_num\n\n        # Mark as a confirmed table now that we have a separator\n        self._table_buffer.is_confirmed_table = True\n\n    def _create_table_from_buffer(self) -> None:\n        \"\"\"\n        Create a table node from the buffered content.\n\n        Returns:\n            None\n        \"\"\"\n        # Create the table structure\n        table_node = MarkdownTableNode()\n        header_node = MarkdownTableHeaderNode()\n        body_node = MarkdownTableBodyNode()\n\n        # Set line information\n        table_node.line_start = self._table_buffer.start_line\n        table_node.line_end = self._table_buffer.current_line\n        header_node.line_start = self._table_buffer.start_line\n\n        # Add header and body to table\n        table_node.add_child(header_node)\n        table_node.add_child(body_node)\n\n        # Process header rows\n        row_node = MarkdownTableRowNode()\n        row_line = self._table_buffer.start_line\n        row_node.line_start = row_line\n        row_node.line_end = row_line\n\n        for j, cell_content in enumerate(self._table_buffer.header_row):\n            # Determine alignment\n            alignment = 'left'\n            if j < len(self._table_buffer.alignments):\n                alignment = self._table_buffer.alignments[j]\n\n            # Create cell\n            cell_node = MarkdownTableCellNode(is_header=True, alignment=alignment)\n\n            # Add content to cell\n            for text_node in self._parse_inline_formatting(cell_content):\n                cell_node.add_child(text_node)\n\n            row_node.add_child(cell_node)\n\n        header_node.add_child(row_node)\n        self._register_node_line(row_node, row_line)\n\n        # Set header end line\n        header_node.line_end = self._table_buffer.start_line\n\n        # Process body rows\n        body_start_line = self._table_buffer.start_line + 1\n        body_node.line_start = body_start_line\n\n        for i, row_cells in enumerate(self._table_buffer.body_rows):\n            row_node = MarkdownTableRowNode()\n            row_line = body_start_line + i\n            row_node.line_start = row_line\n            row_node.line_end = row_line\n\n            for j, cell_content in enumerate(row_cells):\n                # Determine alignment\n                alignment = 'left'\n                if j < len(self._table_buffer.alignments):\n                    alignment = self._table_buffer.alignments[j]\n\n                # Create cell\n                cell_node = MarkdownTableCellNode(is_header=False, alignment=alignment)\n\n                # Add content to cell\n                for text_node in self._parse_inline_formatting(cell_content):\n                    cell_node.add_child(text_node)\n\n                row_node.add_child(cell_node)\n\n            body_node.add_child(row_node)\n            self._register_node_line(row_node, row_line)\n\n        body_node.line_end = self._table_buffer.current_line\n\n        # Add the table to the document\n        self._document.add_child(table_node)\n\n        # Register table with line mappings\n        for i in range(self._table_buffer.start_line, self._table_buffer.current_line + 1):\n            self._register_node_line(table_node, i)\n\n        # Reset table buffer\n        self._table_buffer.reset()\n\n    def _handle_incomplete_table(self) -> None:\n        \"\"\"\n        Handle buffered table content that doesn't form a complete table.\n        Convert it to regular paragraphs.\n\n        Returns:\n            None\n        \"\"\"\n        # Render header rows as regular text\n        self._parse_text(self._table_buffer.header_line, self._table_buffer.start_line)\n\n        # Handle separator if present\n        if self._table_buffer.separator_row:\n            self._parse_text(self._table_buffer.separator_line, self._table_buffer.start_line + 1)\n\n        # Reset table buffer\n        self._table_buffer.reset()\n\n    def _register_node_line(self, node: MarkdownASTNode, line_num: int) -> None:\n        \"\"\"\n        Register a node with a line number for later reference.\n\n        Args:\n            node: The AST node\n            line_num: The line number\n\n        Returns:\n            None\n        \"\"\"\n        if line_num not in self._line_to_node_map:\n            self._line_to_node_map[line_num] = []\n\n        self._line_to_node_map[line_num].append(node)\n\n    def _finalize_code_block(self, end_line: int) -> None:\n        \"\"\"\n        Finalize a code block that might be unclosed at document end.\n\n        Args:\n            end_line: The last line number in the document\n\n        Returns:\n            None\n        \"\"\"\n        # Create a code block node for the unclosed block\n        code_block = MarkdownCodeBlockNode(\n            language=self._code_block_language,\n            content='\\n'.join(self._code_block_content)\n        )\n        code_block.line_start = self._code_block_start_line\n        code_block.line_end = end_line\n\n        # Add to document\n        self._document.add_child(code_block)\n\n        # Register code block with all lines it spans\n        for i in range(self._code_block_start_line, end_line + 1):\n            self._register_node_line(code_block, i)\n\n        # Reset code block state\n        self._in_code_block = False\n        self._code_block_language = \"\"\n        self._code_block_content = []\n        self._code_block_start_line = -1\n        self._code_block_nesting_level = 0\n        self._code_block_indents = []\n        self._embedded_parser_state = None\n        self._embedded_language = ProgrammingLanguage.UNKNOWN\n\n    def _handle_text_continuation(self, text: str, line_num: int) -> bool:\n        \"\"\"\n        Handle text as a continuation of the previous paragraph or list item.\n        A text line is a continuation of a list item if it is indented\n        by at least the same amount as the list item's content indent.\n\n        Args:\n            text: The text content\n            line_num: The line number\n\n        Returns:\n            True if handled as a continuation, False otherwise\n        \"\"\"\n        # Case 1: Continue a paragraph\n        if self._last_paragraph and self._last_processed_line_type == 'text':\n            # Add a space between the continued text as long as we didn't just have a line break\n            if not isinstance(self._last_paragraph.children[-1], MarkdownLineBreakNode):\n                self._last_paragraph.add_child(MarkdownTextNode(\" \"))\n\n            for node in self._parse_inline_formatting(text):\n                self._last_paragraph.add_child(node)\n\n            self._last_paragraph.line_end = line_num\n            self._register_node_line(self._last_paragraph, line_num)\n            return True\n\n        # Case 2: Continue a list item paragraph\n        if self._list_stack and self._last_processed_line_type in ('unordered_list_item', 'ordered_list_item', 'blank', 'text'):\n            # Get the indentation of the current line\n            current_indent = len(text) - len(text.lstrip())\n\n            if self._close_lists_at_indent(current_indent, True):\n                # We closed one or more lists, we should treat it as if a blank line was encountered\n                # This will ensure proper formatting when returning to an outer list\n                if self._list_stack:\n                    self._last_processed_line_type = 'blank'\n                    self._blank_line_count = 1\n\n                # Reset the paragraph continuity as well\n                self._last_paragraph = None\n\n            # If we're continuing a list item and we've seen a blank line, mark the list as loose\n            if self._list_stack and self._blank_line_count > 0:\n                self._list_stack[-1].contains_blank_line = True\n                self._list_stack[-1].list_node.tight = False\n\n            list_state = self._current_list_state()\n            if not list_state or not list_state.last_item:\n                return False\n\n            formatted_text = text.lstrip()\n\n            # Find the paragraph within the last list item and continue it\n            last_item = list_state.last_item\n            paragraph = cast(MarkdownParagraphNode, last_item.children[-1])\n\n            # If we weren't just preceded by a line break then add a space\n            if paragraph.children and not isinstance(paragraph.children[-1], MarkdownLineBreakNode):\n                paragraph.add_child(MarkdownTextNode(\" \"))\n\n            for node in self._parse_inline_formatting(formatted_text):\n                paragraph.add_child(node)\n\n            paragraph.line_end = line_num\n            self._register_node_line(paragraph, line_num)\n\n            last_item.line_end = line_num\n            self._register_node_line(last_item, line_num)\n            return True\n\n        return False\n\n    def _reset_list_state(self) -> None:\n        \"\"\"Reset all list tracking state.\"\"\"\n        self._list_stack = []\n\n    def _parse_line(self, line: str, line_num: int) -> None:\n        \"\"\"\n        Parse a single line and add the resulting nodes to the AST.\n\n        Args:\n            line: The line to parse\n            line_num: The line number\n\n        Returns:\n            None\n        \"\"\"\n        line_type, content = self.identify_line_type(line)\n\n        # Reset paragraph tracking if not continuing text\n        if line_type not in ('text', 'blank', 'line_break'):\n            self._last_paragraph = None\n\n        # Handle table ends when a non-table line is encountered\n        if self._table_buffer.is_in_potential_table and line_type not in ('table_row', 'table_separator'):\n            # Check if we have a complete table to create\n            if self._table_buffer.is_valid_table():\n                self._create_table_from_buffer()\n\n            else:\n                # Not a valid table, render as regular text\n                self._handle_incomplete_table()\n\n        if line_type == 'line_break':\n            self._document.add_child(MarkdownLineBreakNode())\n            return\n\n        if line_type == 'blank':\n            self._blank_line_count += 1\n            self._last_processed_line_type = line_type\n            return\n\n        if line_type == 'unordered_list_item':\n            indent, marker, text = content\n            self._parse_unordered_list_item(indent, marker, text, line_num)\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        if line_type == 'ordered_list_item':\n            indent, number, text = content\n            self._parse_ordered_list_item(indent, number, text, line_num)\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        if line_type == 'code_block_start':\n            self._in_code_block = True\n            self._code_block_language = content\n            self._code_block_content = []\n            self._code_block_start_line = line_num\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        if line_type == 'code_block_content':\n            self._code_block_content.append(content)\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        if line_type == 'code_block_end':\n            self._finalize_code_block(line_num)\n            self._reset_list_state()\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        # Handle table-related lines\n        if line_type == 'table_row':\n            self._handle_table_row(content, line_num)\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        if line_type == 'table_separator':\n            self._handle_table_separator(content, line_num)\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        # Process other line types\n        if line_type == 'heading':\n            level, heading_text = content\n            self._parse_heading(level, heading_text, line_num)\n            self._reset_list_state()\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        if line_type == 'horizontal_rule':\n            horizontal_rule = self._parse_horizontal_rule(line_num)\n            self._document.add_child(horizontal_rule)\n            self._reset_list_state()\n            self._last_processed_line_type = line_type\n            self._blank_line_count = 0\n            return\n\n        # We have text left\n        # Try to handle as a continuation first\n        if self._handle_text_continuation(content, line_num):\n            self._last_processed_line_type = line_type\n            return\n\n        # Regular paragraph\n        paragraph = self._parse_text(content, line_num)\n        self._last_paragraph = paragraph\n        self._reset_list_state()\n        self._last_processed_line_type = line_type\n        self._blank_line_count = 0\n\n    def build_ast(self, text: str) -> MarkdownDocumentNode:\n        \"\"\"\n        Build a complete AST from the given text.\n\n        Args:\n            text: The markdown text to parse\n\n        Returns:\n            The document root node\n        \"\"\"\n        self._document = MarkdownDocumentNode(self._source_path)\n        self._line_to_node_map = {}\n        self._reset_list_state()\n        self._last_paragraph = None\n        self._last_processed_line_type = \"\"\n        self._blank_line_count = 0\n        self._in_code_block = False\n        self._code_block_language = \"\"\n        self._code_block_content = []\n        self._code_block_start_line = -1\n        self._code_block_nesting_level = 0\n        self._code_block_indents = []\n\n        # Reset table buffer\n        self._table_buffer.reset()\n\n        # Parse line by line\n        lines = text.split('\\n')\n        for i, line in enumerate(lines):\n            self._parse_line(line, i)\n\n        # Check for any buffered table content at the end of the document\n        if self._table_buffer.is_in_potential_table:\n            if self._table_buffer.is_valid_table():\n                self._create_table_from_buffer()\n\n            else:\n                self._handle_incomplete_table()\n\n        # Handle case where document ends while still in a code block\n        if self._in_code_block:\n            self._finalize_code_block(len(lines) - 1)\n\n        return self._document\n\n    def update_ast(self, text: str, previous_text: str, path: str | None = None) -> MarkdownDocumentNode:\n        \"\"\"\n        Update the AST incrementally based on changes between previous_text and text.\n\n        Args:\n            text: The new markdown text\n            previous_text: The previous markdown text, or None if this is the first update\n            path: Optional path to the source markdown file\n\n        Returns:\n            The updated document root node\n        \"\"\"\n        self._source_path = path\n        if previous_text is None or not self._document.children:\n            # First update or empty document, build from scratch\n            return self.build_ast(text)\n\n        # Split into lines\n        new_lines = text.split('\\n')\n        old_lines = previous_text.split('\\n')\n\n        # Find common prefix length (unchanged lines)\n        common_prefix_len = 0\n        for i, (old, new) in enumerate(zip(old_lines, new_lines)):\n            if old == new:\n                common_prefix_len = i + 1\n\n            else:\n                break\n\n        # Find common suffix length (unchanged lines from the end)\n        common_suffix_len = 0\n        for i, (old, new) in enumerate(zip(reversed(old_lines), reversed(new_lines))):\n            if old == new and common_prefix_len + common_suffix_len < min(len(old_lines), len(new_lines)):\n                common_suffix_len = i + 1\n\n            else:\n                break\n\n        # Calculate changed region\n        start = common_prefix_len\n        old_end = len(old_lines) - common_suffix_len\n        new_end = len(new_lines) - common_suffix_len\n\n        # If nothing changed, return existing document\n        if start >= old_end and start >= new_end:\n            return self._document\n\n        # For now, just rebuild the entire AST\n        # In the future we might implement incremental updates\n        return self.build_ast(text)\n```\n\nFile: /Users/dave/github/m6r/humbug/src/humbug/markdown/markdown_ast_printer.py\n\n```python\n\"\"\"\nVisitor class to print markdown AST structures for debugging\n\"\"\"\nfrom typing import List, Any, cast\n\nfrom humbug.ast.ast import ASTNode\nfrom humbug.markdown.markdown_ast_node import (\n    MarkdownASTVisitor, MarkdownTextNode, MarkdownHeadingNode, MarkdownInlineCodeNode,\n    MarkdownCodeBlockNode, MarkdownASTNode, MarkdownTableNode, MarkdownTableHeaderNode,\n    MarkdownTableBodyNode, MarkdownTableRowNode, MarkdownTableCellNode, MarkdownHorizontalRuleNode,\n    MarkdownLinkNode, MarkdownImageNode\n)\n\n\nclass MarkdownASTPrinter(MarkdownASTVisitor):\n    \"\"\"Visitor that prints the AST structure for debugging.\"\"\"\n    def __init__(self) -> None:\n        \"\"\"Initialize the AST printer with zero indentation.\"\"\"\n        super().__init__()\n        self.indent_level = 0\n\n    def _indent(self) -> str:\n        \"\"\"\n        Get the current indentation string.\n\n        Returns:\n            A string of spaces for the current indentation level\n        \"\"\"\n        return \"  \" * self.indent_level\n\n    def generic_visit(self, node: ASTNode) -> List[Any]:\n        \"\"\"\n        Default visit method that prints the node type.\n\n        Args:\n            node: The node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        ast_node = cast(MarkdownASTNode, node)\n        node_name = node.__class__.__name__\n        line_range = \"\"\n        if ast_node.line_start is not None and ast_node.line_end is not None:\n            line_range = f\" (lines {ast_node.line_start}-{ast_node.line_end})\"\n\n        print(f\"{self._indent()}{node_name}{line_range}\")\n        self.indent_level += 1\n        results = super().generic_visit(ast_node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownTextNode(self, node: MarkdownTextNode) -> str:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a text node and print its content.\n\n        Args:\n            node: The text node to visit\n\n        Returns:\n            The text content\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None:\n            line_range = f\" (line {node.line_start})\"\n\n        print(f\"{self._indent()}Text{line_range}: '{node.content}'\")\n        return node.content\n\n    def visit_MarkdownHeadingNode(self, node: MarkdownHeadingNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a heading node and print its level.\n\n        Args:\n            node: The heading node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None:\n            line_range = f\" (line {node.line_start})\"\n\n        print(f\"{self._indent()}Heading (level {node.level}){line_range}\")\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownInlineCodeNode(self, node: MarkdownInlineCodeNode) -> str:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit an inline code node and print its content.\n\n        Args:\n            node: The inline code node to visit\n\n        Returns:\n            The inline code content\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None:\n            line_range = f\" (line {node.line_start})\"\n\n        print(f\"{self._indent()}InlineCode{line_range}: '{node.content}'\")\n        return node.content\n\n    def visit_MarkdownLinkNode(self, node: MarkdownLinkNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a link node and print its URL and title.\n\n        Args:\n            node: The link node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None and node.line_end is not None:\n            line_range = f\" (lines {node.line_start}-{node.line_end})\"\n\n        title_info = f\", title='{node.title}'\" if node.title else \"\"\n        print(f\"{self._indent()}Link{line_range}: url='{node.url}'{title_info}\")\n\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownImageNode(self, node: MarkdownImageNode) -> str:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit an image node and print its URL, alt text, and title.\n\n        Args:\n            node: The image node to visit\n\n        Returns:\n            The image URL\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None and node.line_end is not None:\n            line_range = f\" (lines {node.line_start}-{node.line_end})\"\n\n        title_info = f\", title='{node.title}'\" if node.title else \"\"\n        print(f\"{self._indent()}Image{line_range}: url='{node.url}', alt='{node.alt_text}'{title_info}\")\n        return node.url\n\n    def visit_MarkdownCodeBlockNode(self, node: MarkdownCodeBlockNode) -> str:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a code block node and print its language and content.\n\n        Args:\n            node: The code block node to visit\n\n        Returns:\n            The code block content\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None and node.line_end is not None:\n            line_range = f\" (lines {node.line_start}-{node.line_end})\"\n\n        print(f\"{self._indent()}CodeBlock{line_range}: language='{node.language}'\")\n        self.indent_level += 1\n        print(f\"{self._indent()}Content: '{node.content[:30]}...' ({len(node.content)} chars)\")\n        self.indent_level -= 1\n        return node.content\n\n    def visit_MarkdownTableNode(self, node: MarkdownTableNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a table node and print its structure.\n\n        Args:\n            node: The table node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None and node.line_end is not None:\n            line_range = f\" (lines {node.line_start}-{node.line_end})\"\n\n        print(f\"{self._indent()}Table{line_range}\")\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownTableHeaderNode(self, node: MarkdownTableHeaderNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a table header node and print its info.\n\n        Args:\n            node: The table header node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        print(f\"{self._indent()}TableHeader\")\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownTableBodyNode(self, node: MarkdownTableBodyNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a table body node and print its info.\n\n        Args:\n            node: The table body node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        print(f\"{self._indent()}TableBody\")\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownTableRowNode(self, node: MarkdownTableRowNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a table row node and print its info.\n\n        Args:\n            node: The table row node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None and node.line_end is not None:\n            line_range = f\" (lines {node.line_start}-{node.line_end})\"\n\n        print(f\"{self._indent()}TableRow{line_range}\")\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownTableCellNode(self, node: MarkdownTableCellNode) -> List[Any]:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a table cell node and print its properties.\n\n        Args:\n            node: The table cell node to visit\n\n        Returns:\n            The results of visiting the children\n        \"\"\"\n        cell_type = \"HeaderCell\" if node.is_header else \"Cell\"\n        print(f\"{self._indent()}{cell_type} (alignment: {node.alignment})\")\n        self.indent_level += 1\n        results = super().generic_visit(node)\n        self.indent_level -= 1\n        return results\n\n    def visit_MarkdownHorizontalRuleNode(self, node: MarkdownHorizontalRuleNode) -> None:  # pylint: disable=invalid-name\n        \"\"\"\n        Visit a horizontal rule node and print its details.\n\n        Args:\n            node: The horizontal rule node to visit\n\n        Returns:\n            None\n        \"\"\"\n        line_range = \"\"\n        if node.line_start is not None:\n            line_range = f\" (line {node.line_start})\"\n\n        print(f\"{self._indent()}HorizontalRule{line_range}\")\n```\n\n# Action:\n\nBoth metaphor and markdown use three backticks to signify a code-fenced block.  This can lead to problems if\ncode fences exist inside an embedded code block.  The Markdown parser handles this via the\n`_should_parse_code_block_as_continuation` method.  I need similar logic added to metaphor_lexer.py so it will\nemit a CODE token if we're inside a code continuation.\n\nIs this requirement clear?  If yes, then please propose a set of design changes to meet it.",
      "completed": true,
      "usage": null,
      "error": null,
      "model": null,
      "temperature": null
    },
    {
      "id": "ef90c3d2-9de0-4042-9333-05e39a5fcabb",
      "timestamp": "2025-06-04T09:31:13.672491",
      "type": "ai_response",
      "content": "I understand the requirement. You need to enhance the MetaphorLexer to properly handle nested code blocks by detecting when a line with three backticks should be treated as content within an existing code block rather than as the start/end of a code block.\n\nCurrently, the MetaphorLexer doesn't have a sophisticated mechanism to determine if a line with three backticks should be treated as content rather than a fence delimiter, which can cause issues when embedding code that itself contains code fence markers.\n\nHere's my proposed design:\n\n## Proposed Design Changes\n\n1. Add a programming language detection mechanism to MetaphorLexer similar to what's in the MarkdownASTBuilder\n2. Track the embedded parser state to determine if a line is a continuation\n3. Modify the `_process_line` method to use this continuation logic when processing fenced code\n\nLet me outline the specific changes:\n\n### 1. Add Language Parsing Dependencies\n\nThe MetaphorLexer will need to use the same programming language detection and parser registry that the markdown parser uses:\n\n```python\nfrom humbug.syntax.parser_registry import ParserRegistry\nfrom humbug.syntax.programming_language import ProgrammingLanguage\nfrom humbug.syntax.programming_language_utils import ProgrammingLanguageUtils\n```\n\n### 2. Add State Tracking for Embedded Code\n\nAdd new instance variables to track:\n- Current language of the code block\n- Parser state for the embedded language\n- Nesting level of code blocks\n\n### 3. Add Continuation Detection Method\n\nAdd a method similar to `_should_parse_code_block_as_continuation` from the markdown parser to determine if a line with backticks should be treated as content.\n\n### 4. Modify Code Block Processing Logic\n\nUpdate the code block processing logic to use the continuation detection when encountering lines with backticks.\n\n## Implementation\n\nHere's my implementation of these changes for the MetaphorLexer class:\n\n```python\nfrom typing import Dict, List, Final, Any\n\nfrom humbug.metaphor.metaphor_token import MetaphorToken, MetaphorTokenType\nfrom humbug.syntax.parser_registry import ParserRegistry\nfrom humbug.syntax.programming_language import ProgrammingLanguage\nfrom humbug.syntax.programming_language_utils import ProgrammingLanguageUtils\n\n\nclass MetaphorLexer:\n    \"\"\"\n    Lexer for handling the Metaphor language with its specific syntax.\n\n    The Metaphor language consists of:\n    - Keywords (Action:, Context:, Role:, etc)\n    - Indented blocks\n    - Text content\n    - Include/Embed directives\n\n    This lexer handles proper indentation, text block detection, and keyword parsing,\n    including nested code blocks with proper continuation detection.\n    \"\"\"\n\n    # Constants for language elements\n    INDENT_SPACES = 4\n\n    # Mapping of keywords to their token types\n    KEYWORDS: Final[Dict[str, MetaphorTokenType]] = {\n        \"Action:\": MetaphorTokenType.ACTION,\n        \"Context:\": MetaphorTokenType.CONTEXT,\n        \"Embed:\": MetaphorTokenType.EMBED,\n        \"Include:\": MetaphorTokenType.INCLUDE,\n        \"Role:\": MetaphorTokenType.ROLE\n    }\n\n    def __init__(self, input_text: str, filename: str) -> None:\n        \"\"\"\n        Initialize the MetaphorLexer.\n\n        Args:\n            input_text (str): The text content to be lexically analyzed\n            filename (str): Name of the file being processed\n        \"\"\"\n        self.in_text_block: bool = False\n        self.in_fenced_code: bool = False\n        self.indent_column: int = 1\n        self.filename: str = filename\n        self.tokens: List[MetaphorToken] = []\n        self.current_line: int = 1\n        self.input: str = input_text\n\n        # Code block state tracking\n        self._code_block_language: str = \"\"\n        self._embedded_parser_state: Any = None\n        self._embedded_language: ProgrammingLanguage = ProgrammingLanguage.UNKNOWN\n        self._code_block_nesting_level: int = 0\n        self._code_block_indents: List[int] = []\n\n        self._tokenize()\n\n    def get_next_token(self) -> MetaphorToken:\n        \"\"\"Return the next token from the token list.\"\"\"\n        if self.tokens:\n            return self.tokens.pop(0)\n\n        return MetaphorToken(MetaphorTokenType.END_OF_FILE, \"\", \"\", self.filename, self.current_line, 1)\n\n    def _should_parse_code_block_as_continuation(\n        self,\n        language: ProgrammingLanguage,\n        line_content: str\n    ) -> bool:\n        \"\"\"\n        Check if a line should be parsed as a continuation by the embedded parser.\n\n        Args:\n            language: The programming language of the code block\n            line_content: The content of the line to check\n\n        Returns:\n            True if this line should be treated as a continuation\n        \"\"\"\n        if language == ProgrammingLanguage.TEXT:\n            return False\n\n        # Get or create parser for this language\n        parser = ParserRegistry.create_parser(language)\n        if parser is None:\n            return False\n\n        # If language changed, reset state\n        if language != self._embedded_language:\n            self._embedded_parser_state = None\n            self._embedded_language = language\n\n        # Parse the line and check if we're in a continuation\n        new_state = parser.parse(self._embedded_parser_state, line_content)\n\n        # Update stored state\n        self._embedded_parser_state = new_state\n\n        # Return whether we're in a continuation\n        return new_state is not None and new_state.parsing_continuation\n\n    def _tokenize(self) -> None:\n        \"\"\"\n        Tokenize the input file into appropriate tokens.\n        Processes each line for indentation, keywords, and text content.\n        \"\"\"\n        if not self.input:\n            return\n\n        lines: List[str] = self.input.splitlines()\n        for line in lines:\n            self._process_line(line)\n            self.current_line += 1\n\n        # Handle remaining outdents at end of file\n        self._handle_final_outdents()\n\n    def _handle_final_outdents(self) -> None:\n        \"\"\"Handle any remaining outdents needed at the end of file.\"\"\"\n        while self.indent_column > 1:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.OUTDENT,\n                    value=\"[Outdent]\",\n                    input=\"\",\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=self.indent_column\n                )\n            )\n            self.indent_column -= self.INDENT_SPACES\n\n    def _process_line(self, line: str) -> None:\n        \"\"\"\n        Process a single line of input.\n\n        Args:\n            line: The line to process\n        \"\"\"\n        stripped_line = line.lstrip(' ')\n        start_column = len(line) - len(stripped_line) + 1\n\n        if not stripped_line:\n            self._handle_blank_line(start_column)\n            return\n\n        # Is this line a comment?\n        if stripped_line.startswith('#'):\n            return\n\n        # Does this line start with a tab character?\n        if stripped_line.startswith('\\t'):\n            self._handle_tab_character(stripped_line, start_column)\n            stripped_line = stripped_line[1:]\n            if not stripped_line:\n                return\n\n        # Check for code fence\n        in_fenced_code = self.in_fenced_code\n        starts_with_fence = stripped_line.startswith('```')\n\n        # Handle code block continuation detection\n        if starts_with_fence and in_fenced_code:\n            # Determine if this should be treated as content inside the code block\n            if self._code_block_language:\n                language = ProgrammingLanguageUtils.from_name(self._code_block_language)\n                if language != ProgrammingLanguage.UNKNOWN and self._should_parse_code_block_as_continuation(language, line):\n                    # Treat as content, not a fence\n                    self._handle_text_line(line, start_column)\n                    return\n                \n            # Check if this is a nested code fence\n            if start_column > self._code_block_indents[-1]:\n                self._code_block_nesting_level += 1\n                self._code_block_indents.append(start_column)\n                self._handle_text_line(line, start_column)\n                return\n                \n            # Check if this is closing the current fence\n            self._code_block_indents.pop()\n            self._code_block_nesting_level -= 1\n            if self._code_block_nesting_level == 0:\n                self.in_fenced_code = False\n                self._code_block_language = \"\"\n                self._embedded_parser_state = None\n                self._embedded_language = ProgrammingLanguage.UNKNOWN\n            \n        # Handle code fence start\n        elif starts_with_fence and not in_fenced_code:\n            self.in_fenced_code = True\n            self._code_block_nesting_level = 1\n            self._code_block_indents = [start_column]\n            \n            # Extract language if present\n            language_match = stripped_line[3:].strip()\n            if language_match:\n                self._code_block_language = language_match\n\n        # If we're not in a fenced code block then look for keywords.\n        if not self.in_fenced_code:\n            words = stripped_line.split(maxsplit=1)\n            first_word = words[0].capitalize()\n\n            if first_word in self.KEYWORDS:\n                self._handle_keyword_line(line, words, first_word, start_column)\n                self.in_fenced_code = in_fenced_code\n                return\n\n        # Treat this as a text block.\n        self._handle_text_line(line, start_column)\n        self.in_fenced_code = in_fenced_code\n\n    def _handle_tab_character(self, line: str, column: int) -> None:\n        \"\"\"\n        Handle tab characters in the input.\n\n        Args:\n            line: The line to check\n            column: The current column number\n        \"\"\"\n        self.tokens.append(\n            MetaphorToken(\n                type=MetaphorTokenType.TAB,\n                value=\"[Tab]\",\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=column\n            )\n        )\n\n    def _handle_keyword_line(self, line: str, words: List[str], keyword: str, start_column: int) -> None:\n        \"\"\"\n        Handle a line that starts with a keyword.\n\n        Args:\n            line: The complete line\n            words: The line split into words\n            keyword: The keyword found\n            start_column: The starting column of the content\n        \"\"\"\n        self._process_indentation(line, start_column)\n\n        # Create keyword token\n        self.tokens.append(\n            MetaphorToken(\n                type=self.KEYWORDS[keyword],\n                value=keyword,\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n\n        # Handle any text after the keyword\n        if len(words) > 1:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.KEYWORD_TEXT,\n                    value=words[1],\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column + len(keyword) + 1\n                )\n            )\n\n        self.in_text_block = False\n\n    def _handle_text_line(self, line: str, start_column: int) -> None:\n        \"\"\"\n        Handle a line that contains text content.\n\n        Args:\n            line: The line to process\n            start_column: The starting column of the content\n        \"\"\"\n        # Adjust indentation for continued text blocks\n        if self.in_text_block:\n            if start_column > self.indent_column:\n                start_column = self.indent_column\n\n            elif start_column < self.indent_column:\n                self._process_indentation(line, start_column)\n\n        else:\n            self._process_indentation(line, start_column)\n\n        text_content = line[start_column - 1:]\n        token_type = MetaphorTokenType.CODE if self.in_fenced_code else MetaphorTokenType.TEXT\n        self.tokens.append(\n            MetaphorToken(\n                type=token_type,\n                value=text_content,\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n        self.in_text_block = True\n\n    def _handle_blank_line(self, start_column: int) -> None:\n        token_type = MetaphorTokenType.CODE if self.in_fenced_code else MetaphorTokenType.TEXT\n        self.tokens.append(\n            MetaphorToken(\n                type=token_type,\n                value=\"\",\n                input=\"\",\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n\n    def _process_indentation(self, line: str, start_column: int) -> None:\n        \"\"\"\n        Process the indentation of the current line.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n        \"\"\"\n        indent_offset = start_column - self.indent_column\n\n        if indent_offset > 0:\n            self._handle_indent(line, start_column, indent_offset)\n\n        elif indent_offset < 0:\n            self._handle_outdent(line, start_column, indent_offset)\n\n    def _handle_indent(self, line: str, start_column: int, indent_offset: int) -> None:\n        \"\"\"\n        Handle an increase in indentation.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n            indent_offset: The change in indentation\n        \"\"\"\n        if indent_offset % self.INDENT_SPACES != 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.BAD_INDENT,\n                    value=\"[Bad Indent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            return\n\n        while indent_offset > 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.INDENT,\n                    value=\"[Indent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            indent_offset -= self.INDENT_SPACES\n\n        self.indent_column = start_column\n\n    def _handle_outdent(self, line: str, start_column: int, indent_offset: int) -> None:\n        \"\"\"\n        Handle a decrease in indentation.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n            indent_offset: The change in indentation\n        \"\"\"\n        if abs(indent_offset) % self.INDENT_SPACES != 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.BAD_OUTDENT,\n                    value=\"[Bad Outdent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            return\n\n        while indent_offset < 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.OUTDENT,\n                    value=\"[Outdent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            indent_offset += self.INDENT_SPACES\n\n        self.indent_column = start_column\n```\n\n## Key Changes\n\n1. Added code block state tracking variables:\n   - `_code_block_language`: Stores the language of the current code block\n   - `_embedded_parser_state`: Tracks the state of the embedded language parser\n   - `_embedded_language`: Stores the current programming language enum\n   - `_code_block_nesting_level`: Tracks nesting depth of code blocks\n   - `_code_block_indents`: Tracks indentation levels for nested code blocks\n\n2. Added `_should_parse_code_block_as_continuation` method:\n   - Uses the ParserRegistry to get a parser for the current language\n   - Calls the parser to determine if a line is a continuation\n   - Updates and maintains the parser state\n\n3. Enhanced `_process_line` method:\n   - Added detection for code fence markers (```)\n   - Added special handling for code fences inside code blocks\n   - Added nesting level tracking\n   - Added language detection for code blocks\n\nThis implementation should properly handle nested code blocks and determine when a line with three backticks should be treated as content within an existing code block rather than as a fence delimiter.",
      "completed": true,
      "usage": {
        "prompt_tokens": 36478,
        "completion_tokens": 4310,
        "total_tokens": 40788
      },
      "error": null,
      "model": "claude-3-7-sonnet-20250219",
      "temperature": 0.7
    },
    {
      "id": "0ef6f94c-5741-4d0f-8da3-401455a9f80d",
      "timestamp": "2025-06-04T09:43:40.257224",
      "type": "user_message",
      "content": "this won't work - we have to use the embedded parser for every line of the code fenced region (as we do for markdown) - we can't just use it if we see three backticks because the parser will have lost context",
      "completed": true,
      "usage": null,
      "error": null,
      "model": null,
      "temperature": null
    },
    {
      "id": "cc7d0132-4f7b-45c4-a3e8-4277dd12a54f",
      "timestamp": "2025-06-04T09:43:45.091440",
      "type": "ai_response",
      "content": "You're absolutely right. I need to revise my approach. The embedded parser needs to be used for every line within a code block to maintain proper context, not just when we encounter backticks. Let me correct my implementation:\n\n```python\nfrom typing import Dict, List, Final, Any\n\nfrom humbug.metaphor.metaphor_token import MetaphorToken, MetaphorTokenType\nfrom humbug.syntax.parser_registry import ParserRegistry\nfrom humbug.syntax.programming_language import ProgrammingLanguage\nfrom humbug.syntax.programming_language_utils import ProgrammingLanguageUtils\n\n\nclass MetaphorLexer:\n    \"\"\"\n    Lexer for handling the Metaphor language with its specific syntax.\n\n    The Metaphor language consists of:\n    - Keywords (Action:, Context:, Role:, etc)\n    - Indented blocks\n    - Text content\n    - Include/Embed directives\n\n    This lexer handles proper indentation, text block detection, and keyword parsing,\n    including nested code blocks with proper continuation detection.\n    \"\"\"\n\n    # Constants for language elements\n    INDENT_SPACES = 4\n\n    # Mapping of keywords to their token types\n    KEYWORDS: Final[Dict[str, MetaphorTokenType]] = {\n        \"Action:\": MetaphorTokenType.ACTION,\n        \"Context:\": MetaphorTokenType.CONTEXT,\n        \"Embed:\": MetaphorTokenType.EMBED,\n        \"Include:\": MetaphorTokenType.INCLUDE,\n        \"Role:\": MetaphorTokenType.ROLE\n    }\n\n    def __init__(self, input_text: str, filename: str) -> None:\n        \"\"\"\n        Initialize the MetaphorLexer.\n\n        Args:\n            input_text (str): The text content to be lexically analyzed\n            filename (str): Name of the file being processed\n        \"\"\"\n        self.in_text_block: bool = False\n        self.in_fenced_code: bool = False\n        self.indent_column: int = 1\n        self.filename: str = filename\n        self.tokens: List[MetaphorToken] = []\n        self.current_line: int = 1\n        self.input: str = input_text\n\n        # Code block state tracking\n        self._code_block_language: str = \"\"\n        self._embedded_parser_state: Any = None\n        self._embedded_language: ProgrammingLanguage = ProgrammingLanguage.UNKNOWN\n        self._code_block_nesting_level: int = 0\n        self._code_block_indents: List[int] = []\n\n        self._tokenize()\n\n    def get_next_token(self) -> MetaphorToken:\n        \"\"\"Return the next token from the token list.\"\"\"\n        if self.tokens:\n            return self.tokens.pop(0)\n\n        return MetaphorToken(MetaphorTokenType.END_OF_FILE, \"\", \"\", self.filename, self.current_line, 1)\n\n    def _update_parser_state(self, line_content: str) -> None:\n        \"\"\"\n        Update the embedded parser state with the current line.\n        \n        Args:\n            line_content: The content of the line to process\n        \"\"\"\n        if not self._code_block_language:\n            return\n            \n        language = ProgrammingLanguageUtils.from_name(self._code_block_language)\n        if language == ProgrammingLanguage.UNKNOWN or language == ProgrammingLanguage.TEXT:\n            return\n            \n        # Get or create parser for this language\n        parser = ParserRegistry.create_parser(language)\n        if parser is None:\n            return\n            \n        # If language changed, reset state\n        if language != self._embedded_language:\n            self._embedded_parser_state = None\n            self._embedded_language = language\n            \n        # Parse the line and update state\n        self._embedded_parser_state = parser.parse(self._embedded_parser_state, line_content)\n\n    def _is_in_continuation(self) -> bool:\n        \"\"\"\n        Check if the current parser state indicates we're in a continuation.\n        \n        Returns:\n            True if we're in a continuation state\n        \"\"\"\n        return (self._embedded_parser_state is not None and \n                hasattr(self._embedded_parser_state, 'parsing_continuation') and\n                self._embedded_parser_state.parsing_continuation)\n\n    def _tokenize(self) -> None:\n        \"\"\"\n        Tokenize the input file into appropriate tokens.\n        Processes each line for indentation, keywords, and text content.\n        \"\"\"\n        if not self.input:\n            return\n\n        lines: List[str] = self.input.splitlines()\n        for line in lines:\n            self._process_line(line)\n            self.current_line += 1\n\n        # Handle remaining outdents at end of file\n        self._handle_final_outdents()\n\n    def _handle_final_outdents(self) -> None:\n        \"\"\"Handle any remaining outdents needed at the end of file.\"\"\"\n        while self.indent_column > 1:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.OUTDENT,\n                    value=\"[Outdent]\",\n                    input=\"\",\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=self.indent_column\n                )\n            )\n            self.indent_column -= self.INDENT_SPACES\n\n    def _process_line(self, line: str) -> None:\n        \"\"\"\n        Process a single line of input.\n\n        Args:\n            line: The line to process\n        \"\"\"\n        stripped_line = line.lstrip(' ')\n        start_column = len(line) - len(stripped_line) + 1\n\n        if not stripped_line:\n            self._handle_blank_line(start_column)\n            return\n\n        # Is this line a comment?\n        if stripped_line.startswith('#'):\n            return\n\n        # Does this line start with a tab character?\n        if stripped_line.startswith('\\t'):\n            self._handle_tab_character(stripped_line, start_column)\n            stripped_line = stripped_line[1:]\n            if not stripped_line:\n                return\n\n        # Check for code fence\n        starts_with_fence = stripped_line.startswith('```')\n        \n        # If we're in a code block, update parser state for every line\n        if self.in_fenced_code:\n            self._update_parser_state(line)\n            \n            # If we're in a continuation state or this is not a fence, treat as content\n            if self._is_in_continuation() or not starts_with_fence:\n                self._handle_text_line(line, start_column)\n                return\n                \n            # This is a fence and we're not in a continuation\n            if starts_with_fence:\n                # Check if this is a nested fence (indented more than the opening fence)\n                if start_column > self._code_block_indents[-1]:\n                    self._code_block_nesting_level += 1\n                    self._code_block_indents.append(start_column)\n                    self._handle_text_line(line, start_column)\n                    return\n                    \n                # This is closing the current fence\n                self._code_block_indents.pop()\n                self._code_block_nesting_level -= 1\n                \n                if self._code_block_nesting_level == 0:\n                    # This closes the outer-most fence\n                    self.in_fenced_code = False\n                    self._code_block_language = \"\"\n                    self._embedded_parser_state = None\n                    self._embedded_language = ProgrammingLanguage.UNKNOWN\n                    \n                    # Generate the closing token\n                    self._handle_text_line(line, start_column)\n                    return\n                else:\n                    # This closes a nested fence\n                    self._handle_text_line(line, start_column)\n                    return\n        \n        # Handle code fence start when not in code block\n        elif starts_with_fence:\n            self.in_fenced_code = True\n            self._code_block_nesting_level = 1\n            self._code_block_indents = [start_column]\n            \n            # Extract language if present\n            language_match = stripped_line[3:].strip()\n            if language_match:\n                self._code_block_language = language_match\n                \n            # Generate the opening token\n            self._handle_text_line(line, start_column)\n            return\n\n        # If we're not in a fenced code block then look for keywords.\n        if not self.in_fenced_code:\n            words = stripped_line.split(maxsplit=1)\n            first_word = words[0].capitalize()\n\n            if first_word in self.KEYWORDS:\n                self._handle_keyword_line(line, words, first_word, start_column)\n                return\n\n        # Treat this as a text block.\n        self._handle_text_line(line, start_column)\n\n    def _handle_tab_character(self, line: str, column: int) -> None:\n        \"\"\"\n        Handle tab characters in the input.\n\n        Args:\n            line: The line to check\n            column: The current column number\n        \"\"\"\n        self.tokens.append(\n            MetaphorToken(\n                type=MetaphorTokenType.TAB,\n                value=\"[Tab]\",\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=column\n            )\n        )\n\n    def _handle_keyword_line(self, line: str, words: List[str], keyword: str, start_column: int) -> None:\n        \"\"\"\n        Handle a line that starts with a keyword.\n\n        Args:\n            line: The complete line\n            words: The line split into words\n            keyword: The keyword found\n            start_column: The starting column of the content\n        \"\"\"\n        self._process_indentation(line, start_column)\n\n        # Create keyword token\n        self.tokens.append(\n            MetaphorToken(\n                type=self.KEYWORDS[keyword],\n                value=keyword,\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n\n        # Handle any text after the keyword\n        if len(words) > 1:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.KEYWORD_TEXT,\n                    value=words[1],\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column + len(keyword) + 1\n                )\n            )\n\n        self.in_text_block = False\n\n    def _handle_text_line(self, line: str, start_column: int) -> None:\n        \"\"\"\n        Handle a line that contains text content.\n\n        Args:\n            line: The line to process\n            start_column: The starting column of the content\n        \"\"\"\n        # Adjust indentation for continued text blocks\n        if self.in_text_block:\n            if start_column > self.indent_column:\n                start_column = self.indent_column\n\n            elif start_column < self.indent_column:\n                self._process_indentation(line, start_column)\n\n        else:\n            self._process_indentation(line, start_column)\n\n        text_content = line[start_column - 1:]\n        token_type = MetaphorTokenType.CODE if self.in_fenced_code else MetaphorTokenType.TEXT\n        self.tokens.append(\n            MetaphorToken(\n                type=token_type,\n                value=text_content,\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n        self.in_text_block = True\n\n    def _handle_blank_line(self, start_column: int) -> None:\n        \"\"\"\n        Handle a blank line.\n        \n        Args:\n            start_column: The starting column of the content\n        \"\"\"\n        token_type = MetaphorTokenType.CODE if self.in_fenced_code else MetaphorTokenType.TEXT\n        self.tokens.append(\n            MetaphorToken(\n                type=token_type,\n                value=\"\",\n                input=\"\",\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n        \n        # Also update parser state for blank lines in code blocks\n        if self.in_fenced_code:\n            self._update_parser_state(\"\")\n\n    def _process_indentation(self, line: str, start_column: int) -> None:\n        \"\"\"\n        Process the indentation of the current line.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n        \"\"\"\n        indent_offset = start_column - self.indent_column\n\n        if indent_offset > 0:\n            self._handle_indent(line, start_column, indent_offset)\n\n        elif indent_offset < 0:\n            self._handle_outdent(line, start_column, indent_offset)\n\n    def _handle_indent(self, line: str, start_column: int, indent_offset: int) -> None:\n        \"\"\"\n        Handle an increase in indentation.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n            indent_offset: The change in indentation\n        \"\"\"\n        if indent_offset % self.INDENT_SPACES != 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.BAD_INDENT,\n                    value=\"[Bad Indent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            return\n\n        while indent_offset > 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.INDENT,\n                    value=\"[Indent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            indent_offset -= self.INDENT_SPACES\n\n        self.indent_column = start_column\n\n    def _handle_outdent(self, line: str, start_column: int, indent_offset: int) -> None:\n        \"\"\"\n        Handle a decrease in indentation.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n            indent_offset: The change in indentation\n        \"\"\"\n        if abs(indent_offset) % self.INDENT_SPACES != 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.BAD_OUTDENT,\n                    value=\"[Bad Outdent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            return\n\n        while indent_offset < 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.OUTDENT,\n                    value=\"[Outdent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            indent_offset += self.INDENT_SPACES\n\n        self.indent_column = start_column\n```\n\n## Key Changes in the Revised Implementation\n\n1. Added `_update_parser_state` method:\n   - Updates the embedded parser state for every line in a code block\n   - Maintains language context throughout the code block\n\n2. Added `_is_in_continuation` method:\n   - Checks if the current parser state indicates we're in a continuation\n\n3. Enhanced `_process_line` method:\n   - Updates parser state for every line within a code block\n   - Uses the continuation state to determine how to handle lines with backticks\n   - Properly handles nesting and closing of code blocks\n\n4. Updated `_handle_blank_line` method:\n   - Updates parser state for blank lines within code blocks\n\nThis implementation now maintains the parser state throughout the entire code block, not just when encountering backticks. It processes each line through the appropriate language parser to maintain context, just like the markdown implementation does.",
      "completed": true,
      "usage": {
        "prompt_tokens": 40840,
        "completion_tokens": 4041,
        "total_tokens": 44881
      },
      "error": null,
      "model": "claude-3-7-sonnet-20250219",
      "temperature": 0.7
    },
    {
      "id": "376313a3-9bbc-4b40-bfe9-36a95459ec20",
      "timestamp": "2025-06-04T09:45:26.889835",
      "type": "user_message",
      "content": "better, but we should follow the same pattern as the markdown parser and update the parse context and check for continuations in `_should_parse_code_block_as_continution`",
      "completed": true,
      "usage": null,
      "error": null,
      "model": null,
      "temperature": null
    },
    {
      "id": "62471265-e590-4321-a17a-c1136494d75b",
      "timestamp": "2025-06-04T09:45:32.527894",
      "type": "ai_response",
      "content": "You're right - we should align with the pattern used in the markdown parser. Let me revise the implementation to follow that approach more closely:\n\n```python\nfrom typing import Dict, List, Final, Any\n\nfrom humbug.metaphor.metaphor_token import MetaphorToken, MetaphorTokenType\nfrom humbug.syntax.parser_registry import ParserRegistry\nfrom humbug.syntax.programming_language import ProgrammingLanguage\nfrom humbug.syntax.programming_language_utils import ProgrammingLanguageUtils\n\n\nclass MetaphorLexer:\n    \"\"\"\n    Lexer for handling the Metaphor language with its specific syntax.\n\n    The Metaphor language consists of:\n    - Keywords (Action:, Context:, Role:, etc)\n    - Indented blocks\n    - Text content\n    - Include/Embed directives\n\n    This lexer handles proper indentation, text block detection, and keyword parsing,\n    including nested code blocks with proper continuation detection.\n    \"\"\"\n\n    # Constants for language elements\n    INDENT_SPACES = 4\n\n    # Mapping of keywords to their token types\n    KEYWORDS: Final[Dict[str, MetaphorTokenType]] = {\n        \"Action:\": MetaphorTokenType.ACTION,\n        \"Context:\": MetaphorTokenType.CONTEXT,\n        \"Embed:\": MetaphorTokenType.EMBED,\n        \"Include:\": MetaphorTokenType.INCLUDE,\n        \"Role:\": MetaphorTokenType.ROLE\n    }\n\n    def __init__(self, input_text: str, filename: str) -> None:\n        \"\"\"\n        Initialize the MetaphorLexer.\n\n        Args:\n            input_text (str): The text content to be lexically analyzed\n            filename (str): Name of the file being processed\n        \"\"\"\n        self.in_text_block: bool = False\n        self.in_fenced_code: bool = False\n        self.indent_column: int = 1\n        self.filename: str = filename\n        self.tokens: List[MetaphorToken] = []\n        self.current_line: int = 1\n        self.input: str = input_text\n\n        # Code block state tracking\n        self._code_block_language: str = \"\"\n        self._embedded_parser_state: Any = None\n        self._embedded_language: ProgrammingLanguage = ProgrammingLanguage.UNKNOWN\n        self._code_block_nesting_level: int = 0\n        self._code_block_indents: List[int] = []\n\n        self._tokenize()\n\n    def get_next_token(self) -> MetaphorToken:\n        \"\"\"Return the next token from the token list.\"\"\"\n        if self.tokens:\n            return self.tokens.pop(0)\n\n        return MetaphorToken(MetaphorTokenType.END_OF_FILE, \"\", \"\", self.filename, self.current_line, 1)\n\n    def _should_parse_code_block_as_continuation(\n        self,\n        language: ProgrammingLanguage,\n        line_content: str\n    ) -> bool:\n        \"\"\"\n        Check if a line should be parsed as a continuation by the embedded parser.\n\n        Args:\n            language: The programming language of the code block\n            line_content: The content of the line to check\n\n        Returns:\n            True if this line should be treated as a continuation\n        \"\"\"\n        if language == ProgrammingLanguage.TEXT:\n            return False\n\n        # Get or create parser for this language\n        parser = ParserRegistry.create_parser(language)\n        if parser is None:\n            return False\n\n        # If language changed, reset state\n        if language != self._embedded_language:\n            self._embedded_parser_state = None\n            self._embedded_language = language\n\n        # Parse the line and check if we're in a continuation\n        new_state = parser.parse(self._embedded_parser_state, line_content)\n\n        # Update stored state\n        self._embedded_parser_state = new_state\n\n        # Return whether we're in a continuation\n        return new_state is not None and new_state.parsing_continuation\n\n    def _tokenize(self) -> None:\n        \"\"\"\n        Tokenize the input file into appropriate tokens.\n        Processes each line for indentation, keywords, and text content.\n        \"\"\"\n        if not self.input:\n            return\n\n        lines: List[str] = self.input.splitlines()\n        for line in lines:\n            self._process_line(line)\n            self.current_line += 1\n\n        # Handle remaining outdents at end of file\n        self._handle_final_outdents()\n\n    def _handle_final_outdents(self) -> None:\n        \"\"\"Handle any remaining outdents needed at the end of file.\"\"\"\n        while self.indent_column > 1:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.OUTDENT,\n                    value=\"[Outdent]\",\n                    input=\"\",\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=self.indent_column\n                )\n            )\n            self.indent_column -= self.INDENT_SPACES\n\n    def _process_line(self, line: str) -> None:\n        \"\"\"\n        Process a single line of input.\n\n        Args:\n            line: The line to process\n        \"\"\"\n        stripped_line = line.lstrip(' ')\n        start_column = len(line) - len(stripped_line) + 1\n\n        if not stripped_line:\n            self._handle_blank_line(start_column)\n            return\n\n        # Is this line a comment?\n        if stripped_line.startswith('#'):\n            return\n\n        # Does this line start with a tab character?\n        if stripped_line.startswith('\\t'):\n            self._handle_tab_character(stripped_line, start_column)\n            stripped_line = stripped_line[1:]\n            if not stripped_line:\n                return\n\n        # Check for code fence\n        starts_with_fence = stripped_line.startswith('```')\n        \n        # Handle code block state\n        if self.in_fenced_code:\n            # Check if our embedded parser indicates this should be a continuation\n            if self._code_block_language and starts_with_fence:\n                language = ProgrammingLanguageUtils.from_name(self._code_block_language)\n                if language != ProgrammingLanguage.UNKNOWN:\n                    if self._should_parse_code_block_as_continuation(language, line):\n                        self._handle_text_line(line, start_column)\n                        return\n            \n            # If not a continuation and it's a code fence, check for nesting or closing\n            if starts_with_fence:\n                # Check if this is a nested fence (indented more than the opening fence)\n                if start_column > self._code_block_indents[-1]:\n                    self._code_block_nesting_level += 1\n                    self._code_block_indents.append(start_column)\n                    self._handle_text_line(line, start_column)\n                    return\n                    \n                # This is closing the current fence\n                self._code_block_indents.pop()\n                self._code_block_nesting_level -= 1\n                \n                if self._code_block_nesting_level == 0:\n                    # This closes the outer-most fence\n                    self.in_fenced_code = False\n                    self._handle_text_line(line, start_column)\n                    \n                    # Reset code block state\n                    self._code_block_language = \"\"\n                    self._embedded_parser_state = None\n                    self._embedded_language = ProgrammingLanguage.UNKNOWN\n                    return\n                else:\n                    # This closes a nested fence\n                    self._handle_text_line(line, start_column)\n                    return\n            \n            # Regular content within code block\n            self._handle_text_line(line, start_column)\n            return\n        \n        # Handle code fence start when not in code block\n        elif starts_with_fence:\n            self.in_fenced_code = True\n            self._code_block_nesting_level = 1\n            self._code_block_indents = [start_column]\n            \n            # Extract language if present\n            language_match = stripped_line[3:].strip()\n            if language_match:\n                self._code_block_language = language_match\n                \n            # Generate the opening token\n            self._handle_text_line(line, start_column)\n            return\n\n        # If we're not in a fenced code block then look for keywords.\n        words = stripped_line.split(maxsplit=1)\n        first_word = words[0].capitalize()\n\n        if first_word in self.KEYWORDS:\n            self._handle_keyword_line(line, words, first_word, start_column)\n            return\n\n        # Treat this as a text block.\n        self._handle_text_line(line, start_column)\n\n    def _handle_tab_character(self, line: str, column: int) -> None:\n        \"\"\"\n        Handle tab characters in the input.\n\n        Args:\n            line: The line to check\n            column: The current column number\n        \"\"\"\n        self.tokens.append(\n            MetaphorToken(\n                type=MetaphorTokenType.TAB,\n                value=\"[Tab]\",\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=column\n            )\n        )\n\n    def _handle_keyword_line(self, line: str, words: List[str], keyword: str, start_column: int) -> None:\n        \"\"\"\n        Handle a line that starts with a keyword.\n\n        Args:\n            line: The complete line\n            words: The line split into words\n            keyword: The keyword found\n            start_column: The starting column of the content\n        \"\"\"\n        self._process_indentation(line, start_column)\n\n        # Create keyword token\n        self.tokens.append(\n            MetaphorToken(\n                type=self.KEYWORDS[keyword],\n                value=keyword,\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n\n        # Handle any text after the keyword\n        if len(words) > 1:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.KEYWORD_TEXT,\n                    value=words[1],\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column + len(keyword) + 1\n                )\n            )\n\n        self.in_text_block = False\n\n    def _handle_text_line(self, line: str, start_column: int) -> None:\n        \"\"\"\n        Handle a line that contains text content.\n\n        Args:\n            line: The line to process\n            start_column: The starting column of the content\n        \"\"\"\n        # Adjust indentation for continued text blocks\n        if self.in_text_block:\n            if start_column > self.indent_column:\n                start_column = self.indent_column\n\n            elif start_column < self.indent_column:\n                self._process_indentation(line, start_column)\n\n        else:\n            self._process_indentation(line, start_column)\n\n        text_content = line[start_column - 1:]\n        token_type = MetaphorTokenType.CODE if self.in_fenced_code else MetaphorTokenType.TEXT\n        self.tokens.append(\n            MetaphorToken(\n                type=token_type,\n                value=text_content,\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n        self.in_text_block = True\n\n    def _handle_blank_line(self, start_column: int) -> None:\n        \"\"\"\n        Handle a blank line.\n        \n        Args:\n            start_column: The starting column of the content\n        \"\"\"\n        token_type = MetaphorTokenType.CODE if self.in_fenced_code else MetaphorTokenType.TEXT\n        self.tokens.append(\n            MetaphorToken(\n                type=token_type,\n                value=\"\",\n                input=\"\",\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n\n    def _process_indentation(self, line: str, start_column: int) -> None:\n        \"\"\"\n        Process the indentation of the current line.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n        \"\"\"\n        indent_offset = start_column - self.indent_column\n\n        if indent_offset > 0:\n            self._handle_indent(line, start_column, indent_offset)\n\n        elif indent_offset < 0:\n            self._handle_outdent(line, start_column, indent_offset)\n\n    def _handle_indent(self, line: str, start_column: int, indent_offset: int) -> None:\n        \"\"\"\n        Handle an increase in indentation.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n            indent_offset: The change in indentation\n        \"\"\"\n        if indent_offset % self.INDENT_SPACES != 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.BAD_INDENT,\n                    value=\"[Bad Indent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            return\n\n        while indent_offset > 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.INDENT,\n                    value=\"[Indent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            indent_offset -= self.INDENT_SPACES\n\n        self.indent_column = start_column\n\n    def _handle_outdent(self, line: str, start_column: int, indent_offset: int) -> None:\n        \"\"\"\n        Handle a decrease in indentation.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n            indent_offset: The change in indentation\n        \"\"\"\n        if abs(indent_offset) % self.INDENT_SPACES != 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.BAD_OUTDENT,\n                    value=\"[Bad Outdent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            return\n\n        while indent_offset < 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.OUTDENT,\n                    value=\"[Outdent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            indent_offset += self.INDENT_SPACES\n\n        self.indent_column = start_column\n```\n\nThis implementation now follows the same pattern as the markdown parser:\n\n1. It uses `_should_parse_code_block_as_continuation` to both update the parser state and check if we're in a continuation - just like the markdown implementation.\n\n2. It only calls this method when we encounter a code fence within a code block, which is the critical scenario where we need to distinguish between content and fence delimiters.\n\n3. The method handles:\n   - Getting the appropriate parser\n   - Updating the parser state\n   - Checking if we're in a continuation\n\n4. The implementation properly handles nested code blocks and closing fences.\n\nThis approach should correctly process embedded code blocks that contain backtick fences as part of their content, just as the markdown parser does.",
      "completed": true,
      "usage": {
        "prompt_tokens": 44923,
        "completion_tokens": 3944,
        "total_tokens": 48867
      },
      "error": null,
      "model": "claude-3-7-sonnet-20250219",
      "temperature": 0.7
    },
    {
      "id": "072a41e9-175f-4c73-aa7f-1015cb832f59",
      "timestamp": "2025-06-04T09:47:47.367238",
      "type": "user_message",
      "content": "you readded a check for if the line starts with a code fence - the parser must see all code lines",
      "completed": true,
      "usage": null,
      "error": null,
      "model": null,
      "temperature": null
    },
    {
      "id": "d821f28c-ceea-45e9-9b68-2b78ce1de01e",
      "timestamp": "2025-06-04T09:47:53.250720",
      "type": "ai_response",
      "content": "You're absolutely right. I've been making the same mistake repeatedly. Let me correct the implementation to ensure that the parser sees all lines within a code block, not just the ones with code fences:\n\n```python\nfrom typing import Dict, List, Final, Any\n\nfrom humbug.metaphor.metaphor_token import MetaphorToken, MetaphorTokenType\nfrom humbug.syntax.parser_registry import ParserRegistry\nfrom humbug.syntax.programming_language import ProgrammingLanguage\nfrom humbug.syntax.programming_language_utils import ProgrammingLanguageUtils\n\n\nclass MetaphorLexer:\n    \"\"\"\n    Lexer for handling the Metaphor language with its specific syntax.\n\n    The Metaphor language consists of:\n    - Keywords (Action:, Context:, Role:, etc)\n    - Indented blocks\n    - Text content\n    - Include/Embed directives\n\n    This lexer handles proper indentation, text block detection, and keyword parsing,\n    including nested code blocks with proper continuation detection.\n    \"\"\"\n\n    # Constants for language elements\n    INDENT_SPACES = 4\n\n    # Mapping of keywords to their token types\n    KEYWORDS: Final[Dict[str, MetaphorTokenType]] = {\n        \"Action:\": MetaphorTokenType.ACTION,\n        \"Context:\": MetaphorTokenType.CONTEXT,\n        \"Embed:\": MetaphorTokenType.EMBED,\n        \"Include:\": MetaphorTokenType.INCLUDE,\n        \"Role:\": MetaphorTokenType.ROLE\n    }\n\n    def __init__(self, input_text: str, filename: str) -> None:\n        \"\"\"\n        Initialize the MetaphorLexer.\n\n        Args:\n            input_text (str): The text content to be lexically analyzed\n            filename (str): Name of the file being processed\n        \"\"\"\n        self.in_text_block: bool = False\n        self.in_fenced_code: bool = False\n        self.indent_column: int = 1\n        self.filename: str = filename\n        self.tokens: List[MetaphorToken] = []\n        self.current_line: int = 1\n        self.input: str = input_text\n\n        # Code block state tracking\n        self._code_block_language: str = \"\"\n        self._embedded_parser_state: Any = None\n        self._embedded_language: ProgrammingLanguage = ProgrammingLanguage.UNKNOWN\n        self._code_block_nesting_level: int = 0\n        self._code_block_indents: List[int] = []\n\n        self._tokenize()\n\n    def get_next_token(self) -> MetaphorToken:\n        \"\"\"Return the next token from the token list.\"\"\"\n        if self.tokens:\n            return self.tokens.pop(0)\n\n        return MetaphorToken(MetaphorTokenType.END_OF_FILE, \"\", \"\", self.filename, self.current_line, 1)\n\n    def _should_parse_code_block_as_continuation(\n        self,\n        language: ProgrammingLanguage,\n        line_content: str\n    ) -> bool:\n        \"\"\"\n        Check if a line should be parsed as a continuation by the embedded parser.\n\n        Args:\n            language: The programming language of the code block\n            line_content: The content of the line to check\n\n        Returns:\n            True if this line should be treated as a continuation\n        \"\"\"\n        if language == ProgrammingLanguage.TEXT:\n            return False\n\n        # Get or create parser for this language\n        parser = ParserRegistry.create_parser(language)\n        if parser is None:\n            return False\n\n        # If language changed, reset state\n        if language != self._embedded_language:\n            self._embedded_parser_state = None\n            self._embedded_language = language\n\n        # Parse the line and check if we're in a continuation\n        new_state = parser.parse(self._embedded_parser_state, line_content)\n\n        # Update stored state\n        self._embedded_parser_state = new_state\n\n        # Return whether we're in a continuation\n        return new_state is not None and new_state.parsing_continuation\n\n    def _tokenize(self) -> None:\n        \"\"\"\n        Tokenize the input file into appropriate tokens.\n        Processes each line for indentation, keywords, and text content.\n        \"\"\"\n        if not self.input:\n            return\n\n        lines: List[str] = self.input.splitlines()\n        for line in lines:\n            self._process_line(line)\n            self.current_line += 1\n\n        # Handle remaining outdents at end of file\n        self._handle_final_outdents()\n\n    def _handle_final_outdents(self) -> None:\n        \"\"\"Handle any remaining outdents needed at the end of file.\"\"\"\n        while self.indent_column > 1:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.OUTDENT,\n                    value=\"[Outdent]\",\n                    input=\"\",\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=self.indent_column\n                )\n            )\n            self.indent_column -= self.INDENT_SPACES\n\n    def _process_line(self, line: str) -> None:\n        \"\"\"\n        Process a single line of input.\n\n        Args:\n            line: The line to process\n        \"\"\"\n        stripped_line = line.lstrip(' ')\n        start_column = len(line) - len(stripped_line) + 1\n\n        if not stripped_line:\n            self._handle_blank_line(start_column)\n            return\n\n        # Is this line a comment?\n        if stripped_line.startswith('#'):\n            return\n\n        # Does this line start with a tab character?\n        if stripped_line.startswith('\\t'):\n            self._handle_tab_character(stripped_line, start_column)\n            stripped_line = stripped_line[1:]\n            if not stripped_line:\n                return\n\n        # Check for code fence\n        starts_with_fence = stripped_line.startswith('```')\n        \n        # Handle code block state\n        if self.in_fenced_code:\n            # Always update the parser state for every line in the code block\n            if self._code_block_language:\n                language = ProgrammingLanguageUtils.from_name(self._code_block_language)\n                if language != ProgrammingLanguage.UNKNOWN:\n                    # Check if this line should be treated as a continuation\n                    is_continuation = self._should_parse_code_block_as_continuation(language, line)\n                    \n                    # If it's a fence but we're in a continuation, treat it as content\n                    if starts_with_fence and is_continuation:\n                        self._handle_text_line(line, start_column)\n                        return\n            \n            # If not a continuation and it's a code fence, check for nesting or closing\n            if starts_with_fence:\n                # Check if this is a nested fence (indented more than the opening fence)\n                if start_column > self._code_block_indents[-1]:\n                    self._code_block_nesting_level += 1\n                    self._code_block_indents.append(start_column)\n                    self._handle_text_line(line, start_column)\n                    return\n                    \n                # This is closing the current fence\n                self._code_block_indents.pop()\n                self._code_block_nesting_level -= 1\n                \n                if self._code_block_nesting_level == 0:\n                    # This closes the outer-most fence\n                    self.in_fenced_code = False\n                    self._handle_text_line(line, start_column)\n                    \n                    # Reset code block state\n                    self._code_block_language = \"\"\n                    self._embedded_parser_state = None\n                    self._embedded_language = ProgrammingLanguage.UNKNOWN\n                    return\n                else:\n                    # This closes a nested fence\n                    self._handle_text_line(line, start_column)\n                    return\n            \n            # Regular content within code block\n            self._handle_text_line(line, start_column)\n            return\n        \n        # Handle code fence start when not in code block\n        elif starts_with_fence:\n            self.in_fenced_code = True\n            self._code_block_nesting_level = 1\n            self._code_block_indents = [start_column]\n            \n            # Extract language if present\n            language_match = stripped_line[3:].strip()\n            if language_match:\n                self._code_block_language = language_match\n                \n            # Generate the opening token\n            self._handle_text_line(line, start_column)\n            return\n\n        # If we're not in a fenced code block then look for keywords.\n        words = stripped_line.split(maxsplit=1)\n        first_word = words[0].capitalize()\n\n        if first_word in self.KEYWORDS:\n            self._handle_keyword_line(line, words, first_word, start_column)\n            return\n\n        # Treat this as a text block.\n        self._handle_text_line(line, start_column)\n\n    def _handle_tab_character(self, line: str, column: int) -> None:\n        \"\"\"\n        Handle tab characters in the input.\n\n        Args:\n            line: The line to check\n            column: The current column number\n        \"\"\"\n        self.tokens.append(\n            MetaphorToken(\n                type=MetaphorTokenType.TAB,\n                value=\"[Tab]\",\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=column\n            )\n        )\n\n    def _handle_keyword_line(self, line: str, words: List[str], keyword: str, start_column: int) -> None:\n        \"\"\"\n        Handle a line that starts with a keyword.\n\n        Args:\n            line: The complete line\n            words: The line split into words\n            keyword: The keyword found\n            start_column: The starting column of the content\n        \"\"\"\n        self._process_indentation(line, start_column)\n\n        # Create keyword token\n        self.tokens.append(\n            MetaphorToken(\n                type=self.KEYWORDS[keyword],\n                value=keyword,\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n\n        # Handle any text after the keyword\n        if len(words) > 1:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.KEYWORD_TEXT,\n                    value=words[1],\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column + len(keyword) + 1\n                )\n            )\n\n        self.in_text_block = False\n\n    def _handle_text_line(self, line: str, start_column: int) -> None:\n        \"\"\"\n        Handle a line that contains text content.\n\n        Args:\n            line: The line to process\n            start_column: The starting column of the content\n        \"\"\"\n        # Adjust indentation for continued text blocks\n        if self.in_text_block:\n            if start_column > self.indent_column:\n                start_column = self.indent_column\n\n            elif start_column < self.indent_column:\n                self._process_indentation(line, start_column)\n\n        else:\n            self._process_indentation(line, start_column)\n\n        text_content = line[start_column - 1:]\n        token_type = MetaphorTokenType.CODE if self.in_fenced_code else MetaphorTokenType.TEXT\n        self.tokens.append(\n            MetaphorToken(\n                type=token_type,\n                value=text_content,\n                input=line,\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n        self.in_text_block = True\n\n    def _handle_blank_line(self, start_column: int) -> None:\n        \"\"\"\n        Handle a blank line.\n        \n        Args:\n            start_column: The starting column of the content\n        \"\"\"\n        token_type = MetaphorTokenType.CODE if self.in_fenced_code else MetaphorTokenType.TEXT\n        self.tokens.append(\n            MetaphorToken(\n                type=token_type,\n                value=\"\",\n                input=\"\",\n                filename=self.filename,\n                line=self.current_line,\n                column=start_column\n            )\n        )\n        \n        # Also update parser state for blank lines in code blocks\n        if self.in_fenced_code and self._code_block_language:\n            language = ProgrammingLanguageUtils.from_name(self._code_block_language)\n            if language != ProgrammingLanguage.UNKNOWN:\n                self._should_parse_code_block_as_continuation(language, \"\")\n\n    def _process_indentation(self, line: str, start_column: int) -> None:\n        \"\"\"\n        Process the indentation of the current line.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n        \"\"\"\n        indent_offset = start_column - self.indent_column\n\n        if indent_offset > 0:\n            self._handle_indent(line, start_column, indent_offset)\n\n        elif indent_offset < 0:\n            self._handle_outdent(line, start_column, indent_offset)\n\n    def _handle_indent(self, line: str, start_column: int, indent_offset: int) -> None:\n        \"\"\"\n        Handle an increase in indentation.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n            indent_offset: The change in indentation\n        \"\"\"\n        if indent_offset % self.INDENT_SPACES != 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.BAD_INDENT,\n                    value=\"[Bad Indent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            return\n\n        while indent_offset > 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.INDENT,\n                    value=\"[Indent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            indent_offset -= self.INDENT_SPACES\n\n        self.indent_column = start_column\n\n    def _handle_outdent(self, line: str, start_column: int, indent_offset: int) -> None:\n        \"\"\"\n        Handle a decrease in indentation.\n\n        Args:\n            line: The current line\n            start_column: The starting column of the content\n            indent_offset: The change in indentation\n        \"\"\"\n        if abs(indent_offset) % self.INDENT_SPACES != 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.BAD_OUTDENT,\n                    value=\"[Bad Outdent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            return\n\n        while indent_offset < 0:\n            self.tokens.append(\n                MetaphorToken(\n                    type=MetaphorTokenType.OUTDENT,\n                    value=\"[Outdent]\",\n                    input=line,\n                    filename=self.filename,\n                    line=self.current_line,\n                    column=start_column\n                )\n            )\n            indent_offset += self.INDENT_SPACES\n\n        self.indent_column = start_column\n```\n\nKey changes in this revised implementation:\n\n1. Now we process **every** line in a code block through the parser by calling `_should_parse_code_block_as_continuation` for all lines, not just those with code fences.\n\n2. The continuation status is only used to make a decision when we encounter a line with backticks that could be either a fence or content.\n\n3. We also update the parser state for blank lines within code blocks.\n\nThis implementation should now correctly handle all code blocks, including those with nested fences and code that contains backticks as part of the content.",
      "completed": true,
      "usage": {
        "prompt_tokens": 48892,
        "completion_tokens": 4062,
        "total_tokens": 52954
      },
      "error": null,
      "model": "claude-3-7-sonnet-20250219",
      "temperature": 0.7
    }
  ]
}